-gpt3 writes a poem/interesting phrase, then GAN "illustrates" (image and or gif)
    -maybe some way to incorporate torch lucent for more interesting styles
    -incorporate clip to select best "painting"
    -available on github: dall-e, lucidrains dall-e/deep daze/big sleep (note: apparently openai dall-e text encoder is not open sourced so can't directly input text)
-gpt3 provides instructions for building something with stylebreeder (need to experiment a bit manually first)
-provide written (or spoken, followed by speech to text lib) bullet points, then expand to a full speech of some kind in your own voice. Think virtual assistant.
    -chatbot with yourself (prompt gpt3 with your own writing, then use voice cloning app for text to speech)
    -chatbot with famous person (others have done this with gpt3 so should be good pre-existing prompts) combined with voice cloner, so you can actually "chat" with (e.g.) jk rowling in real time. Not sure what audio requirements are for voice cloner yet.
    -transcribe audio (of a meeting, phone call, speech, etc.), generate written feedback, maybe deliver via audio
-ask how to do something, gpt3 provides step by step instructions in text (then text to speech app for a virtual assistant)
-something with GANs for video? Look through coursera notebook.
    -or gans for music? gpt-scrolls pypi lib has example of this, not sure how well it works but I imagine we could find a lib to convert those notes to audio. (Compose background music for gan-generated gif?)
-youtube assistant (chrome extension?)
    -specify a time chunk of a video and have gpt3 explain it in simpler terms (i.e. explain a difficult concept in a stats lecture to a 5th grader, 9th grader, etc.)
        -could even try to generate audio using the voice of the person in the video, though this might not work that well (not much available data, some have multiple speakers)
    -identify emotion/tone throughout the video (see spikes of anger, humor, sadness)
    -identify key points/takeaways
    -generate questions corresponding to various timestamps
    -not just youtube videos: live lectures from remote learning!
-translate my rambling questions/explanations into more concise points (a Harrison translator!)

4/16/21
-------
-idea: we can show gpt3 some paired examples of generated and manual transcripts in hopes it can "translate" from generated to manual. That way, we can get improved transcript quality for videos that only have generated transcripts.
    -4/17 update: after some thought, I've concluded the paired transcripts are a bit less useful than I thought. We could construct something similar by taking fully punctuated text and removing all punctuation. It wouldn't have the occasional errors of speech-to-text (e.g. "adverse cereal" vs "adversarial") but the sentence tokenization task would be solvable that way.

4/17/21
-------
-explain to a 2nd grader prompt:
    -ada and babbage just repeat the input. Curie maybe shortened sentences a bit but wasn't that impressive. Seems like we really do have to use davinci here.
-idea: video recommender or clustering system. gpt3 is good at semantic search, and transcripts let us easily turn videos into "documents". (babbage engine suggested)
-idea: integrate with apple arkit
    -have gpt3 write a story, then use text descriptions plus clip to find available artifacts online to insert into the scene as illustration
    -img recognition -> text description of your surroundings -> some kind of instructions/feedback?
        -batting/yoga/lifting form feedback

5/23/21
-------
-arxiv/semantic scholar integration ideas:
    -say a topic (linear attention) or a question (how does linformer reduce attention time complexity?), find the most relevant paper using API (or get top n, then use gpt3 doc search to choose 1), then have gpt3 use question answering to provide the answer.
    -use my Explain ML prompt or the standard tldr prompt to summarize the abstract, the whole paper, or a portion of the paper.
    -prompt gpt3 to generate abstract from title
        -or generate paper from abstract, but that's very token intensive
    -"Expand On" model: input is a term like "instance norm", output is a short passage explaining it. Just manually construct the prompt once, no need for api - gpt3 already contains compressed representations of all this knowledge.
   -add gui option to paste paper ID/url, then get summary 

5/28/21
-------
Thinking there might be some room to improve google's information retrieval capabilities. Effective googling is definitely still a skill, and it can take multiple query phrasings, clicking on  multiple pages, or reading through long chunks of a page to find the desired answer. I'm thinking we may be able to speed this up with gpt3. I briefly tried to think of a few searches to construct samples manually, but this was a bit tough. I'm thinking it may be better to organically let challenging searches arise and make note of them (and their ultimately useful results) when they do.

7/10/21
-------
I asked GPT3, a massive machine learning model built by OpenAI, to analyze a few of tonights matchups and predict who will win. 
It's not flawless but I've certainly seen worse takes (in the examples below, I typed the lines starting with "Matchup"; the rest is the model):

> **Matchup:** Gilbert Burns vs. Stephen Thompson  
**Analysis:** It's been a long time since we've seen Thompson fight, and it's fair to wonder if he'll still have the same pop on his counters or ability to end a fight in the blink of an eye. He's a very safe fighter, however, and his kicks, volume and power give him a clear edge in this matchup. It's possible that Burns will be able to get in his face or put him in the clinch, but that's not Thompson's game. He'll pick Burns apart with his low kicks and eventually turn this into a kickboxing match.  
**Prediction:** Stephen Thompson by TKO.

***

> **Matchup:** Dustin Poirier vs. Conor McGregor 3  
**Analysis:** McGregor's takedown defense has been steadily improving, and he has the speed and movement to strike with Poirier and avoid exchanges he can't win. Poirier doesn't have the best boxing, but he can crack with power and has a solid wrestling base. He can also scramble up quickly from the bottom, but getting there is a risky proposition against McGregor. McGregor's pressure and pace can create opportunities to land big strikes that time well, and his physical gifts are tough to match. He can finish whenever he wants and Poirier is still an underrated wrestler, but I think McGregor gets off more strikes and forces more action.  
**Prediction:** Conor McGregor by KO.

A few more notes for anyone interested:
-GPT3 basically tries to generate responses that sound plausible but that doesn't guarantee they'll be particularly accurate or insightful. Its training data likely contains far more dumb MMA twitter takes than quality fight articles so we end up with something in between. Carefully phrasing our prompts can lead to very different results (e.g. we could ask for one set of predictions from a casual fan, one from a brilliant fight analyst, etc.). I didn't put a ton of time into engineering the prompts that generated these responses so we could likely get better quality analysis with some effort.
-GPT3 was released over a year ago and I haven't been able to confirm whether OpenAI does any kind of fine-tuning over time. If not, the model's knowledge of these fighters may be a bit outdated.
-GPT3 can also imitate specific people (it's much easier if they're reasonably well-known). As far as mma goes, imagine chatting with Rogan about tonight's fights or asking McGregor how it feels to walk out to a title fight. Pretty cool. I built myself a simple audio interface which adds to the effect, though I haven't added any custom voices yet so Rogan's words are still delivered in a humorless British accent.

7/12/21
-------
Problem: want to be able to hold longer conversations without prompts growing infeasibly long (aside from cost, gpt3 can only handle a limited number of tokens at a time). Current implementation makes that difficult because we pass in a FULL PROMPT each time (we'd need to re-extract the last response). Also, query() gets full text from manager's RUNNING_PROMPT, though I think that can be changed more easily.

Thoughts: 
-maybe we should store a list of user inputs and gpt3 responses so it's easy to choose how many to pass in each time (imagine a param response_window=2, for example).
-running_prompt should not be used by GUI: keep that fully internal. Provide a separate conversation_history var (basically what running_prompt currently refers to).
-maybe should provide method to "query_later". Or this could be an opportunity for my @lazy decorator!

7/16/21
-------
pyinstaller error when trying to run result (file bin/dist/main/main.exe, exe not visible though):

https://stackoverflow.com/questions/35478526/pyinstaller-numpy-intel-mkl-fatal-error-cannot-load-mkl-intel-thread-dll

Looks like we need to write some hook for pyinstaller. I'm guessing this will be just one of many pyinstaller errors so I'll hold off until I'm pretty sure I'm done.

7/22/21
-------
possible post themes
-pick 1 thing ("this is what I learned from talking to gpt3"; "this is what I learned from building my first GUI"; etc.) and focus on that
-document technical things I learned and want to be able to reference later (harder here since this wasn't super technically ambitious)
-jot down a random assortment of thoughts
-quick description of what I did - more portfolio-like than blog post like
-general side project lessons

possible post topics
-take some time to actually talk to the available personas, then write about that. 
-my first gui. Diffs from web app.
-Building an audio interface to gpt3. UX difficulties.
-Programming paradigms: declarative vs OOP and shoehorning one in where it's not ideal
-using a library that's under frequent development (dearpygui)
-pyinstaller and dearpygui

---
Latest dearpygui error:
FileNotFoundError: [Errno 2] No such file or directory: 'data/prompts'

8/13/21
-------
-latest docker error [UPDATE: fixed by downgrading pandas_flavor]:

 File "/usr/local/lib/python3.7/site-packages/pandas_flavor/__init__.py", line 5, in <module>
    from .xarray import (register_xarray_dataarray_method, 
  File "/usr/local/lib/python3.7/site-packages/pandas_flavor/xarray.py", line 2, in <module>
    import xarray as xr
  File "/usr/local/lib/python3.7/site-packages/xarray/__init__.py", line 3, in <module>
    from . import testing, tutorial, ufuncs
  File "/usr/local/lib/python3.7/site-packages/xarray/testing.py", line 9, in <module>
    from xarray.core import duck_array_ops, formatting, utils
  File "/usr/local/lib/python3.7/site-packages/xarray/core/duck_array_ops.py", line 16, in <module>
    from . import dask_array_compat, dask_array_ops, dtypes, npcompat, nputils
  File "/usr/local/lib/python3.7/site-packages/xarray/core/npcompat.py", line 80, in <module>
    from numpy.typing import DTypeLike
  File "/usr/local/lib/python3.7/site-packages/numpy/typing/__init__.py", line 316, in <module>
    from ._dtype_like import (
  File "/usr/local/lib/python3.7/site-packages/numpy/typing/_dtype_like.py", line 95, in <module>
    class _SupportsDType(Generic[_DType_co]):

8/14/21
-------
latest docker error:
Glfw Error 65544: X11: The DISPLAY environment variable is missing
Glfw Error 65537: The GLFW library is not initialized
Glfw Error 65537: The GLFW library is not initialized
Glfw Error 65537: The GLFW library is not initialized
python: /home/appveyor/projects/dearpygui/Dependencies/glfw/src/window.c:531: glfwSetWindowPos: Assertion `window != NULL' failed

8/15/21
-------
recent docker changes (order matters):

apt install sudo
apt-get install -y gnupg gnupg2
apt-get install -y mesa-utils and libgl1-mesa-glx
sudo add-apt-repository ppa:ubuntu-x-swat/updates
sudo apt dist-upgrad

8/28/21
-------
fine tuning notes
-no davinci fine tuning
-pricing is a bit more expensive for the same model but not prohibitively so - fine-tuned curie is half the cost of davinci, and the lack of instructions/prompt can reduce the number of tokens
-conditional generation recommends at least ~500 examples. Open-ended generation (e.g. generating whole podcast transcripts) needs at least a few thousand. Those numbers are honestly not that bad for most tasks. I could probably scrape data for most tasks, but if it really comes down to it, generating 500 manual examples manually isn't crazy.

notes on god prompt
-for better or for worse, god is not very talkative. I guess it's probably common for fictional conversations with god to have the character hoping for some detailed solution to their problems but what they get are short, vague, slightly mystical answers.
-still lots of room to experiment with the prompt. A Douglas Adams-y god might be fun, but would probably require fine-tuning.

9/2/21
------
running app in alias mode. Save as in default mode has default path:
/Users/hmamin/jabberwocky/dist/main.app/Contents/Resources/data/completions/punctuate
instead of
/Users/hmamin/jabberwocky/data/completions/punctuate

2/1/22
------
Possible intents:

- choosePersona
- chooseModel
- changeTemperature
- changeMaxLength

Possible slots:

- person (e.g. Alex Honnold)
- model (e.g. GPT-J)
- temperature
- length

2/9/22 wed
----------
In case I need to revisit email attachment stuff:
https://datamakessense.com/easy-scheduled-emailing-with-python-for-typical-bi-needs/

2/12/22 sat
-----------
Thought: maybe Voice Chat name is being clobbered by an existing skill (either user-built or default). Thought of this because when building dummy app, I forgot I used the name "skill debugger" and tried to launch the skill "memory game" in the dev console since that's what the tutorial used. Rather than failing, it just calls an actual Memory Game skill that's not related to my app. Same thing could be happening with voice chat.
