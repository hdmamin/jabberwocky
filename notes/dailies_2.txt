Context: been fiddling around with this project again lately but I'm not quite ready to restart daily contributions. Documenting where I'm at here for now so it's easier to pick up when I come back.

11/15/21 mon
------------
Left off
-talk() now prints responses with pretty formatted persona name.

Next Steps
-adjust query_kwargs so that we don't pass the wrong ones to gptj or gpt-neo mock funcs (maybe something like drop keys in query_kwargs that aren't in the func signature? Might not work if they take kwargs).
-write new mock funcs to support:
    -codex
    -new open source gpt-like model on modelhub (name is something about "sci" IIRC)
-live typing effect?
-consider a "choose from 1 of k responses" mode. Would need to think about how this would work w/ live typing and how it would work w/ conv manager (usually query() updates the conv history).
-maybe replace save/quit options w/ prompt_toolkit menus?

Context: picking up on this again for part 2 (Alexa skill).

1/31/22 mon
-----------
X -write premortem

2/2/22 tues
-----------
X -look through sample alexa conversation skeleton repo
    X -decide whether to use that template or "start from scratch"
        UPDATE: start by trying template.
X -create alexa skill in AWS UI
X -change invocation name
    UPDATE: needed to be 2 words and I wanted it to be short. Jabberwocky -> Voice Chat.
~ -start adding intents
    ~ -start adding slots
        UPDATE: wrote list of possible slots. added Person slot and Model slot.
    UPDATE: wrote list of possible intents in misc.txt. Added choosePersona intent.
-figure out how code will be structured locally (will alexa reference a separate repo if I use the conversation template? Will a single file basically be sufficient? Maybe an `alexa` subdir which can contain whatever I need it to?)
-follow UI instructions to determine next steps

2/3/22 wed
----------
~ -read up on dialog delegations strategy (do I want this?)
    _ -add to choosePersona if necessary
        UPDATE: alexa auto-determines next thing to ask? Most of my interactions should require minimal scaffolding so I don't think we need this.
~ -read up on intent confirmation (do I want this?)
    _ -add to choosePersona if necessary
        UPDATE: unnecessary at least for now. Consider adding later for Model or settings or choosePersona, maybe.
X -create more slots (see misc.txt)
X -create more intents (see misc.txt)
~ -see backlog
    X -fix incorrect usage of intents/slots 
        UPDATE: intents should use a var name and then you set the var type in the section below. Previously I was using the var type in the intent itself. I.e. "call {amazon.Person}" -> "call {Person}", where Person has type amazon.Person
    ~ -start testing interactions
        UPDATE: lots of failures. I realized my code has been filled in with their conv template but I need to make a lot of changes.

2/4/22 thurs
-------------
~ -look through code tab to see how expected interactions look
    X -try out in Test tab
        UPDATE: still having trouble getting this to work. Found docs for ask_sdk and decided to try to follow those locally.
~ -explore possibility of local ngrok
    UPDATE: not sure if this is compatible with lamda style app code. Table this for now and return to amazon hosted endpoint.
X -add code locally
    UPDATE: created new alexa dir.
-start following ask_sdk tutorial
    X -write launch handler
    ~ -write choose model handler
    ~ -write choose person handler
-update code to use my new intents
    -regular conversation
    -choose person
    -change max length
    -change temperature

2/4/22 fri
----------
-continue following ask_sdk tutorial
    X -finish choose person handler
        X -figure out best way to make conv manager available globally
            UPDATE: initially wrote wrapper class that delegates to an attr where is stores the manager, then realized it didn't seem to be doing anything useful. Just load the manager as a global var in the global scope. Can adjust strategy later if needed.
        UPDATE: tentatively done, though will likely need some troubleshooting/extra functionality/logging/error handling once I start testing.
    ~ -finish choose model handler
        UPDATE: tentatively mostly done, though need to figure out how to handle changing model to gptj or other non-int version. I think a better strategy than updating kwargs may be to store some session-level kwargs (I believe handler_input has some kind of session object that may be appropriate for this), then always pass that in to the query method.
X -write convenience func to access slots
X -write convenience func to speak/respond
~ -clean up template file a bit (delete unused classes)
_ -confirm stackoverflow-suggested method of extracting slots works (unclear - pycharm code completion stopped finding it)
    UPDATE: prob need to wait until I figure out how to run this thing. Template has a helper method that does something similar so that's an option too.

2/5/22 sat
----------
[DON'T LET THIS GET PUSHED BACK TOO FAR - don't want to end up having to rewrite a ton of code if something is incompatible.]
~ -figure out how to get this running on lambda (if possible: reliance on local files might be a problem)
    X -how hard would it be to convert this to something we can run with ngrok? Is lambda_function.py still compatible or is it totally different locally?
        UPDATE: decided to try rewriting with flask-ask. We're still early and it seems like dev/testing will be far easier (hopefully avoid slow build time for every change).
X -write new template app with flask-ask
X -try running flask app w/ ngrok
    UPDATE: accessible via generic url.
X -rebuild model 
    ~ -see if I can access flask-ask app through aws console
        UPDATE: no errors but still references console code rather than flask ask local code.
-look into handler_input session object
    -try using this to update kwargs (e.g. model, max len, etc.)
-more intent functions/endpoints:
    X -set temperature
    ~ -set max length
        UPDATE: added skeleton func.

2/6/22 sun
----------
~ -troubleshoot model build (no errors but still references console code rather than flask ask local code)
    ~ -try new flask-ask version in Alexa console (Test tab)
        UPDATE: spent most of time troubleshooting w/ minimal progress. Seems like the test console knows about the right URL (I think) but the api call is failing so it falls back to some generic message. Sample flask-ask code from aws tutorial has the same problem - possible that flask-ask is just no longer compatible ðŸ˜¬. When using test console, I see failed requests show up in app (not to any specific endpoint, looks like?).
-more endpoints:
    ~ -set max_length endpoint
        UPDATE: still need error handling though.
    -conversation end (add extra question offering to email transcript to user?)
    -generic conv response endpoint
X -fix logger (wasn't printing to stdout)
    UPDATE: unsure if fix was related to changing logging level or just restarting app, but it works now.
X -read up on flask-ask session vs. context (readthedocs.io tab)
    X -update it to store default _kwargs attr from conv manager
    X -update chooseModel to use this
    X -update chooseMaxLength to use this
    X -update chooseTemperature to use this

2/7/22 mon
----------
X -add error handling to max_length endpoint
-add more endpoints:
    ~ -conversation end (add extra question offering to email transcript to user?)
        UPDATE: started writing but it's a bit tricky with optional saving.
    X -generic conv response endpoint
    X -debugging intent (repeat user response back)
X -first draft of func to save conv (want it emailed rather than local)
-brainstorm: what else could possibly cause these alexa issues? How to troubleshoot and eventually fix?
-see if there are places I should add reprompt (chained method after question)

2/8/22 tues
-----------
_ -new endpoint for user to set email
    _ -add intent in console
    UPDATE: think I found a way to do this via amazon API rather than through voice.
    X -function to get user email using Amazon API
        UPDATE: untested though because it requires Alexa context object to run, which means I need to get the test tab working to see if it works.
-update other endpoints to check if should_exit
-rename `exit` function to avoid clobbering builtin
-brainstorm: what else could possibly cause these alexa issues? How to troubleshoot and eventually fix?
-see if there are places I should add reprompt (chained method after question)

2/9/22 wed
----------
-rename `exit` function to avoid clobbering builtin
-see if we can easily update htools.quickmail to include text attachment
-make new jabberwocky email to send transcripts
    -add info to htools creds file
-see if there are places I should add reprompt (chained method after question)


Backlog
-look in alexa dev forum for how to direct 1 intent to another (prob need to use session to set temporary key)
-update other endpoints to check if should_exit
-brainstorm: what else could possibly cause these alexa issues? How to troubleshoot and eventually fix?
-misc docstrings in app.py
-follow UI instructions to determine next steps
-figure out how code will be structured locally (will alexa reference a separate repo if I use the conversation template? Will a single file basically be sufficient? Maybe an `alexa` subdir which can contain whatever I need it to?)
