4/9/21
------
X -update cookiecutter template makefile and notes files
X -choose project name
X -final investigation of dearpygui vs kivy (+kivymd)
    [dearpygui mobile won't be ready in time. Use this if you want to build a desktop app, use kivy if you want to build mobile. Leaning mobile - dearpygui looks cool but I feel if I'm going to do something non-streamlit/dash, I should make it REALLY different. I'm now thinking the gans could be a problem though - gpt3 is just an api so that's fine, but I'd need to host the gans somewhere. This is meant to be pretty open ended though so I could do gan stuff on paperspace and then a voice app or something else for mobile (spoken/written bullet points -> speech in my voice?). Time may be a constraint though if I try to do both - gpt3 trial expires at end of June. Maybe learning fund can help out there.]
X -make new git project
X -write project requirements
X -write premortem
-write lessons from last time

4/10/21
-------
X -write lessons from last time
    X -documented various project ideas
    X -looked through openai repos for more ideas. Briefly tried out dall-e notebook.
X -try out openai pypi package to make sure I can communicate w/ gpt3 programmatically
    -if necessary, write my own helper functions to wrap common actions
X -choose method of loading api key and write func
    [dotfile or env var both supported]
X -define constants to easily access engine names by index and view prices
X -watch video on sirens (in this context, basically a way to create better combinations of inputs (e.g. images) than simple interpolation)
X -run dall-e and deep-daze demo notebooks in colab
-look into how to use various gan packages (install? clone?)
-make sure I can still access paperspace
    -maybe update dotfiles/envs etc. on machine if necessary

4/11/21
-------
-try out chronology lib for programmatic gpt3 access and see if it looks helpful compared to openai lib
    -if necessary, write my own helper functions to wrap common actions
    X -try a couple simple requests
X -make sure I can still access paperspace
    X -maybe update dotfiles/envs etc. on machine if necessary
    X -copy over openai dotfile
    X -create new machine and configure (some things changed)
        X -test that gpu is available
X -create prompts dir and write func to load_prompt
    X -allow data/prompts subdir in git (not very big)
X -write helper to print prompt in bold and resp in normal text
X -add jabberwocky imports to template nb
X -re-watched kilcher Clip video
-choose a first use case to work on
    -download/install a gan package?

4/12/21
-------
~ -more api exploration
    -try out chronology lib for programmatic gpt3 access and see if it looks helpful compared to openai lib
    -if necessary, write my own helper functions to wrap common actions
    ~ -check if there's a free gpt2 endpoint?
        [pypi library booste. API key is in gmail 55.]
        ~ -if not, maybe create mock request func to save credits (though ada is pretty cheap)
X -try free content filter in openai api
    X -write wrapper
X -udpate openai_auth func to set key automatically
X -finish signup for booste lib
-choose a first use case to work on
    -download/install a gan package?

4/13/21
-------
-try chronology lib
X -write booste api key loading func
X -port and finalize text_segment func for youtube transcription idea
X -document functions in utils
X -finish query_gpt3 func
    X -how to handle logprobs?
        [Just let user choose to return everything if they want.]
    X -try stream=True
        -write generator version of query_gpt3 (func must be one or the other)
    -add tab completion for extra params? Would take some py magic
X -create even shorter prompt to save tokens
X -port query_content_filter func
    X -finish documenting
-re-watch dall-e video

4/14/21
-------
X -port query_gpt3
    X -document
    X -save sample response and use it for better mocking
    X -write generator version of query_gpt3 (func must be one or the other)
        X -port and document
    -tab completion magic?
-try chronology lib
-try booste lib
-re-watch dall-e video

4/15/21
-------
_ -tab completion magic for query_gpt3 and generator?
    UPDATE: looked into this but doesn't look like openai api includes this anywhere. Good enough - I included the major kwargs.
X -rewrite 2 query functions into 1 merged function (stream=True returns a generator rather than yielding values)
-try chronology lib
-try booste lib
-look through misc.txt notes and decide on a first use case to try
    -if videos, start messing around with youtube transcription package
    -if gans, select a gan to start with and look into download/installation (dall-e, deep daze, etc.)
-re-watch dall-e video

4/16/21
-------
X -look through misc.txt notes and decide on a first use case to try (leaning heavily towards youtube transcription-related stuff)
    UPDATE: start with youtube transcription stuff. The jabberwocky name may make less sense here, as does the supposed requirement for a mobile/desktop app. I suppose if really necessary I could always push my gan mobile app to a separate project - probably easier to justify gpt3 payment if I demo something useful first.
~ -if youtube, start messing around with youtube transcription package
    ~ -do all/most videos have transcripts?
        UPDATE: I think all/most have auto-generated transcripts, but relatively few have manually generated ones.
    _ -maybe wrap text_segment func to work if we want the PREV n seconds instead of specifying start/end
        UPDATE: unnecessary atm. We can make the user facing version ask for last n seconds, but for now it makes sense to keep it this way.
    -try out "explain to a fifth grader" etc. prompts from docs
    -save some in prompts dir
    -consider cleaning up text_segment and related funcs to act on whole sentences when possible
-if gans, select a gan to start with and look into download/installation (dall-e, deep daze, etc.)

4/17/21
-------
X -try out "explain to a fifth grader" etc. prompts from docs
    X -save some in prompts dir
    X -try tuning ML simplifier prompt
    -consider cleaning up text_segment and related funcs to act on whole sentences when possible
-try some format fixing prompts (autogenerated -> manual transcript. Maybe use chunks from different videos to get some variety. This idea alone actually seems pretty powerful - a way to rapidly improve quality of speech to text.)

4/18/21
-------
X -save more generic ELI5 prompt (mine is very ml-focused. They provide a good jupiter example.)
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
X -update or write new load_prompt func:
    X -some prompts should allow us to embed input text into them (e.g. rather than being static like short_dates, we want to show a few examples (saved in txt file) and then append our new piece of text to generate based on)
    X -store recommended kwargs for calling query_gpt3 (e.g. simplify_ml really requires davinci to work well. Stop sequence should be specified as well.)
    X -add kwarg info to data dir (single json file mapping file name to kwargs? Or make each prompt file a txt/yaml file containing multiple fields?)
        UPDATE: give each prompt a subdir with a config.yaml file and prompt.txt file. Reasons in load_prompt func.
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
-try some format fixing prompts (autogenerated -> manual transcript. Maybe use chunks from different videos to get some variety. This idea alone actually seems pretty powerful - a way to rapidly improve quality of speech to text.)

4/19/21
-------
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
    X -error checking for times
X -try some format fixing prompts (autogenerated -> manual transcript. Maybe use chunks from different videos to get some variety. This idea alone actually seems pretty powerful - a way to rapidly improve quality of speech to text.)
    UPDATE: not perfect but this generally works quite well.
    X -try chaining <PUNCTUATE> - <ELI>
        UPDATE: didn't work very well. Maybe the input passage was too simple already, or maybe we need to provide a few examples from youtube transcripts.
X -add some printed outputs to get_transcripts() so I don't always have to check which are None
X -update load_prompt to separate printed reminder from main prompt

4/20/21
-------
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
    ~ -consider: add punctuation once (to whole transcript) or add it to a small segment each time we ask for a summary/eli5 etc?
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-try some other prompts post punctuation: summarize, simplify_ml (on an ml video)
-try out other tasks and add to prompts dir:
    -key point extraction
    -question generation

4/21/21
-------
~ -continue working on func to re-map punctuated text to timestamps. (Even if we don't do this all at once, we should probably cache results from translating chunks.)
    X -try re.split in place of split
    X -add strip results option to query_gpt3 (and prompt config files)
    X -try fuzzywuzzy-based approach to realignment
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-try some other prompts post punctuation: summarize, simplify_ml (on an ml video)
-try out other tasks and add to prompts dir:
    -key point extraction
    -question generation

4/22/21
-------
X -continue working on func to re-map punctuated text to timestamps. (Even if we don't do this all at once, we should probably cache results from translating chunks.)
    -evaluate fuzzywuzzy realignment approach on a couple more chunks
    -consider ways to improve:
        X -bigram similarity instead of single word
        X -wider candidate window (instead of last 3 words, use whole chunk? Must make sure we reindex correctly when appending to rows if length is less than expected)
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-try some other prompts post punctuation: summarize, simplify_ml (on an ml video)
-try out other tasks and add to prompts dir:
    -key point extraction
    -question generation

4/23/21
-------
~ -evaluate fuzzywuzzy realignment approach on a couple more chunks
~ -consider updating alignment func to update a chunk of a df instead of returning a new df?
    UPDATE: think it may be a good idea to write a class which maintains two copies of the df, original and punctuated. If the user asks for an overlapping chunk, maybe we can punctuate only the portion that needs it.
X -maybe update get_transcripts to check for british english manual transcripts (better than US generated + saves tokens)
X -add warnings to realignment func when max similarity score is low
-consider cleaning up text_segment and related funcs to act on whole sentences when possible

4/24/21
-------
~ -start designing obj that will track unpunct and punct dfs
    ~ -rewrite text_segment if necessary to (optionally?) return df slice/ids so we can avoid punctuating overlaps twice.
        UPDATE: currently returns relevant rows from df rather than str. May adjust interface as needed though.
    -consider cleaning up text_segment and related funcs to act on whole sentences when possible
X -add verbose option to load_prompt

4/25/21
-------
~ -continue building Transcript classes
    -rewrite text_segment if necessary to (optionally?) return df slice/ids so we can avoid punctuating overlaps twice.
    -add option to text_segment-related funcs to act on whole sentences when possible
    ~ -make unpunct transcript auto call gpt3 when accessing an unpunctuated chunk of df? First need a lot of scoping about desired interface.
        UPDATE: adding punctuated_chunk method which just is loc for PunctuatedTranscript and queries gpt3 for UnpunctTranscript. Mostly works but need to troubleshoot the update to self.df_punct (settingwithcopywarning caused error).

4/26/21
-------
~ -continue building Transcript classes
    X -fix settingwithcopyerror when punctuating part of df_punct
    X -rewrite time_segment/related methods to avoid re-punctuating rows we've already punctuated
    -add functionality to make text_segment-related funcs act on whole sentences when possible
-lots of docstrings to write for Transcript classes

4/27/21
-------
-continue building Transcript classes
    X -add option for time_segment to not punctuate text
    -consider: could we make text_segment-related funcs act on whole sentences when possible? generatedTrans can't determine this til after punctuation. Maybe we could select an extra wide window to be safe, punctuate it, and then select whole sentences? Or we could just simplify everything and punctuate the whole transcript from the start (either in chunks or all at once) at the cost of gpt3 tokens.
        -if possible and advisable, start building this functionality
    X -design interface for allowing multiple tasks post punct (just diff methods on generatedTranscript? Or allow user to pass in funcs somehow?)
        X -first draft of PromptManager class
        -select first task to try post-punctuation (maybe tldr?)
            _ -start building method
                UPDATE: new PromptManager class auto-loads all prompts in prompt dir so no need to do this.

4/28/21
-------
-revise PromptManager class
    ~ -add option to skip certain prompts or load dynamically?
        UPDATE: skip dynamic loading, but allow passing in a select number of prompts.
    ~ -clean up dynamic method generation (or find graceful way to do this)
-continue building Transcript classes
    -consider: could we make text_segment-related funcs act on whole sentences when possible? generatedTrans can't determine this til after punctuation. Maybe we could select an extra wide window to be safe, punctuate it, and then select whole sentences? Or we could just simplify everything and punctuate the whole transcript from the start (either in chunks or all at once) at the cost of gpt3 tokens.
        -if possible and advisable, start building this functionality
        -select first task to try post-punctuation (maybe tldr?)
-write draft of function to tie together Transcript.time_range() and PromptManager.query().

4/29/21
-------
-revise PromptManager class
    ~ -work on rigorous_partial issues in nb
        X -handling param order in cases it changes
        X -handling new kwargs
            UPDATE: tentatively mostly working? Need to stop it from mutating old func though.
    -update dynamic method generation in cls

4/30/21
-------
X -stop rigorous_partial from mutating original func (look at old copy_func func)
~ -test on more cases to see if it seems to work
    UPDATE: found and fixed bug where *args was handled incorrectly.
-add dynamic method generation to cls (hopefully going from func to method doesn't break anything)
-return to Transcript classes
    -consider: could we make text_segment-related funcs act on whole sentences when possible? generatedTrans can't determine this til after punctuation. Maybe we could select an extra wide window to be safe, punctuate it, and then select whole sentences? Or we could just simplify everything and punctuate the whole transcript from the start (either in chunks or all at once) at the cost of gpt3 tokens.

5/1/21
------
X -Fix newfound issue when sorting new_pars (instead of using x.default, maybe can use constant or index in old parms) if defaults have mixed types
X -test if renaming func works
    UPDATE: yes, but repr and str are not updated. Wrote class that can do this but haven't integrated it into the partial function yet. Might also provide a simpler way to do a lot stuff - not sure yet.
X -fix __defaults__ and __kwdefaults__ (only worked on wrapped func before)
-test on more cases to try to track down any other bugs
-add dynamic method generation to cls (hopefully going from func to method doesn't break anything)

5/2/21
------
X -revise partial func to use attach_repr
    UPDATE: technically didn't use attach_repr, but used same concept to update repr and str.
X -test on more cases to try to track down any other bugs
_ -add dynamic method generation to cls (hopefully going from func to method doesn't break anything)
    UPDATE: spent some time trying this but we still run into annoying issues (apparently generating methods always has these difficulties, even with functools version of partial). Decided it's good enough for now that I got Partial working and I should really just use a non-hacky method ('query' method) for this use case. No need to burn more GPT3 trial time on this.
X -port getindex
    _ -port attach_repr
        UPDATE: skip for now. Not really a common use case, I think.
    X -port rigorous_partial (rename?)
        UPDATE: renamed to Partial

5/3/21
------
X -finalize PromptManager
    X -port
-maybe clean up notebook a bit
-return to Transcript classes
    -consider: could we make text_segment-related funcs act on whole sentences when possible? generatedTrans can't determine this til after punctuation. Maybe we could select an extra wide window to be safe, punctuate it, and then select whole sentences? Or we could just simplify everything and punctuate the whole transcript from the start (either in chunks or all at once) at the cost of gpt3 tokens.
    -if possible and advisable, start building this functionality
    -select first task to try post-punctuation (maybe tldr?)
-write draft of function to tie together Transcript.time_range() and PromptManager.query().

5/4/21
------
X -maybe clean up notebook a bit
~ -return to Transcript classes
    X -consider: could we make text_segment-related funcs act on whole sentences when possible? generatedTrans can't determine this til after punctuation. Maybe we could select an extra wide window to be safe, punctuate it, and then select whole sentences? Or we could just simplify everything and punctuate the whole transcript from the start (either in chunks or all at once) at the cost of gpt3 tokens.
    ~ -if possible and advisable, start building this functionality
        UPDATE: trimmed off partial sentences at start, still need to do end.
    -select first task to try post-punctuation (maybe tldr?)
    X -update unpunct transcript class w/ promptmanager
    X -cleanup old code a bit
-write draft of function to tie together Transcript.time_range() and PromptManager.query().

5/5/21
------
X -trim off partial sentences from end of time_range_str
    -clean up methods/delete old code
    -test on generated transcript
-write draft of function/interface of some sort tying together transcript and external promptmanager
~ -flex task!: work on less fragile alternative to htools.Args
    UPDATE: see ipython session. Just need to test picklablility.

5/6/21
------
-debug time_range_str issue (not using punctuated rows but time_range is?)
    UPDATE: found bug cause (see nb03) but haven't fixed yet.
    -consider: add another option for punctuate (always, never, if_necessary)? Might be good to be able to be sure we can get an unpunctuated chunk sometimes.
    -clean up methods/delete old code
    -test on generated transcript
-write draft of function/interface of some sort tying together transcript and external promptmanager
X -flex task!: check Object picklability (see ipython session)
    UPDATE: fleshed out Object, renamed to Results, wrote barebones docs, fixed picklability

5/7/21
------
X -write module docstrings
    UPDATE: pretty sick so slept most of the day. Just spent a couple minutes knocking out an easy task.
X -find cause of readme updating issue
    UPDATE: need error handling in case dir has no relevant files. Check if df empty in self._parse_dir_files before sorting.
-consider desired behavior re time_range_str issue
    -consider: add another option for punctuate (always, never, if_necessary)? Might be good to be able to be sure we can get an unpunctuated chunk sometimes.
    -clean up methods/delete old code
    -test on generated transcript
-write draft of function/interface of some sort tying together transcript and external promptmanager

5/8/21
------
X -add error handling for empty dir in readme updater cli
~ -look into live speech recognition options with timestamps to extend beyond youtube
    UPDATE: pocketsphinx, but installing is proving to be a challenge. Come back to this later.
X -consider reorganizing lib structure (some utils probably belong in youtube or openai modules; part of core module belongs in openai and youtube modules)
X -fix time_range_str bug
    UPDATE: just add warning suggesting what to do.
X -fix text realignment bug
    UPDATE: thought I'd set max_tokens somewhere but maybe I deleted it. This meant we were only receving 50 tokens back from gpt3 but many more rows of df, so realignment wasn't working properly.
~ -consider desired behavior re time_range_str issue
    UPDATE: Think I should add an always/never/if_necessary option as suggested below. Haven't implemented yet though.
    -begin implementing
    -consider: add another option for punctuate (always, never, if_necessary)? Might be good to be able to be sure we can get an unpunctuated chunk sometimes.
    -clean up methods/delete old code
    -test on generated transcript
-write draft of function/interface of some sort tying together transcript and external promptmanager

5/9/21
------
X -add another option for punctuate (always, never, if_necessary)? Might be good to be able to be sure we can get an unpunctuated chunk sometimes.
    -clean up methods/delete old code
    -test on generated transcript
-write draft of function/interface of some sort tying together transcript and external promptmanager
-start basic gui
-watch sentdex video to see if that new nvidia package might be a good alternative to the annoyingly hard to install pocketsphinx

5/10/21
-------
X -add option/setting to avoid chopping off start/end of time_segment when fragment is sufficiently long? (Sometimes transcription fails or youtuber has a long run on sentence. Rather than throwing away 50 words (for ex), we might just want to keep it - we just don't want to feed a short meaningless fragment to gpt3).
X -add method to get punctuated indices of transcript
    X -method to get unpunct indices
    X -method to get punct rows
    X -move na_index_rows from staticmethod to function

5/11/21
-------
X -try out various transcript options
    X -passing in different kwargs (e.g. engine_i)
    X -try mock mode
        X -add option for different mock modes in query_gpt3
        X -write mock func for punctuate task
        X -method to reset punct df (useful after mocked calls. Considered making mock calls not update df_punct but that prevents us from testing side effects.)
    X -fix bug where punctuated_rows called unpunct df
_ -clean up nb
    UPDATE: skip, these are all just dev notebooks at this point, not anything polished to display somewhere.
X -port to lib
    ~ -document

5/12/21
-------
X -select first task to try post-punctuation (maybe tldr?)
    UPDATE: didn't work that well. Even the punctuation task alone is struggling. Thinking it may not have been a great idea to work on transcripts - prompt engineering guide specifically mentioned any typos or grammatical errors make it hard to get good responses.
X -write draft of function to tie together Transcript.time_range() and PromptManager.query().
    UPDATE: started session class to handle multiple videos. Thinking we might want to look for backup tasks (identifying similar videos?) in case running standard queries (e.g. tldr, eli5) on the transcripts doesn't work so well.
-choose: desktop gui, mobile, or web? (web makes most sense but part of the point of this project was supposed to be learning one of the others. Maybe start with desktop for learning purposes and if it ends up being particularly cool, I could always rebuild a simple streamlit app.)
    UPDATE: choosing desktop gui. Just want to learn here, even if it's not as practical for sharing as a web app. And initial results are not promising so that probably won't be a concern anyway.
    -maybe start building? Might be good to set up a UI early for easy experimentation.

5/13/21
-------
-consider if there's anything else worth adding to Session
    -port
-code to find videos w/ transcripts? Maybe just try to avoid punctuation task for now.
~ -start building desktop gui
-easier options: document Session
    -document Transcript methods

5/14/21
-------
X -work through rest of dearpygui video
    ~ -look through available widgets and see if it sparks any interesting ideas
X -add microphone recording option to app
X -add skeleton button to punctuate text

5/15/21
-------
X -figure out how to change labels (don't want element id's to be shown as text to user)
    UPDATE: fixed for buttons. Input_text label suppression seems a little hacky but I think it's how the lib intends us to do it.
~ -add menu bar
    UPDATE: layout/alignment still a work in progress.
X -refactor transcribe callback_data
    UPDATE: now can pass in as many ids to show during/after as we want.
X -try adding tooltip
    UPDATE: a little wonky (must use context manager) but it seems to work.
-add option to gpt3 punctuate text?
-add buttons/dropdown menu/etc. for different tasks (keypoints, eli5, summarize, fancier language, etc.)
-look into possibility of longer mic sessions (don't immediately stop at first pause)
    -maybe can translate as we go in a different thread or something? Ideally would be able to make request to google api while user is still talking and process in chunks.

5/16/21
-------
X -add buttons/dropdown menu/etc. for different tasks (keypoints, eli5, summarize, fancier language, etc.)
-add option to gpt3 punctuate text?
-look into possibility of longer mic sessions (don't immediately stop at first pause)
    -maybe can translate as we go in a different thread or something? Ideally would be able to make request to google api while user is still talking and process in chunks.

5/17/21
-------
X -clean up layout and make more flexible
    X -methods to calculate heights/widths
    X -callback to adjust these when window is resized
    -rename windows (would prefer to find way to separate id and label, but I don't think that's available)
-add query button
-look into issue of all text being displayed on same line in text input
-aesthetic improvements
    -diff font?
    -diff font size?
-add prompt warning (if exists) after selecting a task
-add query button
    -add query callback to actually query gpt3 and update output text

5/18/21
-------
X -port Session
X -put prompt text last after other options.
_ -format so no long horizontal scrollbar.
    UPDATE: not supported by dearpygui. Could write a function to break text into fixed length pieces but that's a bit annoying since with text box width is also variable.
X -update options callback to update value when prompt changes.
-rename windows (would prefer to find way to separate id and label, but I don't think that's available)
X -add query button
    X -add query callback to actually query gpt3 and update output text

5/19/21
-------
X -generalize query_callback so it works on passed in data rather than hardcoded IDs
-see if we can add places to enter options like:
    -mock_fn
    -stop_terms (name might be wrong here)
X -make transcription finish trigger update of options (prompt needs to be reformatted)
-add warning in case you try to query with empty text for a prompt that needs input
X -investigate bug where options are no longer updated with each task selection.

5/20/21
-------
X -see if we can add places to enter options like:
    _ -mock_fn
    UPDATE: I think this is only necessary for transcript. Fine to leave out for now.
    X -stop_terms (name might be wrong here)
-add warning in case you try to query with empty text for a prompt that needs input
-consider how we might support other (non-gpt3) tasks
    -what tasks might those be? (translation package, huggingface pretrained models (see py_project.txt notes)
    -how to show in gui? Probably ideal to have all tasks together but maybe it would be okay to separate them from gpt3 since options might be different.
    -could update manager class to support this? Would be a bit messy.
X -prevent user moving/resizing windows?
X -redo layout so options gets full height
-see if there's a way so manually typing input in record box (and then moving focus or something) can trigger options update too. This would also be useful if the user manually cleans up the punctuation after recording.
-add more voice interface features:
    -read gpt3 output
    -allow voice commands? E.g. say "Task: Summarize. Input: ..."

5/21/21
-------
X -add new font
    X -adjust font size
-see if there's a way so manually typing input in record box (and then moving focus or something) can trigger options update too. This would also be useful if the user manually cleans up the punctuation after recording.
X -add output audio (see old translation file)
X -fix bug where empty stop param is list when openai expects None
-add warning from a prompt's config file in options window
-add warning in case you try to query with empty text for a prompt that needs input
-consider image task tie-ins
    -consider ways to interact with internet (i.e. scrape some data based on gpt3 response?)

5/22/21
-------
X -get voice response working (put in thread?)
    UPDATE: tried threads but it sounds like there may be a threading issue on mac specifically. Found workaround using builtin mac os functionality.
X -adjust speaking pace
-maybe make it so we can choose a voice in the app?
-see if there's a way so manually typing input in record box (and then moving focus or something) can trigger options update too. This would also be useful if the user manually cleans up the punctuation after recording.
-add warning in case you try to query with empty text for a prompt that needs input

5/23/21
-------
X -see if we can add slight pauses on newlines when reading responses
X -consider adjusting pace a little
-consider removing auto-punct button since it's already available in prompts? Or remove from prompts menu?
-maybe make it so we can choose a voice in the app?
X -see if there's a way so manually typing input in record box (and then moving focus or something) can trigger options update too. This would also be useful if the user manually cleans up the punctuation after recording.
-add warning in case you try to query with empty text for a prompt that needs input

5/24/21
-------
X -work on prompt mapping term to ELI5 (or an average high schooler, really) passage
    UPDATE: tried mapping term to metaphor, but haven't been able to get this working well yet. Mapping idea (basically a simplified TLDR from semantic scholar) to abstract works reasonably well, however. Unfortunately, abstracts are usually not technically detailed enough for this to be particularly useful as a brainstorming technique.
    X -add this option to gui and experiment
-Think about how we might add a gui option for URL entry (youtube video, arxiv paper, etc.). Might need a menu that allows us to open a separate window since the expected workflow is a bit different (fetch text from URL rather than operate on input directly.)
-consider removing auto-punct button since it's already available in prompts? Or remove from prompts menu?
-add warning in case you try to query with empty text for a prompt that needs input

5/25/21
-------
~ -try gpt neo in colab
    UPDATE: crashed colab due to ram limit. Put on hold in favor of Huggingface api.
X -try huggingface api
~ -start building query_gpt_neo function

5/26/21
-------
X -update query_gpt_neo func
    UPDATE: Found and fixed some bugs. Most importantly, we were passing in parameters wrong which caused them to be ignored.
    _ -work on different length responses (seems to return slightly different format depending on max_tokens)
        UPDATE: This should only happen if we pass in a list of input strings, which I don't do with this interface.
    X -make interface more compatible w/ query_gpt_3?
        UPDATE: made it work as a mock_func.
    X -consider interface: should we hide this inside query_gpt3 (basically another mock mode option) or make interfaces identical so we can swap out functions interchangeably?
        X -work on implementing changes
~ -add gpt neo option to gui
    UPDATE: hardcoded for now when user selects mock mode. Eventually, might want to distinguish between a truly mocked call (faster) and neo.

5/27/21
-------
X -better error handling for query_neo (see error message in pycharm console) 
    UPDATE: also found and fixed bug w/ max_token len and identified possible cause of api errors (input is too long - tried to test this but then started getting errors about rate limits, which is odd because I'm nowhere near the documented limit).
~ -experiment with other information seeking task
    UPDATE: see misc

5/28/21
-------
X -create file to track tough google searches and the ultimately helpful piece of information
X -gui options for true mock call vs. neo call.
    UPDATE: collapsed mock checkbox and model options into one radio button list.
~ -make speech interruptable
    UPDATE: set default to off for dev purposes. Also started building interruptable decorator in ipython session.
X -show more graceful error message in gui if response fails for some reason (or maybe w/ my new error handling in query func this is unlikely enough that it basically never hapepns? Assess.)
X -tweak "how to" prompt params
    UPDATE: higher model, longer length, new stop_word
-make gui show when response is in progress (sometimes unsure if click didn't work or if response is just slow)
-check if we do any auto-updating of max_tokens in query manager when task is Punctuate (pretty sure we don't)
    -maybe adapt logic from UnpunctuatedTranscript to GUI: i.e. if we punctuate, we want the output to be the appropriate length.
-document gpt neo (maybe can largely copy from query_gpt3 or use add_docstring decorator.

5/29/21
-------
X -interruptable decorator
    ~ -test with @callback
        X -consider integrating callbacks natively? So use just 1 deco, not 2.
    X -port to htools
    ~ -integrate into GUI/speaker class to allow speech interrupt
 -make gui show when response is in progress (sometimes unsure if click didn't work or if response is just slow)
-check if we do any auto-updating of max_tokens in query manager when task is Punctuate (pretty sure we don't)
    -maybe adapt logic from UnpunctuatedTranscript to GUI: i.e. if we punctuate, we want the output to be the appropriate length.
-document gpt neo (maybe can largely copy from query_gpt3 or use add_docstring decorator.

5/30/21
-------
X -integrate into GUI/speaker class to allow speech interrupt
    X -troubleshoot threading issues: seems that each callback is run in a separate thread and it's tricky to propagate an exception from one thread to another
-make gui show when response is in progress (sometimes unsure if click didn't work or if response is just slow)
-check if we do any auto-updating of max_tokens in query manager when task is Punctuate (pretty sure we don't)
    -maybe adapt logic from UnpunctuatedTranscript to GUI: i.e. if we punctuate, we want the output to be the appropriate length.
-document gpt neo (maybe can largely copy from query_gpt3 or use add_docstring decorator.

5/31/21
-------
X -clean up code a bit after speaker interrupt ordeal
    X -document new funcs
X -make gui show when response is in progress (sometimes unsure if click didn't work or if response is just slow)
-check if we do any auto-updating of max_tokens in query manager when task is Punctuate (pretty sure we don't)
    -maybe adapt logic from UnpunctuatedTranscript to GUI: i.e. if we punctuate, we want the output to be the appropriate length.
X -document gpt neo (maybe can largely copy from query_gpt3 or use add_docstring decorator.
~ -start generic monitor class (see ipy session)

6/1/21
------
X -check if we do any auto-updating of max_tokens in query manager when task is Punctuate (pretty sure we don't)
    X -maybe adapt logic from UnpunctuatedTranscript to GUI: i.e. if we punctuate, we want the output to be the appropriate length.
X -consider removing auto-punct button since it's already available in prompts? Or remove from prompts menu?
    UPDATE: removed. Updated transcribe task and get_query_kwargs method to do some light autoformatting.
X -add vanilla gpt3 prompt (no instructions, no specific task, just give it some text and let it talk for a bit)
-add chatbot prompt
-add translation prompt?
-continue work on more generic Monitor class for htools

6/2/21
------
X -add tooltips to everything
X -fix bug where empty default task resulted in a colon
-increase max tokens (gpt3 allows up to 2048 between input+output, though neo allows only up to 250 token outputs)

6/3/21
------
-investigate possible bug where manually updating a setting sometimes resets other settings (seems to happen when you type in a number for max_tokens but not when you adjust it with arrow keys)
-investigate and fix possible bug where vanilla query seems to replace apostrophes with question marks
-prototype chatbot prompt
X -build steelman prompt
    X -add config and prompt files to data/prompts dir
    X -integrate into UI
X -fix bug in speaker where hyphens are still interpreted as CLI flags
~ -start looking into potential slack app
-prototype translation prompt
-continue work on more generic Monitor class for htools

6/4/21
------
X -consider ways to avoid unwanted pauses after periods in words like U.S.A.
X -prototype MMA fight predictor prompt
    X- add files to data/prompts dir
    X -integrate into UI
X -investigate and fix possible bug where vanilla query seems to replace apostrophes with question marks

6/5/21
------
~ -prototype "slack replier" prompt
    UPDATE: tried a bit but realized I blocked slack and it's harder without sample messages. Maybe try again tomorrow.
X -prototype translation prompt
    X -update config/prompt files
    X -add to UI
-record some mma examples (text? silent gif? video with audio?)
-investigate possible bug where manually updating a setting sometimes resets other settings (seems to happen when you type in a number for max_tokens but not when you adjust it with arrow keys)
-see if slack app is a possibility (do I have auth to do in GG workspace?)
X -explore possiblity of scraping pro/con website for t5-like dataset.
    UPDATE: No api, but it does look fairly scrapable. Only ~100 issues though, it seems.
-maybe manually add 1 more example to debate prompt to see if it improves response quality? Does mean queries would be more token-intensive though.

6/6/21
------
~ -prototype "slack replier" prompt
    UPDATE: still couldn't find that many great examples. Maybe keep an eye out for useful data that comes up organically in the future.
~ -prototype chat w/ various public figures
    UPDATE: Tried with a few and results were decent. Worth pursuing further.
~ -write basic func to get wiki summary about a person
    UPDATE: still some improvements to be made.
X -prototype writing analyzer prompt, add data files, add to UI
    UPDATE: examples probably could be better - this seems to fixate more on author emotion/feelings than writing style
-prototype cover letter writer from job posting
-record some mma examples (text? silent gif? video with audio?)
-investigate possible bug where manually updating a setting sometimes resets other settings (seems to happen when you type in a number for max_tokens but not when you adjust it with arrow keys)
-see if slack app is a possibility (do I have auth to do in GG workspace?)
-maybe manually add 1 more example to debate prompt to see if it improves response quality? Does mean queries would be more token-intensive though.

6/7/21
------
X -make wiki_summary func more robust
    X -handle situation where page not found
    _ -handle situation where wiki page is disambiguation page (idea for both: ask user for optional *tags args. On disambiguation page, look for semantically similar person. E.g. if I search wiki_summary('john smith', 'wrestling') that should let me find an article named something like 'John_Smith_(Collegiate_Wrestler)'. For case where no disambiguation page, we could try googling 'john smith wrestling wikipedia' and see if something comes up)
        UPDATE: think this isn't necessary with current solution - I'll never intentionally search for a disambiguation page and I skip them in search results. Worked on the google search approach a bit but decided wikipedia api was more reliable and more stable for the future.
    X -add img downloading functionality

6/8/21
------
X -improve text cleanup in wiki summary (name pronunciations don't always parse to the same char; need something more generic to find junk after parenthesis)
    X -select best image
    X -validate page is a reasonable match
    X -port 
    -document
    -see how to load image in gui
-figure out how to integrate conversation prompt into gui
    -consider how we might allow for an ongoing conversation - maybe there should be a single text input field instead of 2?
-investigate possible bug where manually updating a setting sometimes resets other settings (seems to happen when you type in a number for max_tokens but not when you adjust it with arrow keys)

6/9/21
------
~ -document wiki funcs
X -figure out how to make conversation prompt work w/ current setup (may need to add hook func so user to call when loading)
    UPDATE: added option to provide custom formatter. Not the most elegant but seems workable so far.
    ~ -figure out how to integrate conversation prompt into gui
        UPDATE: Sort of works, but I think we might be calling wiki_data every time the user types a character, horribly gumming up the app. Need to work on this.
    -consider how we might allow for an ongoing conversation - maybe there should be a single text input field instead of 2?
-see how to load image in gui
-investigate possible bug where manually updating a setting sometimes resets other settings (seems to happen when you type in a number for max_tokens but not when you adjust it with arrow keys)
X -flex task: monitor_time decorator (see ipython session)

6/10/21
-------
-update gui so conversation wiki_summary isn't run repeatedly (remove reliance on promptmanager.kwargs? Or somehow cache results? Or logic to wait several seconds after user stops typing?)
-consider how we might allow for an ongoing conversation - maybe there should be a single text input field instead of 2?
-investigate possible bug where manually updating a setting sometimes resets other settings (seems to happen when you type in a number for max_tokens but not when you adjust it with arrow keys)
X -see how to load image in gui
X -add frequency_penalty to query_gpt3
X -add freq penalty to conversation default config
X -make conversation formatter sentence tokenize more reliably (prev didn't support names like Dr. Seuss or J.K. Rowling).
X -func to get most recently edited path in dir (workaround for lack of access to downloaded img url)
X -port monitor_time deco
    X -document

6/11/21
-------
-update img size
-consider how we might allow for an ongoing conversation - maybe there should be a single text input field instead of 2? Do we need multiple windows/tabs or change window depending on settings?
-update gui so conversation wiki_summary isn't run repeatedly (remove reliance on promptmanager.kwargs? Or somehow cache results? Or logic to wait several seconds after user stops typing?)
-investigate possible bug where manually updating a setting sometimes resets other settings (seems to happen when you type in a number for max_tokens but not when you adjust it with arrow keys)


-------------------------------------------------------------------------------
easy tasks for low energy days

- artbreeder tutorial
- lots of waiting docs in core.py
- dearpygui videos tutorials (https://github.com/hoffstadt/DearPyGui/wiki/Video-Tutorials):
    -parent stack system
    -callbacks
    -value storage system

-------------------------------------------------------------------------------
backlog

-see if slack app is a possibility (do I have auth to do in GG workspace?)
-record some mma examples (text? silent gif? video with audio?)
-prototype cover letter writer from job posting
-continue work on more generic Monitor class for htools
-add chatbot prompt
    -consider how we might enable a more conversational mode, with multiple user input/gpt3 response pairs over time.
-Think about how we might add a gui option for URL entry (youtube video, arxiv paper, etc.). Might need a menu that allows us to open a separate window since the expected workflow is a bit different (fetch text from URL rather than operate on input directly.)
-add warning in case you try to query with empty text for a prompt that needs input
-add warning from a prompt's config file in options window
-consider image task tie-ins
    -consider ways to interact with internet (i.e. scrape some data based on gpt3 response?)
-consider how we might support other (non-gpt3) tasks
    -how to show in gui? Probably ideal to have all tasks together but maybe it would be okay to separate them from gpt3 since options might be different.
-add more voice interface features:
    -allow voice commands? E.g. say "Task: Summarize. Input: ..."
-rename windows (would prefer to find way to separate id and label, but I don't think that's available)
-document session
-document transcript methods
-code to find videos w/ transcripts? Maybe just try to avoid punctuation task for now.
-try out eleuther ai model (is it a viable alternative, at least to engine_i=0? Is it too big to load in a reasonable period of time? Are there existing apis hosting it?)
    -same for big gpt2 model? I think that does have free apis hosting it but doesn't really have the same prompt response functionailty.
-watch sentdex video to see if that new nvidia package might be a good alternative to the annoyingly hard to install pocketsphinx
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-try some other prompts post punctuation: summarize, simplify_ml (on an ml video)
-try out other tasks and add to prompts dir:
    -key point extraction
    -question generation
-re-watch dall-e video
-add booste config file to paperspace
-look through and/or download coursera video gan notebook
-look through instructions/demo for voice cloning app - how much audio do we need? Does it need to be custom or could I plausibly find enough for a famous person?
-try chronology lib
-try booste lib
