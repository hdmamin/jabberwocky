4/9/21
------
X -update cookiecutter template makefile and notes files
X -choose project name
X -final investigation of dearpygui vs kivy (+kivymd)
    [dearpygui mobile won't be ready in time. Use this if you want to build a desktop app, use kivy if you want to build mobile. Leaning mobile - dearpygui looks cool but I feel if I'm going to do something non-streamlit/dash, I should make it REALLY different. I'm now thinking the gans could be a problem though - gpt3 is just an api so that's fine, but I'd need to host the gans somewhere. This is meant to be pretty open ended though so I could do gan stuff on paperspace and then a voice app or something else for mobile (spoken/written bullet points -> speech in my voice?). Time may be a constraint though if I try to do both - gpt3 trial expires at end of June. Maybe learning fund can help out there.]
X -make new git project
X -write project requirements
X -write premortem
-write lessons from last time

4/10/21
-------
X -write lessons from last time
    X -documented various project ideas
    X -looked through openai repos for more ideas. Briefly tried out dall-e notebook.
X -try out openai pypi package to make sure I can communicate w/ gpt3 programmatically
    -if necessary, write my own helper functions to wrap common actions
X -choose method of loading api key and write func
    [dotfile or env var both supported]
X -define constants to easily access engine names by index and view prices
X -watch video on sirens (in this context, basically a way to create better combinations of inputs (e.g. images) than simple interpolation)
X -run dall-e and deep-daze demo notebooks in colab
-look into how to use various gan packages (install? clone?)
-make sure I can still access paperspace
    -maybe update dotfiles/envs etc. on machine if necessary

4/11/21
-------
-try out chronology lib for programmatic gpt3 access and see if it looks helpful compared to openai lib
    -if necessary, write my own helper functions to wrap common actions
    X -try a couple simple requests
X -make sure I can still access paperspace
    X -maybe update dotfiles/envs etc. on machine if necessary
    X -copy over openai dotfile
    X -create new machine and configure (some things changed)
        X -test that gpu is available
X -create prompts dir and write func to load_prompt
    X -allow data/prompts subdir in git (not very big)
X -write helper to print prompt in bold and resp in normal text
X -add jabberwocky imports to template nb
X -re-watched kilcher Clip video
-choose a first use case to work on
    -download/install a gan package?

4/12/21
-------
~ -more api exploration
    -try out chronology lib for programmatic gpt3 access and see if it looks helpful compared to openai lib
    -if necessary, write my own helper functions to wrap common actions
    ~ -check if there's a free gpt2 endpoint?
        [pypi library booste. API key is in gmail 55.]
        ~ -if not, maybe create mock request func to save credits (though ada is pretty cheap)
X -try free content filter in openai api
    X -write wrapper
X -udpate openai_auth func to set key automatically
X -finish signup for booste lib
-choose a first use case to work on
    -download/install a gan package?

4/13/21
-------
-try chronology lib
X -write booste api key loading func
X -port and finalize text_segment func for youtube transcription idea
X -document functions in utils
X -finish query_gpt3 func
    X -how to handle logprobs?
        [Just let user choose to return everything if they want.]
    X -try stream=True
        -write generator version of query_gpt3 (func must be one or the other)
    -add tab completion for extra params? Would take some py magic
X -create even shorter prompt to save tokens
X -port query_content_filter func
    X -finish documenting
-re-watch dall-e video

4/14/21
-------
X -port query_gpt3
    X -document
    X -save sample response and use it for better mocking
    X -write generator version of query_gpt3 (func must be one or the other)
        X -port and document
    -tab completion magic?
-try chronology lib
-try booste lib
-re-watch dall-e video

4/15/21
-------
_ -tab completion magic for query_gpt3 and generator?
    UPDATE: looked into this but doesn't look like openai api includes this anywhere. Good enough - I included the major kwargs.
X -rewrite 2 query functions into 1 merged function (stream=True returns a generator rather than yielding values)
-try chronology lib
-try booste lib
-look through misc.txt notes and decide on a first use case to try
    -if videos, start messing around with youtube transcription package
    -if gans, select a gan to start with and look into download/installation (dall-e, deep daze, etc.)
-re-watch dall-e video

4/16/21
-------
X -look through misc.txt notes and decide on a first use case to try (leaning heavily towards youtube transcription-related stuff)
    UPDATE: start with youtube transcription stuff. The jabberwocky name may make less sense here, as does the supposed requirement for a mobile/desktop app. I suppose if really necessary I could always push my gan mobile app to a separate project - probably easier to justify gpt3 payment if I demo something useful first.
~ -if youtube, start messing around with youtube transcription package
    ~ -do all/most videos have transcripts?
        UPDATE: I think all/most have auto-generated transcripts, but relatively few have manually generated ones.
    _ -maybe wrap text_segment func to work if we want the PREV n seconds instead of specifying start/end
        UPDATE: unnecessary atm. We can make the user facing version ask for last n seconds, but for now it makes sense to keep it this way.
    -try out "explain to a fifth grader" etc. prompts from docs
    -save some in prompts dir
    -consider cleaning up text_segment and related funcs to act on whole sentences when possible
-if gans, select a gan to start with and look into download/installation (dall-e, deep daze, etc.)

4/17/21
-------
X -try out "explain to a fifth grader" etc. prompts from docs
    X -save some in prompts dir
    X -try tuning ML simplifier prompt
    -consider cleaning up text_segment and related funcs to act on whole sentences when possible
-try some format fixing prompts (autogenerated -> manual transcript. Maybe use chunks from different videos to get some variety. This idea alone actually seems pretty powerful - a way to rapidly improve quality of speech to text.)

4/18/21
-------
X -save more generic ELI5 prompt (mine is very ml-focused. They provide a good jupiter example.)
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
X -update or write new load_prompt func:
    X -some prompts should allow us to embed input text into them (e.g. rather than being static like short_dates, we want to show a few examples (saved in txt file) and then append our new piece of text to generate based on)
    X -store recommended kwargs for calling query_gpt3 (e.g. simplify_ml really requires davinci to work well. Stop sequence should be specified as well.)
    X -add kwarg info to data dir (single json file mapping file name to kwargs? Or make each prompt file a txt/yaml file containing multiple fields?)
        UPDATE: give each prompt a subdir with a config.yaml file and prompt.txt file. Reasons in load_prompt func.
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
-try some format fixing prompts (autogenerated -> manual transcript. Maybe use chunks from different videos to get some variety. This idea alone actually seems pretty powerful - a way to rapidly improve quality of speech to text.)

4/19/21
-------
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
    X -error checking for times
X -try some format fixing prompts (autogenerated -> manual transcript. Maybe use chunks from different videos to get some variety. This idea alone actually seems pretty powerful - a way to rapidly improve quality of speech to text.)
    UPDATE: not perfect but this generally works quite well.
    X -try chaining <PUNCTUATE> - <ELI>
        UPDATE: didn't work very well. Maybe the input passage was too simple already, or maybe we need to provide a few examples from youtube transcripts.
X -add some printed outputs to get_transcripts() so I don't always have to check which are None
X -update load_prompt to separate printed reminder from main prompt

4/20/21
-------
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
    ~ -consider: add punctuation once (to whole transcript) or add it to a small segment each time we ask for a summary/eli5 etc?
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-try some other prompts post punctuation: summarize, simplify_ml (on an ml video)
-try out other tasks and add to prompts dir:
    -key point extraction
    -question generation

4/21/21
-------
~ -continue working on func to re-map punctuated text to timestamps. (Even if we don't do this all at once, we should probably cache results from translating chunks.)
    X -try re.split in place of split
    X -add strip results option to query_gpt3 (and prompt config files)
    X -try fuzzywuzzy-based approach to realignment
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-try some other prompts post punctuation: summarize, simplify_ml (on an ml video)
-try out other tasks and add to prompts dir:
    -key point extraction
    -question generation

4/22/21
-------
X -continue working on func to re-map punctuated text to timestamps. (Even if we don't do this all at once, we should probably cache results from translating chunks.)
    -evaluate fuzzywuzzy realignment approach on a couple more chunks
    -consider ways to improve:
        X -bigram similarity instead of single word
        X -wider candidate window (instead of last 3 words, use whole chunk? Must make sure we reindex correctly when appending to rows if length is less than expected)
-consider cleaning up text_segment and related funcs to act on whole sentences when possible
-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-try some other prompts post punctuation: summarize, simplify_ml (on an ml video)
-try out other tasks and add to prompts dir:
    -key point extraction
    -question generation

4/23/21
-------
~ -evaluate fuzzywuzzy realignment approach on a couple more chunks
~ -consider updating alignment func to update a chunk of a df instead of returning a new df?
    UPDATE: think it may be a good idea to write a class which maintains two copies of the df, original and punctuated. If the user asks for an overlapping chunk, maybe we can punctuate only the portion that needs it.
X -maybe update get_transcripts to check for british english manual transcripts (better than US generated + saves tokens)
X -add warnings to realignment func when max similarity score is low
-consider cleaning up text_segment and related funcs to act on whole sentences when possible

4/24/21
-------
~ -start designing obj that will track unpunct and punct dfs
    ~ -rewrite text_segment if necessary to (optionally?) return df slice/ids so we can avoid punctuating overlaps twice.
        UPDATE: currently returns relevant rows from df rather than str. May adjust interface as needed though.
    -consider cleaning up text_segment and related funcs to act on whole sentences when possible
X -add verbose option to load_prompt

4/25/21
-------
~ -continue building Transcript classes
    -rewrite text_segment if necessary to (optionally?) return df slice/ids so we can avoid punctuating overlaps twice.
    -add option to text_segment-related funcs to act on whole sentences when possible
    ~ -make unpunct transcript auto call gpt3 when accessing an unpunctuated chunk of df? First need a lot of scoping about desired interface.
        UPDATE: adding punctuated_chunk method which just is loc for PunctuatedTranscript and queries gpt3 for UnpunctTranscript. Mostly works but need to troubleshoot the update to self.df_punct (settingwithcopywarning caused error).

4/26/21
-------
~ -continue building Transcript classes
    X -fix settingwithcopyerror when punctuating part of df_punct
    X -rewrite time_segment/related methods to avoid re-punctuating rows we've already punctuated
    -add functionality to make text_segment-related funcs act on whole sentences when possible
-lots of docstrings to write for Transcript classes

4/27/21
-------
-continue building Transcript classes
    X -add option for time_segment to not punctuate text
    -consider: could we make text_segment-related funcs act on whole sentences when possible? generatedTrans can't determine this til after punctuation. Maybe we could select an extra wide window to be safe, punctuate it, and then select whole sentences? Or we could just simplify everything and punctuate the whole transcript from the start (either in chunks or all at once) at the cost of gpt3 tokens.
        -if possible and advisable, start building this functionality
    X -design interface for allowing multiple tasks post punct (just diff methods on generatedTranscript? Or allow user to pass in funcs somehow?)
        X -first draft of PromptManager class
        -select first task to try post-punctuation (maybe tldr?)
            _ -start building method
                UPDATE: new PromptManager class auto-loads all prompts in prompt dir so no need to do this.

4/28/21
-------
-revise PromptManager class
    -add option to skip certain prompts or load dynamically?
    -clean up dynamic method generation (or find graceful way to do this)
-continue building Transcript classes
    -consider: could we make text_segment-related funcs act on whole sentences when possible? generatedTrans can't determine this til after punctuation. Maybe we could select an extra wide window to be safe, punctuate it, and then select whole sentences? Or we could just simplify everything and punctuate the whole transcript from the start (either in chunks or all at once) at the cost of gpt3 tokens.
        -if possible and advisable, start building this functionality
        -select first task to try post-punctuation (maybe tldr?)
-write draft of function to tie together Transcript.time_range() and PromptManager.query().

-------------------------------------------------------------------------------
easy tasks for low energy days

- artbreeder tutorial

-------------------------------------------------------------------------------
backlog

-start tuning some custom prompts based on youtube transcripts (realized even academic lectures tend to have much more informal language than written papers)
-try some other prompts post punctuation: summarize, simplify_ml (on an ml video)
-try out other tasks and add to prompts dir:
    -key point extraction
    -question generation
-re-watch dall-e video
-add booste config file to paperspace
-look through and/or download coursera video gan notebook
-review kilcher videos on dall-e, maybe other gans
-look through instructions/demo for voice cloning app - how much audio do we need? Does it need to be custom or could I plausibly find enough for a famous person?
-try chronology lib
-try booste lib
