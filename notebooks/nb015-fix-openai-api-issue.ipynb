{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Recently (possibly since upgrading to openai 0.18.1?), querying openai causes invalid URL errors. Here are some notes from yesterday's troubleshooting session.\n",
    "\n",
    "- curl works, python doesn't.\n",
    "- Not just codex, now nox openai engines work w/ python. Maybe due to updating pip package? Temporarily upped billing limit to try other models.\n",
    "- Restarted kernel and gpt query works again w/ ada. BUT after I import openai explicitly, that fails too. That must be a clue.\n",
    "- Tried uninstalling, reinstalling, opened new tmux pane. Still same error.\n",
    "- Tried deleting 'openai' object and then importing jabberwocky. This does work!?\n",
    "- If I re-import openai after that, gpt.query still works. But openai.completion while codex does not.\n",
    "- If I import openai FROM jabberwocky openai_utils, codex query still fails. But gpt.query works. And openai.Completion works w/ engine ada!\n",
    "- Conclusion: maybe it is codex-specific then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:25.833217Z",
     "start_time": "2022-04-26T02:42:25.797726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.330949Z",
     "start_time": "2022-04-26T02:42:26.656974Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.367973Z",
     "start_time": "2022-04-26T02:42:28.333268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.417512Z",
     "start_time": "2022-04-26T02:42:28.374347Z"
    }
   },
   "outputs": [],
   "source": [
    "j_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine_i': 0}\n",
    "ada_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine': 'text-ada-001'}\n",
    "code_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine': 'code-davinci-001'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jabberwocky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:29.898711Z",
     "start_time": "2022-04-26T02:42:29.089044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key, \\\n",
    "    GPTBackend\n",
    "import jabberwocky.openai_utils as oautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:34.484408Z",
     "start_time": "2022-04-26T02:42:34.440337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBackend <current_name: openai>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:35.320532Z",
     "start_time": "2022-04-26T02:42:34.868415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_tokens': 1, 'engine_i': 0, 'prompt': 'a', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Mon Apr 25 19:42:34 2022'}}\n"
     ]
    }
   ],
   "source": [
    "res = gpt.query(**j_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:35.981679Z",
     "start_time": "2022-04-26T02:42:35.923931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([''],\n",
       " [{'text': '\\n',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length',\n",
       "   'prompt_index': 0}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai 0.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:37.398887Z",
     "start_time": "2022-04-26T02:42:37.362213Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:37.674368Z",
     "start_time": "2022-04-26T02:42:37.636416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:38.646957Z",
     "start_time": "2022-04-26T02:42:38.600483Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/hmamin/.openai', 'r') as f:\n",
    "    openai.api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:39.149616Z",
     "start_time": "2022-04-26T02:42:39.118576Z"
    }
   },
   "outputs": [],
   "source": [
    "# oautils.openai == openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:42.511652Z",
     "start_time": "2022-04-26T02:42:41.097177Z"
    }
   },
   "outputs": [],
   "source": [
    "res = openai.Completion.create(**code_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:43.073351Z",
     "start_time": "2022-04-26T02:42:43.036388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-515RxlKh9094yUQFyFqI4pVMKtjrV at 0x11f6c0b48> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"nt\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1650940961,\n",
       "  \"id\": \"cmpl-515RxlKh9094yUQFyFqI4pVMKtjrV\",\n",
       "  \"model\": \"code-davinci:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai 0.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:50.585914Z",
     "start_time": "2022-04-26T02:42:50.547720Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:50.747586Z",
     "start_time": "2022-04-26T02:42:50.707083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:11.939142Z",
     "start_time": "2022-04-26T02:33:11.888709Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/hmamin/.openai', 'r') as f:\n",
    "    openai.api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:16.525379Z",
     "start_time": "2022-04-26T02:33:16.482091Z"
    }
   },
   "outputs": [],
   "source": [
    "# oautils.openai == openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:21.766693Z",
     "start_time": "2022-04-26T02:33:18.368577Z"
    }
   },
   "outputs": [],
   "source": [
    "res = openai.Completion.create(**code_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:22.601648Z",
     "start_time": "2022-04-26T02:33:22.568651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-515ItOmu7H4oHPA2yyDXpfHpteeby at 0x1245a1bf8> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1650940399,\n",
       "  \"id\": \"cmpl-515ItOmu7H4oHPA2yyDXpfHpteeby\",\n",
       "  \"model\": \"code-davinci:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:54.236780Z",
     "start_time": "2022-04-24T22:42:53.572476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key, \\\n",
    "    GPTBackend\n",
    "import jabberwocky.openai_utils as oautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:55.862716Z",
     "start_time": "2022-04-24T22:42:55.822807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBackend <current_name: openai>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:59.158100Z",
     "start_time": "2022-04-24T22:42:58.972217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_tokens': 1, 'engine_i': 0, 'prompt': 'a', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Sun Apr 24 15:42:59 2022'}}\n"
     ]
    }
   ],
   "source": [
    "res = gpt.query(**j_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:43:01.154887Z",
     "start_time": "2022-04-24T22:43:01.105334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([''],\n",
       " [{'text': '\\n',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length',\n",
       "   'prompt_index': 0}])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "Could not reproduce error with either old or new version of openai package. Maybe ipython handles things differently from jupyter?\n",
    "\n",
    "Update: could not reproduce in ipython either. No new openai version has been released in the last few days so it's not like they fixed something. Maybe it was an autoreload thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words in streaming mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:46:26.605282Z",
     "start_time": "2022-04-26T03:46:26.528728Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:29:08.290681Z",
     "start_time": "2022-04-26T03:29:00.287037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb990074fda422ba61ac87ef0749d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b1d8fbb8f641559684a77aa11f4c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334f2b4d163c4d4c864b74c96c661eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cbc1e1629342cc91ef27e23dc5638e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:29:26.056541Z",
     "start_time": "2022-04-26T03:29:17.766397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3109fcf3e5504b008905148fad7769f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc775d0c6e1246ab9e3aa96711166f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2b108cc6834e99bfa2ed832efca65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9accc6a12ac842bab72b33966d9825d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7bd0af56c24bcfabfdec664bf4da76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab04df275b14289a65042e6e3aa0689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_j = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-j-6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T04:07:06.579974Z",
     "start_time": "2022-04-26T04:07:06.495232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġregress', 50252),\n",
       " ('ĠCollider', 50253),\n",
       " ('Ġinformants', 50254),\n",
       " ('Ġgazed', 50255),\n",
       " ('<|endoftext|>', 50256)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.get_vocab().items())[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:34:21.548249Z",
     "start_time": "2022-04-26T03:34:21.436082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<',\n",
       " 'END',\n",
       " '>']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Sylvia: Hi.\\n\\nMe: Hello<END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T04:12:40.438052Z",
     "start_time": "2022-04-26T04:12:40.352642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<|endoftext|>']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Sylvia: Hi.\\n\\nMe: Hello<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:34:25.139146Z",
     "start_time": "2022-04-26T03:34:25.056975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<',\n",
       " 'END',\n",
       " '>']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_j.tokenize('Sylvia: Hi.\\n\\nMe: Hello<END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:55.841274Z",
     "start_time": "2022-04-26T02:42:55.792167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai', 'gooseai', 'huggingface', 'hobby', 'banana', 'repeat', 'mock']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:56.659436Z",
     "start_time": "2022-04-26T02:42:56.621956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"mock\".\n"
     ]
    }
   ],
   "source": [
    "gpt.switch('mock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:57.636239Z",
     "start_time": "2022-04-26T02:42:57.593919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stream': True, 'prompt': 'This is the last time', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock', 'datetime': 'Mon Apr 25 19:42:57 2022'}}\n",
      " a\n",
      "{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x11f6b3db0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " bit\n",
      "{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x11f6b3f68> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -4.75390625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" bit\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' bit', 'token_index': 1, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " busy\n",
      "{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x11f6c0150> JSON: {\n",
      "  \"text_offset\": [\n",
      "    6\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -5.09375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" busy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" like\": -4.03515625,\n",
      "      \" more\": -3.875,\n",
      "      \" of\": -0.352294921875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' busy', 'token_index': 2, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:721: UserWarning: strip_output=True is not supported in stream mode. Automatically setting it to False.\n",
      "  warnings.warn('strip_output=True is not supported in stream '\n",
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:726: UserWarning: Streaming mode does not support manual truncation of stop phrases and your current backend has limited support for truncation.\n",
      "  'Streaming mode does not support manual truncation of '\n"
     ]
    }
   ],
   "source": [
    "for tok, full in gpt.query('This is the last time', stream=True):\n",
    "    print(tok)\n",
    "    print(full)\n",
    "    print(spacer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:43:05.044328Z",
     "start_time": "2022-04-26T02:43:04.970210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jabberwocky.openai_utils.ConversationManager at 0x11f707240>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = oautils.ConversationManager(verbose=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:41.771659Z",
     "start_time": "2022-04-26T03:25:41.139841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n",
      "Switching openai backend to \"openai\".\n",
      "{'engine_i': 0, 'temperature': 0.5, 'max_tokens': 25, 'frequency_penalty': 0.1, 'stop': ['\\n\\nMe:', 'This is a conversation with'], 'stream': True, 'prompt': 'This is a conversation with Sylvia Plath. Sylvia Plath (October 27, 1932 - February 11, 1963) was an American poet, novelist, and short-story writer. She is credited with advancing the genre of confessional poetry and is best known for two of her published collections, The Colossus and Other Poems (1960) and Ariel (1965), as well as The Bell Jar, a semi-autobiographical novel published shortly before her death in 1963.\\n\\nMe: Hi.\\n\\nSylvia Plath:', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Mon Apr 25 20:25:41 2022'}}\n"
     ]
    }
   ],
   "source": [
    "gpt.switch('openai')\n",
    "with conv.converse('Sylvia Plath'):\n",
    "    res = conv.query('Hi.', engine_i=0,\n",
    "                     stream=True, max_tokens=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:43.063469Z",
     "start_time": "2022-04-26T03:25:43.023480Z"
    }
   },
   "outputs": [],
   "source": [
    "res2 = list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:44.148168Z",
     "start_time": "2022-04-26T03:25:44.106791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Hi', '.', ' How', ' are', ' you', '?', '']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row[0] for row in res2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:08:27.075696Z",
     "start_time": "2022-04-27T02:08:26.965034Z"
    }
   },
   "outputs": [],
   "source": [
    "res = [(' Hi',\n",
    "  {'text': ' Hi',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('.',\n",
    "  {'text': '.',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' How',\n",
    "  {'text': ' How',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' are',\n",
    "  {'text': ' are',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' you',\n",
    "  {'text': ' you',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('?',\n",
    "  {'text': '?',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('',\n",
    "  {'text': '',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "('<|endoftext|>',\n",
    "  {'text': '<|endoftext|>',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "(' ',\n",
    " {'text': ' ',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('Hey',\n",
    " {'text': 'Hey',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "  (' there',\n",
    " {'text': ' there',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': 'length',\n",
    "   'prompt_index': 0}),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on usage:\n",
    "\n",
    "- When NOT in stream mode, gpt.query uses `openai_utils.truncate_at_first_stop`. This executes on a single completion (np=1, nc=1) at a time.\n",
    "- When in stream mode, it uses `utils.stream_response`. This calls `stream_openai_generator` if the query func has param 'stream' and does some custom logic in the same stream_response func otherwise.\n",
    "- Possible way to utilize new stream func (when done): use it in stream_openai_generator? Will be unnecessary for openai (basically just for gooseai, since other query funcs don't support streaming at all) but shouldn't be harmful, in theory. Then update stream_response logic if necessary (might be easier to just convert to str/list and rstrip/replace, since these aren't really streamed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:08:27.607417Z",
     "start_time": "2022-04-27T02:08:27.504312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize('<END>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:58.195328Z",
     "start_time": "2022-04-27T02:09:58.112558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uses lookahead so we don't return any tokens past stop. Might be tricky to\n",
    "# use w/ multiple stopwords bc diff lengths.\n",
    "# TODO: update to work when np > 1 and/or nc > 1.\n",
    "def stream_with_stop(gen, stop_word='<|endoftext|>', stop_word_n_tokens=1):\n",
    "    # stop_word_n_tokens: number of tokens stop_word consists of when using \n",
    "    # the appropriate gpt tokenizer (I vaguely recall this may differ for\n",
    "    # gpt-j models).\n",
    "    full_text = ''\n",
    "    q = deque()\n",
    "    for i, (text, full) in enumerate(gen):\n",
    "        full_text += text\n",
    "        q.append((text, full))\n",
    "        if i < stop_word_n_tokens: continue\n",
    "        if full_text.endswith(stop_word):\n",
    "            q[0][-1]['finish_reason'] = 'stop'\n",
    "            yield q.popleft()\n",
    "            break\n",
    "        yield q.popleft()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:08:28.661935Z",
     "start_time": "2022-04-27T02:08:28.585672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Hi' None\n",
      "'.' None\n",
      "' How' None\n",
      "' are' None\n",
      "' you' None\n",
      "'?' None\n",
      "'' None\n",
      "'<|endoftext|>' None\n",
      "' ' None\n",
      "'Hey' None\n",
      "' there' length\n"
     ]
    }
   ],
   "source": [
    "for tok, full in res:\n",
    "    print(repr(tok), full['finish_reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:08:29.301691Z",
     "start_time": "2022-04-27T02:08:29.234881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Hi' None\n",
      "'.' None\n",
      "' How' None\n",
      "' are' None\n",
      "' you' None\n",
      "'?' None\n",
      "'' stop\n"
     ]
    }
   ],
   "source": [
    "for tok, full in stream_with_stop(res):\n",
    "    print(repr(tok), full['finish_reason'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost estimator\n",
    "\n",
    "Since the stopword removal for a backend with native streaming currently only helps gooseai, I want to get a better sense of how often gooseai is actually cost effective. Write function to compute:\n",
    "- openai cost\n",
    "- gooseai cost\n",
    "- which one is cheaper\n",
    "- evaluate over a range of possible prompt lengths and output lengths\n",
    "    - maybe plot\n",
    "- consideration: we often specify max_tokens but the actual response could be shorter. Maybe provide an option to use some sort of expected value of return a distribution of possible prices, rather than a single price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T04:13:10.393955Z",
     "start_time": "2022-04-28T04:13:10.301703Z"
    }
   },
   "outputs": [],
   "source": [
    "class EngineMap:\n",
    "    \n",
    "    bases = [\n",
    "        'ada',\n",
    "        'babbage',\n",
    "        'curie', \n",
    "        'davinci'\n",
    "    ]\n",
    "    backend_engines = C.backend_engines\n",
    "    \n",
    "    @classmethod\n",
    "    def get(cls, engine, backend=None, infer=False, default=None, \n",
    "            openai_base=False):\n",
    "        # Returns str if resolved, default value (e.g. None) otherwise.\n",
    "        user_engine = engine\n",
    "        if isinstance(engine, int):\n",
    "            if engine not in range(4):\n",
    "                raise ValueError(\n",
    "                    f'Received invalid engine value: {engine}. If engine is '\n",
    "                    'specified as an integer, it must lie in [0, 3].'\n",
    "                )\n",
    "            engine_i = engine\n",
    "        else:\n",
    "            base = cls._openai_base_engine(engine)\n",
    "            engine_i = cls.bases.index(base)\n",
    "        \n",
    "        backend = backend or GPTBackend.current()\n",
    "        if backend not in cls.backend_engines:\n",
    "            return default\n",
    "            \n",
    "        backend_engines = cls.backend_engines[backend]\n",
    "        engine = backend_engines[engine_i]\n",
    "        if not engine:\n",
    "            msg = f'No engine={user_engine} equivalent for backend {backend}.'\n",
    "            if infer:\n",
    "                warnings.warn(msg + 'Trying to auto-infer best option.')\n",
    "                while engine_i > 0 and not engine:\n",
    "                    engine_i -= 1\n",
    "                    engine = backend_engines[engine_i]\n",
    "            else:\n",
    "                return default\n",
    "                \n",
    "        # We can choose to get response like 'ada' instead of 'text-ada-001'.\n",
    "        if backend == 'openai' and openai_base:\n",
    "            engine = cls.bases[engine_i]\n",
    "        return engine\n",
    "        \n",
    "    @classmethod\n",
    "    def _openai_base_engine(cls, engine:str):\n",
    "        matches = [chunk for chunk in engine.split('-') \n",
    "                   if chunk in cls.bases]\n",
    "        if not matches:\n",
    "            raise ValueError(f'Engine \"{engine}\" does not contain any of the '\n",
    "                             f'recognized openai bases {cls.bases}.')\n",
    "        if len(matches) > 1:\n",
    "            raise ValueError(f'Engine \"{engine}\" contains multiple matches '\n",
    "                             f'among the recognized openai bases '\n",
    "                             f'{cls.bases}.')\n",
    "\n",
    "        return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T04:13:10.845628Z",
     "start_time": "2022-04-28T04:13:10.745566Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai 0\n",
      "\t 'text-ada-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai 1\n",
      "\t 'text-babbage-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai 2\n",
      "\t 'text-curie-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai 3\n",
      "\t 'text-davinci-002'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai ada\n",
      "\t 'text-ada-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai babbage\n",
      "\t 'text-babbage-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai curie\n",
      "\t 'text-curie-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai davinci\n",
      "\t 'text-davinci-002'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai text-ada-001\n",
      "\t 'text-ada-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai text-babbage-001\n",
      "\t 'text-babbage-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai text-curie-001\n",
      "\t 'text-curie-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai text-davinci-002\n",
      "\t 'text-davinci-002'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai 9\n",
      "Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "Inferred engine failed too. Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai typo\n",
      "Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "Inferred engine failed too. Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai code-ada-001\n",
      "\t 'text-ada-001'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai 0\n",
      "\t 'gpt-neo-2-7b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai 1\n",
      "\t 'gpt-j-6b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai 2\n",
      "\t 'fairseq-13b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai 3\n",
      "\t 'gpt-neo-20b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai ada\n",
      "\t 'gpt-neo-2-7b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai babbage\n",
      "\t 'gpt-j-6b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai curie\n",
      "\t 'fairseq-13b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai davinci\n",
      "\t 'gpt-neo-20b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai text-ada-001\n",
      "\t 'gpt-neo-2-7b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai text-babbage-001\n",
      "\t 'gpt-j-6b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai text-curie-001\n",
      "\t 'fairseq-13b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai text-davinci-002\n",
      "\t 'gpt-neo-20b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai 9\n",
      "Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "Inferred engine failed too. Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai typo\n",
      "Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "Inferred engine failed too. Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "gooseai code-ada-001\n",
      "\t 'gpt-neo-2-7b'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface 0\n",
      "\t 'gpt-neo-2.7B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface 1\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface 2\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface 3\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface ada\n",
      "\t 'gpt-neo-2.7B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface babbage\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface curie\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface davinci\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface text-ada-001\n",
      "\t 'gpt-neo-2.7B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface text-babbage-001\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface text-curie-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface text-davinci-002\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface 9\n",
      "Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "Inferred engine failed too. Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface typo\n",
      "Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "Inferred engine failed too. Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "huggingface code-ada-001\n",
      "\t 'gpt-neo-2.7B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby 0\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby 1\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby 2\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby 3\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby ada\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby babbage\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby curie\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby davinci\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby text-ada-001\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby text-babbage-001\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby text-curie-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby text-davinci-002\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby 9\n",
      "Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "Inferred engine failed too. Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby typo\n",
      "Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "Inferred engine failed too. Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "hobby code-ada-001\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana 0\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana 1\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana 2\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana 3\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana ada\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana babbage\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana curie\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana davinci\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana text-ada-001\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana text-babbage-001\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana text-curie-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana text-davinci-002\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana 9\n",
      "Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "Inferred engine failed too. Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana typo\n",
      "Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "Inferred engine failed too. Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "banana code-ada-001\n",
      "\t 'gpt-j-6B'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat 0\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat 1\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat 2\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat 3\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat ada\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat babbage\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat curie\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat davinci\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat text-ada-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat text-babbage-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat text-curie-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat text-davinci-002\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat 9\n",
      "Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "Inferred engine failed too. Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat typo\n",
      "Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "Inferred engine failed too. Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "repeat code-ada-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock 0\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock 1\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock 2\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock 3\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock ada\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock babbage\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock curie\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock davinci\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock text-ada-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock text-babbage-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock text-curie-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock text-davinci-002\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock 9\n",
      "Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "Inferred engine failed too. Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock typo\n",
      "Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "Inferred engine failed too. Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "mock code-ada-001\n",
      "\t None\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backends = GPTBackend.backends()\n",
    "engine_inputs = [\n",
    "    0, 1, 2, 3, 'ada', 'babbage', 'curie', 'davinci', 'text-ada-001', \n",
    "    'text-babbage-001', 'text-curie-001', 'text-davinci-002', 9, 'typo', \n",
    "    'code-ada-001'\n",
    "]\n",
    "\n",
    "for backend in backends:\n",
    "    for engine in engine_inputs:\n",
    "        print(backend, engine)\n",
    "        try:\n",
    "            tmp = EngineMap.get(engine, backend)\n",
    "            print('\\t', repr(tmp))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            try:\n",
    "                tmp = EngineMap.get(engine, backend, infer=True)\n",
    "                print('\\tInferred: ', repr(tmp))\n",
    "            except Exception as e:\n",
    "                print('Inferred engine failed too. ' + str(e))\n",
    "        print(spacer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T04:19:22.252674Z",
     "start_time": "2022-04-28T04:19:21.954780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"huggingface\".\n",
      "gpt-neo-2.7B\n",
      "Switching  backend back to \"mock\".\n"
     ]
    }
   ],
   "source": [
    "with gpt('huggingface'):\n",
    "    print(EngineMap.get('ada'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T04:19:28.521572Z",
     "start_time": "2022-04-28T04:19:28.438977Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: No engine=text-davinci-002 equivalent for backend huggingface.Trying to auto-infer best option.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gpt-j-6B'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EngineMap.get('text-davinci-002', 'huggingface', infer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T04:13:11.284721Z",
     "start_time": "2022-04-28T04:13:11.207063Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai 0\n",
      "\t 'ada'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai 1\n",
      "\t 'babbage'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai 2\n",
      "\t 'curie'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai 3\n",
      "\t 'davinci'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai ada\n",
      "\t 'ada'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai babbage\n",
      "\t 'babbage'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai curie\n",
      "\t 'curie'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai davinci\n",
      "\t 'davinci'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai text-ada-001\n",
      "\t 'ada'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai text-babbage-001\n",
      "\t 'babbage'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai text-curie-001\n",
      "\t 'curie'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai text-davinci-002\n",
      "\t 'davinci'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai 9\n",
      "Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "Inferred engine failed too. Received invalid engine value: 9. If engine is specified as an integer, it must lie in [0, 3].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai typo\n",
      "Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "Inferred engine failed too. Engine \"typo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "openai code-ada-001\n",
      "\t 'ada'\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backend = 'openai'\n",
    "for engine in engine_inputs:\n",
    "    print(backend, engine)\n",
    "    try:\n",
    "        tmp = EngineMap.get(engine, backend, openai_base=True)\n",
    "        print('\\t', repr(tmp))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        try:\n",
    "            tmp = EngineMap.get(engine, backend, infer=True, openai_base=True)\n",
    "            print('\\tInferred: ', repr(tmp))\n",
    "        except Exception as e:\n",
    "            print('Inferred engine failed too. ' + str(e))\n",
    "    print(spacer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T04:13:23.149858Z",
     "start_time": "2022-04-28T04:13:23.057859Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_cost(completion_length, prompt_length=None, prompt=None, \n",
    "                  openai_engine=None):\n",
    "    xor_none(prompt_length, prompt)\n",
    "    \n",
    "        \n",
    "    # Unlike gooseai, openai charges for both prompt and generation tokens.\n",
    "    # We convert their prices to cents per token.\n",
    "    # And/or support passing in engine_i int?\n",
    "    openai_prices = {\n",
    "        'ada': {'per': .0008 / 1_000},\n",
    "        'babbage': {'per': .0012 / 1_000},\n",
    "        'curie': {'per': .0060 / 1_000},\n",
    "        'davinci': {'per': .0600 / 1_000},\n",
    "    }\n",
    "    \n",
    "    # Gooseai base prices (in cents) cover the input and the first 25 tokens \n",
    "    # of the output. `Per` prices are cents per token.\n",
    "    gooseai_prices = {\n",
    "        'gpt-neo-20b': {'base': 0.002650, 'per': 0.000063},\n",
    "        'fairseq-13b': {'base': 0.001250, 'per': 0.000036},\n",
    "        'fairseq-6-7b': {'base': 0.000450, 'per': 0.000012},\n",
    "        'gpt-j-6b': {'base': 0.000450, 'per': 0.000012},\n",
    "        'gpt-neo-2-7b': {'base': 0.000300, 'per': 0.000008},\n",
    "        'fairseq-2-7b': {'base': 0.000300, 'per': 0.000008},\n",
    "        'gpt-neo-1-3b': {'base': 0.000110, 'per': 0.000003},\n",
    "        'fairseq-1-3b': {'base': 0.000110, 'per': 0.000003},\n",
    "        'gpt-neo-125m': {'base': 0.000035, 'per': 0.000001},\n",
    "        'fairseq-125m': {'base': 0.000035, 'per': 0.000001},\n",
    "    }\n",
    "\n",
    "    \n",
    "    prompt_length = prompt_length or len(tokenizer.tokenize(prompt))\n",
    "    gooseai_resolved = [\n",
    "        ('gooseai', name, prices['base']*prompt_length \n",
    "              + prices['per']*max(0, completion_length - 25))\n",
    "        for name, prices in gooseai_prices.items()\n",
    "    ]\n",
    "    openai_resolved = [\n",
    "        ('openai', name, prices['per'] * (prompt_length + completion_length))\n",
    "        for name, prices in openai_prices.items()\n",
    "    ]\n",
    "    # Prices are returned in cents.\n",
    "    return pd.DataFrame(\n",
    "        gooseai_resolved + openai_resolved,\n",
    "        columns=['backend', 'engine', 'cost_cents']\n",
    "    ).sort_values('cost_cents', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:37:56.689174Z",
     "start_time": "2022-04-27T03:37:56.582768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debate: Non-zero frequency penalty was initially included by accident, but in at least 1 test removing it noticeably worsened results.\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend</th>\n",
       "      <th>engine</th>\n",
       "      <th>cost_cents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai</td>\n",
       "      <td>babbage</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai</td>\n",
       "      <td>curie</td>\n",
       "      <td>0.005304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-125m</td>\n",
       "      <td>0.020715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-125m</td>\n",
       "      <td>0.020715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai</td>\n",
       "      <td>davinci</td>\n",
       "      <td>0.053040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-1-3b</td>\n",
       "      <td>0.065065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-1-3b</td>\n",
       "      <td>0.065065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-2-7b</td>\n",
       "      <td>0.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-2-7b</td>\n",
       "      <td>0.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-6-7b</td>\n",
       "      <td>0.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-j-6b</td>\n",
       "      <td>0.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-13b</td>\n",
       "      <td>0.739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-20b</td>\n",
       "      <td>1.564925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    backend        engine  cost_cents\n",
       "0    openai           ada    0.000707\n",
       "1    openai       babbage    0.001061\n",
       "2    openai         curie    0.005304\n",
       "3   gooseai  gpt-neo-125m    0.020715\n",
       "4   gooseai  fairseq-125m    0.020715\n",
       "5    openai       davinci    0.053040\n",
       "6   gooseai  gpt-neo-1-3b    0.065065\n",
       "7   gooseai  fairseq-1-3b    0.065065\n",
       "8   gooseai  gpt-neo-2-7b    0.177400\n",
       "9   gooseai  fairseq-2-7b    0.177400\n",
       "10  gooseai  fairseq-6-7b    0.266100\n",
       "11  gooseai      gpt-j-6b    0.266100\n",
       "12  gooseai   fairseq-13b    0.739900\n",
       "13  gooseai   gpt-neo-20b    1.564925"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt('debate', 'A hot dog is a sandwich.')['prompt']\n",
    "cost_res = estimate_cost(completion_length=300, prompt=prompt)\n",
    "cost_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:38:16.208506Z",
     "start_time": "2022-04-27T03:38:16.105390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend</th>\n",
       "      <th>engine</th>\n",
       "      <th>cost_cents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai</td>\n",
       "      <td>babbage</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai</td>\n",
       "      <td>curie</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-125m</td>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-125m</td>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-1-3b</td>\n",
       "      <td>0.007190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-1-3b</td>\n",
       "      <td>0.007190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai</td>\n",
       "      <td>davinci</td>\n",
       "      <td>0.008340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-2-7b</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-2-7b</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-6-7b</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-j-6b</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-13b</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-20b</td>\n",
       "      <td>0.172750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    backend        engine  cost_cents\n",
       "0    openai           ada    0.000111\n",
       "1    openai       babbage    0.000167\n",
       "2    openai         curie    0.000834\n",
       "3   gooseai  gpt-neo-125m    0.002290\n",
       "4   gooseai  fairseq-125m    0.002290\n",
       "5   gooseai  gpt-neo-1-3b    0.007190\n",
       "6   gooseai  fairseq-1-3b    0.007190\n",
       "7    openai       davinci    0.008340\n",
       "8   gooseai  gpt-neo-2-7b    0.019600\n",
       "9   gooseai  fairseq-2-7b    0.019600\n",
       "10  gooseai  fairseq-6-7b    0.029400\n",
       "11  gooseai      gpt-j-6b    0.029400\n",
       "12  gooseai   fairseq-13b    0.081800\n",
       "13  gooseai   gpt-neo-20b    0.172750"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = conv.kwargs('Jeremy Howard', return_prompt=True)['prompt'] \\\n",
    "    + '\\n\\nMe: Hi Jeremy.\\n\\nJeremy Howard:'\n",
    "estimate_cost(prompt=prompt, completion_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:44:14.040243Z",
     "start_time": "2022-04-27T03:44:13.954905Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_lengths = np.arange(1, 2048, 10)\n",
    "completion_lengths = np.arange(1, 2048, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:50:21.712791Z",
     "start_time": "2022-04-27T03:50:03.288737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5869fb9c94948f3adad7977e02f7833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_dfs = {\n",
    "    (p_len, c_len): estimate_cost(c_len, prompt_length=p_len)\n",
    "    for p_len, c_len in \n",
    "    tqdm(product(prompt_lengths, completion_lengths), \n",
    "         total=len(prompt_lengths) * len(completion_lengths))\n",
    "    if p_len + c_len <= 2_048\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:50:27.041181Z",
     "start_time": "2022-04-27T03:50:26.962613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21115"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cost_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:50:30.472482Z",
     "start_time": "2022-04-27T03:50:30.403887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend</th>\n",
       "      <th>engine</th>\n",
       "      <th>cost_cents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai</td>\n",
       "      <td>babbage</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai</td>\n",
       "      <td>curie</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-125m</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-125m</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-1-3b</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-1-3b</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai</td>\n",
       "      <td>davinci</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-2-7b</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-2-7b</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-6-7b</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-j-6b</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-13b</td>\n",
       "      <td>0.001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-20b</td>\n",
       "      <td>0.002650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    backend        engine  cost_cents\n",
       "0    openai           ada    0.000002\n",
       "1    openai       babbage    0.000002\n",
       "2    openai         curie    0.000012\n",
       "3   gooseai  gpt-neo-125m    0.000035\n",
       "4   gooseai  fairseq-125m    0.000035\n",
       "5   gooseai  gpt-neo-1-3b    0.000110\n",
       "6   gooseai  fairseq-1-3b    0.000110\n",
       "7    openai       davinci    0.000120\n",
       "8   gooseai  gpt-neo-2-7b    0.000300\n",
       "9   gooseai  fairseq-2-7b    0.000300\n",
       "10  gooseai  fairseq-6-7b    0.000450\n",
       "11  gooseai      gpt-j-6b    0.000450\n",
       "12  gooseai   fairseq-13b    0.001250\n",
       "13  gooseai   gpt-neo-20b    0.002650"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_dfs[1, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
