{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Recently (possibly since upgrading to openai 0.18.1?), querying openai causes invalid URL errors. Here are some notes from yesterday's troubleshooting session.\n",
    "\n",
    "- curl works, python doesn't.\n",
    "- Not just codex, now nox openai engines work w/ python. Maybe due to updating pip package? Temporarily upped billing limit to try other models.\n",
    "- Restarted kernel and gpt query works again w/ ada. BUT after I import openai explicitly, that fails too. That must be a clue.\n",
    "- Tried uninstalling, reinstalling, opened new tmux pane. Still same error.\n",
    "- Tried deleting 'openai' object and then importing jabberwocky. This does work!?\n",
    "- If I re-import openai after that, gpt.query still works. But openai.completion while codex does not.\n",
    "- If I import openai FROM jabberwocky openai_utils, codex query still fails. But gpt.query works. And openai.Completion works w/ engine ada!\n",
    "- Conclusion: maybe it is codex-specific then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:25.833217Z",
     "start_time": "2022-04-26T02:42:25.797726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.330949Z",
     "start_time": "2022-04-26T02:42:26.656974Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.367973Z",
     "start_time": "2022-04-26T02:42:28.333268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.417512Z",
     "start_time": "2022-04-26T02:42:28.374347Z"
    }
   },
   "outputs": [],
   "source": [
    "j_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine_i': 0}\n",
    "ada_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine': 'text-ada-001'}\n",
    "code_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine': 'code-davinci-001'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jabberwocky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:29.898711Z",
     "start_time": "2022-04-26T02:42:29.089044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key, \\\n",
    "    GPTBackend\n",
    "import jabberwocky.openai_utils as oautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:34.484408Z",
     "start_time": "2022-04-26T02:42:34.440337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBackend <current_name: openai>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:35.320532Z",
     "start_time": "2022-04-26T02:42:34.868415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_tokens': 1, 'engine_i': 0, 'prompt': 'a', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Mon Apr 25 19:42:34 2022'}}\n"
     ]
    }
   ],
   "source": [
    "res = gpt.query(**j_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:35.981679Z",
     "start_time": "2022-04-26T02:42:35.923931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([''],\n",
       " [{'text': '\\n',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length',\n",
       "   'prompt_index': 0}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai 0.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:37.398887Z",
     "start_time": "2022-04-26T02:42:37.362213Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:37.674368Z",
     "start_time": "2022-04-26T02:42:37.636416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:38.646957Z",
     "start_time": "2022-04-26T02:42:38.600483Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/hmamin/.openai', 'r') as f:\n",
    "    openai.api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:39.149616Z",
     "start_time": "2022-04-26T02:42:39.118576Z"
    }
   },
   "outputs": [],
   "source": [
    "# oautils.openai == openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:42.511652Z",
     "start_time": "2022-04-26T02:42:41.097177Z"
    }
   },
   "outputs": [],
   "source": [
    "res = openai.Completion.create(**code_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:43.073351Z",
     "start_time": "2022-04-26T02:42:43.036388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-515RxlKh9094yUQFyFqI4pVMKtjrV at 0x11f6c0b48> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"nt\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1650940961,\n",
       "  \"id\": \"cmpl-515RxlKh9094yUQFyFqI4pVMKtjrV\",\n",
       "  \"model\": \"code-davinci:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai 0.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:50.585914Z",
     "start_time": "2022-04-26T02:42:50.547720Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:50.747586Z",
     "start_time": "2022-04-26T02:42:50.707083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:11.939142Z",
     "start_time": "2022-04-26T02:33:11.888709Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/hmamin/.openai', 'r') as f:\n",
    "    openai.api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:16.525379Z",
     "start_time": "2022-04-26T02:33:16.482091Z"
    }
   },
   "outputs": [],
   "source": [
    "# oautils.openai == openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:21.766693Z",
     "start_time": "2022-04-26T02:33:18.368577Z"
    }
   },
   "outputs": [],
   "source": [
    "res = openai.Completion.create(**code_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:22.601648Z",
     "start_time": "2022-04-26T02:33:22.568651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-515ItOmu7H4oHPA2yyDXpfHpteeby at 0x1245a1bf8> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1650940399,\n",
       "  \"id\": \"cmpl-515ItOmu7H4oHPA2yyDXpfHpteeby\",\n",
       "  \"model\": \"code-davinci:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:54.236780Z",
     "start_time": "2022-04-24T22:42:53.572476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key, \\\n",
    "    GPTBackend\n",
    "import jabberwocky.openai_utils as oautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:55.862716Z",
     "start_time": "2022-04-24T22:42:55.822807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBackend <current_name: openai>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:59.158100Z",
     "start_time": "2022-04-24T22:42:58.972217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_tokens': 1, 'engine_i': 0, 'prompt': 'a', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Sun Apr 24 15:42:59 2022'}}\n"
     ]
    }
   ],
   "source": [
    "res = gpt.query(**j_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:43:01.154887Z",
     "start_time": "2022-04-24T22:43:01.105334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([''],\n",
       " [{'text': '\\n',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length',\n",
       "   'prompt_index': 0}])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "Could not reproduce error with either old or new version of openai package. Maybe ipython handles things differently from jupyter?\n",
    "\n",
    "Update: could not reproduce in ipython either. No new openai version has been released in the last few days so it's not like they fixed something. Maybe it was an autoreload thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words in streaming mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:46:26.605282Z",
     "start_time": "2022-04-26T03:46:26.528728Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:29:08.290681Z",
     "start_time": "2022-04-26T03:29:00.287037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb990074fda422ba61ac87ef0749d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b1d8fbb8f641559684a77aa11f4c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334f2b4d163c4d4c864b74c96c661eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cbc1e1629342cc91ef27e23dc5638e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:29:26.056541Z",
     "start_time": "2022-04-26T03:29:17.766397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3109fcf3e5504b008905148fad7769f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc775d0c6e1246ab9e3aa96711166f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2b108cc6834e99bfa2ed832efca65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9accc6a12ac842bab72b33966d9825d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7bd0af56c24bcfabfdec664bf4da76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab04df275b14289a65042e6e3aa0689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_j = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-j-6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T04:07:06.579974Z",
     "start_time": "2022-04-26T04:07:06.495232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġregress', 50252),\n",
       " ('ĠCollider', 50253),\n",
       " ('Ġinformants', 50254),\n",
       " ('Ġgazed', 50255),\n",
       " ('<|endoftext|>', 50256)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.get_vocab().items())[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:34:21.548249Z",
     "start_time": "2022-04-26T03:34:21.436082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<',\n",
       " 'END',\n",
       " '>']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Sylvia: Hi.\\n\\nMe: Hello<END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T04:12:40.438052Z",
     "start_time": "2022-04-26T04:12:40.352642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<|endoftext|>']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Sylvia: Hi.\\n\\nMe: Hello<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:34:25.139146Z",
     "start_time": "2022-04-26T03:34:25.056975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<',\n",
       " 'END',\n",
       " '>']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_j.tokenize('Sylvia: Hi.\\n\\nMe: Hello<END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:55.841274Z",
     "start_time": "2022-04-26T02:42:55.792167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai', 'gooseai', 'huggingface', 'hobby', 'banana', 'repeat', 'mock']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:56.659436Z",
     "start_time": "2022-04-26T02:42:56.621956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"mock\".\n"
     ]
    }
   ],
   "source": [
    "gpt.switch('mock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:57.636239Z",
     "start_time": "2022-04-26T02:42:57.593919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stream': True, 'prompt': 'This is the last time', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock', 'datetime': 'Mon Apr 25 19:42:57 2022'}}\n",
      " a\n",
      "{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x11f6b3db0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " bit\n",
      "{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x11f6b3f68> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -4.75390625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" bit\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' bit', 'token_index': 1, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " busy\n",
      "{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x11f6c0150> JSON: {\n",
      "  \"text_offset\": [\n",
      "    6\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -5.09375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" busy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" like\": -4.03515625,\n",
      "      \" more\": -3.875,\n",
      "      \" of\": -0.352294921875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' busy', 'token_index': 2, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:721: UserWarning: strip_output=True is not supported in stream mode. Automatically setting it to False.\n",
      "  warnings.warn('strip_output=True is not supported in stream '\n",
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:726: UserWarning: Streaming mode does not support manual truncation of stop phrases and your current backend has limited support for truncation.\n",
      "  'Streaming mode does not support manual truncation of '\n"
     ]
    }
   ],
   "source": [
    "for tok, full in gpt.query('This is the last time', stream=True):\n",
    "    print(tok)\n",
    "    print(full)\n",
    "    print(spacer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:43:05.044328Z",
     "start_time": "2022-04-26T02:43:04.970210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jabberwocky.openai_utils.ConversationManager at 0x11f707240>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = oautils.ConversationManager(verbose=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:41.771659Z",
     "start_time": "2022-04-26T03:25:41.139841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n",
      "Switching openai backend to \"openai\".\n",
      "{'engine_i': 0, 'temperature': 0.5, 'max_tokens': 25, 'frequency_penalty': 0.1, 'stop': ['\\n\\nMe:', 'This is a conversation with'], 'stream': True, 'prompt': 'This is a conversation with Sylvia Plath. Sylvia Plath (October 27, 1932 - February 11, 1963) was an American poet, novelist, and short-story writer. She is credited with advancing the genre of confessional poetry and is best known for two of her published collections, The Colossus and Other Poems (1960) and Ariel (1965), as well as The Bell Jar, a semi-autobiographical novel published shortly before her death in 1963.\\n\\nMe: Hi.\\n\\nSylvia Plath:', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Mon Apr 25 20:25:41 2022'}}\n"
     ]
    }
   ],
   "source": [
    "gpt.switch('openai')\n",
    "with conv.converse('Sylvia Plath'):\n",
    "    res = conv.query('Hi.', engine_i=0,\n",
    "                     stream=True, max_tokens=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:43.063469Z",
     "start_time": "2022-04-26T03:25:43.023480Z"
    }
   },
   "outputs": [],
   "source": [
    "res2 = list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:44.148168Z",
     "start_time": "2022-04-26T03:25:44.106791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Hi', '.', ' How', ' are', ' you', '?', '']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row[0] for row in res2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:55:10.249313Z",
     "start_time": "2022-04-26T03:55:10.155063Z"
    }
   },
   "outputs": [],
   "source": [
    "res = [(' Hi',\n",
    "  {'text': ' Hi',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('.',\n",
    "  {'text': '.',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' How',\n",
    "  {'text': ' How',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' are',\n",
    "  {'text': ' are',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' you',\n",
    "  {'text': ' you',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('?',\n",
    "  {'text': '?',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('',\n",
    "  {'text': '',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "('<',\n",
    "  {'text': '<',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "('END',\n",
    " {'text': 'END',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('>',\n",
    " {'text': '>',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "(' ',\n",
    " {'text': ' ',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('Hey',\n",
    " {'text': 'Hey',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "  (' there',\n",
    " {'text': ' there',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': 'length',\n",
    "   'prompt_index': 0}),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on usage:\n",
    "\n",
    "- When NOT in stream mode, gpt.query uses `openai_utils.truncate_at_first_stop`. This executes on a single completion (np=1, nc=1) at a time.\n",
    "- When in stream mode, it uses `utils.stream_response`. This calls `stream_openai_generator` if the query func has param 'stream' and does some custom logic in the same stream_response func otherwise.\n",
    "- Possible way to utilize new stream func (when done): use it in stream_openai_generator? Will be unnecessary for openai (basically just for gooseai, since other query funcs don't support streaming at all) but shouldn't be harmful, in theory. Then update stream_response logic if necessary (might be easier to just convert to str/list and rstrip/replace, since these aren't really streamed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:56:52.754855Z",
     "start_time": "2022-04-26T03:56:52.667500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uses lookahead so we don't return any tokens past stop. Might be tricky to\n",
    "# use w/ multiple stopwords bc diff lengths.\n",
    "# TODO: update to work when np > 1 and/or nc > 1.\n",
    "def stream_with_stop(gen):\n",
    "    # Hardcode stop_word for now so we know how many tokens it is.\n",
    "    # <END> is 3 tokens.\n",
    "    stop_word = '<END>'\n",
    "    stop_n_tokens = 3\n",
    "    full_text = ''\n",
    "    q = deque()\n",
    "    for i, (text, full) in enumerate(gen):\n",
    "        full_text += text\n",
    "        q.append((text, full))\n",
    "        if i < stop_n_tokens: continue\n",
    "        if full_text.endswith(stop_word):\n",
    "            q[0][-1]['finish_reason'] = 'stop'\n",
    "            yield q.popleft()\n",
    "            break\n",
    "        yield q.popleft()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:55:58.548751Z",
     "start_time": "2022-04-26T03:55:58.462878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Hi' None\n",
      "'.' None\n",
      "' How' None\n",
      "' are' None\n",
      "' you' None\n",
      "'?' None\n",
      "'' stop\n",
      "'<' stop\n",
      "'END' None\n",
      "'>' None\n",
      "' ' None\n",
      "'Hey' None\n",
      "' there' length\n"
     ]
    }
   ],
   "source": [
    "for tok, full in res:\n",
    "    print(repr(tok), full['finish_reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:55:59.227866Z",
     "start_time": "2022-04-26T03:55:59.158005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Hi' None\n",
      "'.' None\n",
      "' How' None\n",
      "' are' None\n",
      "' you' None\n",
      "'?' None\n",
      "'' stop\n"
     ]
    }
   ],
   "source": [
    "for tok, full in stream_with_stop(res):\n",
    "    print(repr(tok), full['finish_reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
