{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Recently (possibly since upgrading to openai 0.18.1?), querying openai causes invalid URL errors. Here are some notes from yesterday's troubleshooting session.\n",
    "\n",
    "- curl works, python doesn't.\n",
    "- Not just codex, now nox openai engines work w/ python. Maybe due to updating pip package? Temporarily upped billing limit to try other models.\n",
    "- Restarted kernel and gpt query works again w/ ada. BUT after I import openai explicitly, that fails too. That must be a clue.\n",
    "- Tried uninstalling, reinstalling, opened new tmux pane. Still same error.\n",
    "- Tried deleting 'openai' object and then importing jabberwocky. This does work!?\n",
    "- If I re-import openai after that, gpt.query still works. But openai.completion while codex does not.\n",
    "- If I import openai FROM jabberwocky openai_utils, codex query still fails. But gpt.query works. And openai.Completion works w/ engine ada!\n",
    "- Conclusion: maybe it is codex-specific then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:25.833217Z",
     "start_time": "2022-04-26T02:42:25.797726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.330949Z",
     "start_time": "2022-04-26T02:42:26.656974Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.367973Z",
     "start_time": "2022-04-26T02:42:28.333268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:28.417512Z",
     "start_time": "2022-04-26T02:42:28.374347Z"
    }
   },
   "outputs": [],
   "source": [
    "j_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine_i': 0}\n",
    "ada_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine': 'text-ada-001'}\n",
    "code_kwargs = {'prompt': 'a', 'max_tokens': 1, 'engine': 'code-davinci-001'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jabberwocky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:29.898711Z",
     "start_time": "2022-04-26T02:42:29.089044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key, \\\n",
    "    GPTBackend\n",
    "import jabberwocky.openai_utils as oautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:34.484408Z",
     "start_time": "2022-04-26T02:42:34.440337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBackend <current_name: openai>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:35.320532Z",
     "start_time": "2022-04-26T02:42:34.868415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_tokens': 1, 'engine_i': 0, 'prompt': 'a', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Mon Apr 25 19:42:34 2022'}}\n"
     ]
    }
   ],
   "source": [
    "res = gpt.query(**j_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:35.981679Z",
     "start_time": "2022-04-26T02:42:35.923931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([''],\n",
       " [{'text': '\\n',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length',\n",
       "   'prompt_index': 0}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai 0.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:37.398887Z",
     "start_time": "2022-04-26T02:42:37.362213Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:37.674368Z",
     "start_time": "2022-04-26T02:42:37.636416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:38.646957Z",
     "start_time": "2022-04-26T02:42:38.600483Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/hmamin/.openai', 'r') as f:\n",
    "    openai.api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:39.149616Z",
     "start_time": "2022-04-26T02:42:39.118576Z"
    }
   },
   "outputs": [],
   "source": [
    "# oautils.openai == openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:42.511652Z",
     "start_time": "2022-04-26T02:42:41.097177Z"
    }
   },
   "outputs": [],
   "source": [
    "res = openai.Completion.create(**code_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:43.073351Z",
     "start_time": "2022-04-26T02:42:43.036388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-515RxlKh9094yUQFyFqI4pVMKtjrV at 0x11f6c0b48> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"nt\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1650940961,\n",
       "  \"id\": \"cmpl-515RxlKh9094yUQFyFqI4pVMKtjrV\",\n",
       "  \"model\": \"code-davinci:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai 0.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:50.585914Z",
     "start_time": "2022-04-26T02:42:50.547720Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:50.747586Z",
     "start_time": "2022-04-26T02:42:50.707083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:11.939142Z",
     "start_time": "2022-04-26T02:33:11.888709Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/hmamin/.openai', 'r') as f:\n",
    "    openai.api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:16.525379Z",
     "start_time": "2022-04-26T02:33:16.482091Z"
    }
   },
   "outputs": [],
   "source": [
    "# oautils.openai == openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:21.766693Z",
     "start_time": "2022-04-26T02:33:18.368577Z"
    }
   },
   "outputs": [],
   "source": [
    "res = openai.Completion.create(**code_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:33:22.601648Z",
     "start_time": "2022-04-26T02:33:22.568651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-515ItOmu7H4oHPA2yyDXpfHpteeby at 0x1245a1bf8> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1650940399,\n",
       "  \"id\": \"cmpl-515ItOmu7H4oHPA2yyDXpfHpteeby\",\n",
       "  \"model\": \"code-davinci:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:54.236780Z",
     "start_time": "2022-04-24T22:42:53.572476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key, \\\n",
    "    GPTBackend\n",
    "import jabberwocky.openai_utils as oautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:55.862716Z",
     "start_time": "2022-04-24T22:42:55.822807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBackend <current_name: openai>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:42:59.158100Z",
     "start_time": "2022-04-24T22:42:58.972217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_tokens': 1, 'engine_i': 0, 'prompt': 'a', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Sun Apr 24 15:42:59 2022'}}\n"
     ]
    }
   ],
   "source": [
    "res = gpt.query(**j_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T22:43:01.154887Z",
     "start_time": "2022-04-24T22:43:01.105334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([''],\n",
       " [{'text': '\\n',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length',\n",
       "   'prompt_index': 0}])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "Could not reproduce error with either old or new version of openai package. Maybe ipython handles things differently from jupyter?\n",
    "\n",
    "Update: could not reproduce in ipython either. No new openai version has been released in the last few days so it's not like they fixed something. Maybe it was an autoreload thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words in streaming mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:46:26.605282Z",
     "start_time": "2022-04-26T03:46:26.528728Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:29:08.290681Z",
     "start_time": "2022-04-26T03:29:00.287037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb990074fda422ba61ac87ef0749d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b1d8fbb8f641559684a77aa11f4c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334f2b4d163c4d4c864b74c96c661eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cbc1e1629342cc91ef27e23dc5638e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:29:26.056541Z",
     "start_time": "2022-04-26T03:29:17.766397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3109fcf3e5504b008905148fad7769f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc775d0c6e1246ab9e3aa96711166f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2b108cc6834e99bfa2ed832efca65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9accc6a12ac842bab72b33966d9825d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7bd0af56c24bcfabfdec664bf4da76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab04df275b14289a65042e6e3aa0689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_j = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-j-6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T04:07:06.579974Z",
     "start_time": "2022-04-26T04:07:06.495232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġregress', 50252),\n",
       " ('ĠCollider', 50253),\n",
       " ('Ġinformants', 50254),\n",
       " ('Ġgazed', 50255),\n",
       " ('<|endoftext|>', 50256)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.get_vocab().items())[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:34:21.548249Z",
     "start_time": "2022-04-26T03:34:21.436082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<',\n",
       " 'END',\n",
       " '>']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Sylvia: Hi.\\n\\nMe: Hello<END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T04:12:40.438052Z",
     "start_time": "2022-04-26T04:12:40.352642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<|endoftext|>']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Sylvia: Hi.\\n\\nMe: Hello<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:34:25.139146Z",
     "start_time": "2022-04-26T03:34:25.056975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'yl',\n",
       " 'via',\n",
       " ':',\n",
       " 'ĠHi',\n",
       " '.',\n",
       " 'Ċ',\n",
       " 'Ċ',\n",
       " 'Me',\n",
       " ':',\n",
       " 'ĠHello',\n",
       " '<',\n",
       " 'END',\n",
       " '>']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_j.tokenize('Sylvia: Hi.\\n\\nMe: Hello<END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:55.841274Z",
     "start_time": "2022-04-26T02:42:55.792167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai', 'gooseai', 'huggingface', 'hobby', 'banana', 'repeat', 'mock']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:56.659436Z",
     "start_time": "2022-04-26T02:42:56.621956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"mock\".\n"
     ]
    }
   ],
   "source": [
    "gpt.switch('mock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:42:57.636239Z",
     "start_time": "2022-04-26T02:42:57.593919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stream': True, 'prompt': 'This is the last time', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock', 'datetime': 'Mon Apr 25 19:42:57 2022'}}\n",
      " a\n",
      "{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x11f6b3db0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " bit\n",
      "{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x11f6b3f68> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -4.75390625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" bit\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' bit', 'token_index': 1, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " busy\n",
      "{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x11f6c0150> JSON: {\n",
      "  \"text_offset\": [\n",
      "    6\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -5.09375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" busy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" like\": -4.03515625,\n",
      "      \" more\": -3.875,\n",
      "      \" of\": -0.352294921875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' busy', 'token_index': 2, 'prompt_index': 0}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:721: UserWarning: strip_output=True is not supported in stream mode. Automatically setting it to False.\n",
      "  warnings.warn('strip_output=True is not supported in stream '\n",
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:726: UserWarning: Streaming mode does not support manual truncation of stop phrases and your current backend has limited support for truncation.\n",
      "  'Streaming mode does not support manual truncation of '\n"
     ]
    }
   ],
   "source": [
    "for tok, full in gpt.query('This is the last time', stream=True):\n",
    "    print(tok)\n",
    "    print(full)\n",
    "    print(spacer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T02:43:05.044328Z",
     "start_time": "2022-04-26T02:43:04.970210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jabberwocky.openai_utils.ConversationManager at 0x11f707240>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = oautils.ConversationManager(verbose=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:41.771659Z",
     "start_time": "2022-04-26T03:25:41.139841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n",
      "Switching openai backend to \"openai\".\n",
      "{'engine_i': 0, 'temperature': 0.5, 'max_tokens': 25, 'frequency_penalty': 0.1, 'stop': ['\\n\\nMe:', 'This is a conversation with'], 'stream': True, 'prompt': 'This is a conversation with Sylvia Plath. Sylvia Plath (October 27, 1932 - February 11, 1963) was an American poet, novelist, and short-story writer. She is credited with advancing the genre of confessional poetry and is best known for two of her published collections, The Colossus and Other Poems (1960) and Ariel (1965), as well as The Bell Jar, a semi-autobiographical novel published shortly before her death in 1963.\\n\\nMe: Hi.\\n\\nSylvia Plath:', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Mon Apr 25 20:25:41 2022'}}\n"
     ]
    }
   ],
   "source": [
    "gpt.switch('openai')\n",
    "with conv.converse('Sylvia Plath'):\n",
    "    res = conv.query('Hi.', engine_i=0,\n",
    "                     stream=True, max_tokens=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:43.063469Z",
     "start_time": "2022-04-26T03:25:43.023480Z"
    }
   },
   "outputs": [],
   "source": [
    "res2 = list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T03:25:44.148168Z",
     "start_time": "2022-04-26T03:25:44.106791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Hi', '.', ' How', ' are', ' you', '?', '']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row[0] for row in res2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:08:27.075696Z",
     "start_time": "2022-04-27T02:08:26.965034Z"
    }
   },
   "outputs": [],
   "source": [
    "res = [(' Hi',\n",
    "  {'text': ' Hi',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('.',\n",
    "  {'text': '.',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' How',\n",
    "  {'text': ' How',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' are',\n",
    "  {'text': ' are',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " (' you',\n",
    "  {'text': ' you',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('?',\n",
    "  {'text': '?',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('',\n",
    "  {'text': '',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "('<|endoftext|>',\n",
    "  {'text': '<|endoftext|>',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "(' ',\n",
    " {'text': ' ',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    " ('Hey',\n",
    " {'text': 'Hey',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': None,\n",
    "   'prompt_index': 0}),\n",
    "  (' there',\n",
    " {'text': ' there',\n",
    "   'index': 0,\n",
    "   'logprobs': None,\n",
    "   'finish_reason': 'length',\n",
    "   'prompt_index': 0}),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on usage:\n",
    "\n",
    "- When NOT in stream mode, gpt.query uses `openai_utils.truncate_at_first_stop`. This executes on a single completion (np=1, nc=1) at a time.\n",
    "- When in stream mode, it uses `utils.stream_response`. This calls `stream_openai_generator` if the query func has param 'stream' and does some custom logic in the same stream_response func otherwise.\n",
    "- Possible way to utilize new stream func (when done): use it in stream_openai_generator? Will be unnecessary for openai (basically just for gooseai, since other query funcs don't support streaming at all) but shouldn't be harmful, in theory. Then update stream_response logic if necessary (might be easier to just convert to str/list and rstrip/replace, since these aren't really streamed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:08:27.607417Z",
     "start_time": "2022-04-27T02:08:27.504312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize('<END>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:09:58.195328Z",
     "start_time": "2022-04-27T02:09:58.112558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uses lookahead so we don't return any tokens past stop. Might be tricky to\n",
    "# use w/ multiple stopwords bc diff lengths.\n",
    "# TODO: update to work when np > 1 and/or nc > 1.\n",
    "def stream_with_stop(gen, stop_word='<|endoftext|>', stop_word_n_tokens=1):\n",
    "    # stop_word_n_tokens: number of tokens stop_word consists of when using \n",
    "    # the appropriate gpt tokenizer (I vaguely recall this may differ for\n",
    "    # gpt-j models).\n",
    "    full_text = ''\n",
    "    q = deque()\n",
    "    for i, (text, full) in enumerate(gen):\n",
    "        full_text += text\n",
    "        q.append((text, full))\n",
    "        if i < stop_word_n_tokens: continue\n",
    "        if full_text.endswith(stop_word):\n",
    "            q[0][-1]['finish_reason'] = 'stop'\n",
    "            yield q.popleft()\n",
    "            break\n",
    "        yield q.popleft()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:08:28.661935Z",
     "start_time": "2022-04-27T02:08:28.585672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Hi' None\n",
      "'.' None\n",
      "' How' None\n",
      "' are' None\n",
      "' you' None\n",
      "'?' None\n",
      "'' None\n",
      "'<|endoftext|>' None\n",
      "' ' None\n",
      "'Hey' None\n",
      "' there' length\n"
     ]
    }
   ],
   "source": [
    "for tok, full in res:\n",
    "    print(repr(tok), full['finish_reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T02:08:29.301691Z",
     "start_time": "2022-04-27T02:08:29.234881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Hi' None\n",
      "'.' None\n",
      "' How' None\n",
      "' are' None\n",
      "' you' None\n",
      "'?' None\n",
      "'' stop\n"
     ]
    }
   ],
   "source": [
    "for tok, full in stream_with_stop(res):\n",
    "    print(repr(tok), full['finish_reason'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost estimator\n",
    "\n",
    "Since the stopword removal for a backend with native streaming currently only helps gooseai, I want to get a better sense of how often gooseai is actually cost effective. Write function to compute:\n",
    "- openai cost\n",
    "- gooseai cost\n",
    "- which one is cheaper\n",
    "- evaluate over a range of possible prompt lengths and output lengths\n",
    "    - maybe plot\n",
    "- consideration: we often specify max_tokens but the actual response could be shorter. Maybe provide an option to use some sort of expected value of return a distribution of possible prices, rather than a single price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:09:57.807341Z",
     "start_time": "2022-04-27T03:09:57.725382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-neo-20b': None,\n",
       " 'gpt-j-6b': None,\n",
       " 'gpt-neo-2-7b': None,\n",
       " 'gpt-neo-1-3b': None,\n",
       " 'gpt-neo-125m': None,\n",
       " 'fairseq-13b': None,\n",
       " 'fairseq-6-7b': None,\n",
       " 'fairseq-2-7b': None,\n",
       " 'fairseq-1-3b': None,\n",
       " 'fairseq-125m': None}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:37:44.997233Z",
     "start_time": "2022-04-27T03:37:44.899356Z"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_cost(completion_length, prompt_length=None, prompt=None):\n",
    "    xor_none(prompt_length, prompt)\n",
    "    \n",
    "    # Gooseai base prices (in cents) cover the input and the first 25 tokens \n",
    "    # of the output. `Per` prices are cents per token.\n",
    "    gooseai_prices = {\n",
    "        'gpt-neo-20b': {'base': 0.002650, 'per': 0.000063},\n",
    "        'fairseq-13b': {'base': 0.001250, 'per': 0.000036},\n",
    "        'fairseq-6-7b': {'base': 0.000450, 'per': 0.000012},\n",
    "        'gpt-j-6b': {'base': 0.000450, 'per': 0.000012},\n",
    "        'gpt-neo-2-7b': {'base': 0.000300, 'per': 0.000008},\n",
    "        'fairseq-2-7b': {'base': 0.000300, 'per': 0.000008},\n",
    "        'gpt-neo-1-3b': {'base': 0.000110, 'per': 0.000003},\n",
    "        'fairseq-1-3b': {'base': 0.000110, 'per': 0.000003},\n",
    "        'gpt-neo-125m': {'base': 0.000035, 'per': 0.000001},\n",
    "        'fairseq-125m': {'base': 0.000035, 'per': 0.000001},\n",
    "    }\n",
    "    # Unlike gooseai, openai charges for both prompt and generation tokens.\n",
    "    # We convert their prices to cents per token.\n",
    "    # TODO: allow passing in name like 'text-ada-001'?\n",
    "    # And/or support passing in engine_i int?\n",
    "    openai_prices = {\n",
    "        'ada': {'per': .0008 / 1_000},\n",
    "        'babbage': {'per': .0012 / 1_000},\n",
    "        'curie': {'per': .0060 / 1_000},\n",
    "        'davinci': {'per': .0600 / 1_000}\n",
    "    }\n",
    "    prompt_length = prompt_length or len(tokenizer.tokenize(prompt))\n",
    "    gooseai_resolved = [\n",
    "        ('gooseai', name, prices['base']*prompt_length \n",
    "              + prices['per']*max(0, completion_length - 25))\n",
    "        for name, prices in gooseai_prices.items()\n",
    "    ]\n",
    "    openai_resolved = [\n",
    "        ('openai', name, prices['per'] * (prompt_length + completion_length))\n",
    "        for name, prices in openai_prices.items()\n",
    "    ]\n",
    "    # Prices are returned in cents.\n",
    "    return pd.DataFrame(\n",
    "        gooseai_resolved + openai_resolved,\n",
    "        columns=['backend', 'engine', 'cost_cents']\n",
    "    ).sort_values('cost_cents', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:37:56.689174Z",
     "start_time": "2022-04-27T03:37:56.582768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debate: Non-zero frequency penalty was initially included by accident, but in at least 1 test removing it noticeably worsened results.\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend</th>\n",
       "      <th>engine</th>\n",
       "      <th>cost_cents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai</td>\n",
       "      <td>babbage</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai</td>\n",
       "      <td>curie</td>\n",
       "      <td>0.005304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-125m</td>\n",
       "      <td>0.020715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-125m</td>\n",
       "      <td>0.020715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai</td>\n",
       "      <td>davinci</td>\n",
       "      <td>0.053040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-1-3b</td>\n",
       "      <td>0.065065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-1-3b</td>\n",
       "      <td>0.065065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-2-7b</td>\n",
       "      <td>0.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-2-7b</td>\n",
       "      <td>0.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-6-7b</td>\n",
       "      <td>0.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-j-6b</td>\n",
       "      <td>0.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-13b</td>\n",
       "      <td>0.739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-20b</td>\n",
       "      <td>1.564925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    backend        engine  cost_cents\n",
       "0    openai           ada    0.000707\n",
       "1    openai       babbage    0.001061\n",
       "2    openai         curie    0.005304\n",
       "3   gooseai  gpt-neo-125m    0.020715\n",
       "4   gooseai  fairseq-125m    0.020715\n",
       "5    openai       davinci    0.053040\n",
       "6   gooseai  gpt-neo-1-3b    0.065065\n",
       "7   gooseai  fairseq-1-3b    0.065065\n",
       "8   gooseai  gpt-neo-2-7b    0.177400\n",
       "9   gooseai  fairseq-2-7b    0.177400\n",
       "10  gooseai  fairseq-6-7b    0.266100\n",
       "11  gooseai      gpt-j-6b    0.266100\n",
       "12  gooseai   fairseq-13b    0.739900\n",
       "13  gooseai   gpt-neo-20b    1.564925"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt('debate', 'A hot dog is a sandwich.')['prompt']\n",
    "cost_res = estimate_cost(completion_length=300, prompt=prompt)\n",
    "cost_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:38:16.208506Z",
     "start_time": "2022-04-27T03:38:16.105390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend</th>\n",
       "      <th>engine</th>\n",
       "      <th>cost_cents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai</td>\n",
       "      <td>babbage</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai</td>\n",
       "      <td>curie</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-125m</td>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-125m</td>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-1-3b</td>\n",
       "      <td>0.007190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-1-3b</td>\n",
       "      <td>0.007190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai</td>\n",
       "      <td>davinci</td>\n",
       "      <td>0.008340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-2-7b</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-2-7b</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-6-7b</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-j-6b</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-13b</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-20b</td>\n",
       "      <td>0.172750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    backend        engine  cost_cents\n",
       "0    openai           ada    0.000111\n",
       "1    openai       babbage    0.000167\n",
       "2    openai         curie    0.000834\n",
       "3   gooseai  gpt-neo-125m    0.002290\n",
       "4   gooseai  fairseq-125m    0.002290\n",
       "5   gooseai  gpt-neo-1-3b    0.007190\n",
       "6   gooseai  fairseq-1-3b    0.007190\n",
       "7    openai       davinci    0.008340\n",
       "8   gooseai  gpt-neo-2-7b    0.019600\n",
       "9   gooseai  fairseq-2-7b    0.019600\n",
       "10  gooseai  fairseq-6-7b    0.029400\n",
       "11  gooseai      gpt-j-6b    0.029400\n",
       "12  gooseai   fairseq-13b    0.081800\n",
       "13  gooseai   gpt-neo-20b    0.172750"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = conv.kwargs('Jeremy Howard', return_prompt=True)['prompt'] \\\n",
    "    + '\\n\\nMe: Hi Jeremy.\\n\\nJeremy Howard:'\n",
    "estimate_cost(prompt=prompt, completion_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:44:14.040243Z",
     "start_time": "2022-04-27T03:44:13.954905Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_lengths = np.arange(1, 2048, 10)\n",
    "completion_lengths = np.arange(1, 2048, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:50:21.712791Z",
     "start_time": "2022-04-27T03:50:03.288737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5869fb9c94948f3adad7977e02f7833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_dfs = {\n",
    "    (p_len, c_len): estimate_cost(c_len, prompt_length=p_len)\n",
    "    for p_len, c_len in \n",
    "    tqdm(product(prompt_lengths, completion_lengths), \n",
    "         total=len(prompt_lengths) * len(completion_lengths))\n",
    "    if p_len + c_len <= 2_048\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:50:27.041181Z",
     "start_time": "2022-04-27T03:50:26.962613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21115"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cost_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T03:50:30.472482Z",
     "start_time": "2022-04-27T03:50:30.403887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend</th>\n",
       "      <th>engine</th>\n",
       "      <th>cost_cents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai</td>\n",
       "      <td>babbage</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai</td>\n",
       "      <td>curie</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-125m</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-125m</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-1-3b</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-1-3b</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai</td>\n",
       "      <td>davinci</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-2-7b</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-2-7b</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-6-7b</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-j-6b</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>fairseq-13b</td>\n",
       "      <td>0.001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gooseai</td>\n",
       "      <td>gpt-neo-20b</td>\n",
       "      <td>0.002650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    backend        engine  cost_cents\n",
       "0    openai           ada    0.000002\n",
       "1    openai       babbage    0.000002\n",
       "2    openai         curie    0.000012\n",
       "3   gooseai  gpt-neo-125m    0.000035\n",
       "4   gooseai  fairseq-125m    0.000035\n",
       "5   gooseai  gpt-neo-1-3b    0.000110\n",
       "6   gooseai  fairseq-1-3b    0.000110\n",
       "7    openai       davinci    0.000120\n",
       "8   gooseai  gpt-neo-2-7b    0.000300\n",
       "9   gooseai  fairseq-2-7b    0.000300\n",
       "10  gooseai  fairseq-6-7b    0.000450\n",
       "11  gooseai      gpt-j-6b    0.000450\n",
       "12  gooseai   fairseq-13b    0.001250\n",
       "13  gooseai   gpt-neo-20b    0.002650"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_dfs[1, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
