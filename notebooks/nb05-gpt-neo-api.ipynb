{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "`Try getting GPT Neo predictions using the Huggingface API.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T03:47:11.819457Z",
     "start_time": "2021-05-26T03:47:11.803281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:03:50.878646Z",
     "start_time": "2021-05-26T04:03:50.803352Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key\n",
    "from jabberwocky.utils import load_huggingface_api_key\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T03:47:52.065588Z",
     "start_time": "2021-05-26T03:47:52.035290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:15:31.706275Z",
     "start_time": "2021-05-26T04:15:31.627561Z"
    }
   },
   "outputs": [],
   "source": [
    "HF_API_KEY = load_huggingface_api_key()\n",
    "HEADERS = {'Authorization': f'Bearer api_{HF_API_KEY}'}\n",
    "URL_FMT = 'https://api-inference.huggingface.co/models/{}'\n",
    "# These accept different parameters. For now just start with the basics, but\n",
    "# keep these around in case I want to do something with them later.\n",
    "_task2suff = {'generate': 'EleutherAI/gpt-neo-2.7B',\n",
    "              'summarize': 'facebook/bart-large-cnn',\n",
    "              'chat': 'microsoft/DialoGPT-large',\n",
    "              'q&a': 'deepset/roberta-base-squad2'}\n",
    "TASK2URL = DotDict({k: URL_FMT.format(v) for k, v in _task2suff.items()})\n",
    "NEO_URL = URL_FMT.format(_task2suff['generate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:25:01.318190Z",
     "start_time": "2021-05-26T04:25:01.260582Z"
    }
   },
   "outputs": [],
   "source": [
    "def query_gpt_neo(prompt, top_k=None, top_p=None, temperature=1.0, \n",
    "                  repetition_penalty=None, max_tokens=256, api_key=None,\n",
    "                  **kwargs):\n",
    "    headers = {'Authorization': \n",
    "               f'Bearer api_{api_key or load_huggingface_api_key()}'}\n",
    "    # Notice the names don't always align with parameter names - I wanted \n",
    "    # those to be more consistent with query_gpt3() function.\n",
    "    data = {'input': prompt, 'top_k': top_k, 'top_p': top_p, \n",
    "            'temperature': temperature, 'max_new_tokens': max_tokens}\n",
    "    r = requests.post(NEO_URL, headers=headers, data=json.dumps(data))\n",
    "    return r.json()\n",
    "#     return r.json()[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:25:03.707511Z",
     "start_time": "2021-05-26T04:25:03.265889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'generated_text': 'input>\\n\\nThe code of the form is the same as the one used for the other forms in the page:\\n<form id=\"form2\" action=\"index.php\" method=\"post\">\\n    <input type=\"'}], [{'generated_text': 'top_k, k=0 ... N) of size N x 4\\n\\nThe values within the matrix are as follows:\\n0 = value_0\\n1 = value_1\\n2 = value_2\\n3 = value_3'}], [{'generated_text': 'top_pwm1_cntl),\\n\\t(0x0f110000 + 0x20 * i + 0x9b * 2) = PM_CTRL1_PWM_OFF_FAST,\\n\\t'}], [{'generated_text': 'temperature (5-40°C), and humidity.\\n\\nProtein recovery was calculated as the remaining protein percentage per total soluble protein content after precipitation. Protein recovery percentage was calculated as follows:\\n\\nProtein recovery (%) = (Protein'}], [{'generated_text': 'max_new_tokens=50,token_limit=10**\\n\\nNote that this is just one of many ways you can change your token limit. This is just an example.\\nHere are some more options:\\n\\nSet'}]]\n"
     ]
    }
   ],
   "source": [
    "text = 'Why does the'\n",
    "res = query_gpt_neo(text)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:26:33.844486Z",
     "start_time": "2021-05-26T04:26:33.775669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input>\n",
      "\n",
      "The code of the form is the same as the one used for the other forms in the page:\n",
      "<form id=\"form2\" action=\"index.php\" method=\"post\">\n",
      "    <input type=\"\n",
      "top_k, k=0 ... N) of size N x 4\n",
      "\n",
      "The values within the matrix are as follows:\n",
      "0 = value_0\n",
      "1 = value_1\n",
      "2 = value_2\n",
      "3 = value_3\n",
      "top_pwm1_cntl),\n",
      "\t(0x0f110000 + 0x20 * i + 0x9b * 2) = PM_CTRL1_PWM_OFF_FAST,\n",
      "\t\n",
      "temperature (5-40°C), and humidity.\n",
      "\n",
      "Protein recovery was calculated as the remaining protein percentage per total soluble protein content after precipitation. Protein recovery percentage was calculated as follows:\n",
      "\n",
      "Protein recovery (%) = (Protein\n",
      "max_new_tokens=50,token_limit=10**\n",
      "\n",
      "Note that this is just one of many ways you can change your token limit. This is just an example.\n",
      "Here are some more options:\n",
      "\n",
      "Set\n"
     ]
    }
   ],
   "source": [
    "for row in res:\n",
    "    print(row[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:22:58.640691Z",
     "start_time": "2021-05-26T04:22:57.851528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does the world go so crazy so quickly???\n",
      "\n",
      "If you are a person who has experienced any time of loss, pain or sadness you should know just how overwhelming life can be during that time.\n",
      "\n",
      "The best way to get through an\n"
     ]
    }
   ],
   "source": [
    "dates_kwargs = load_prompt('short_dates', verbose=False)\n",
    "res = query_gpt_neo(**dates_kwargs)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:23:58.322141Z",
     "start_time": "2021-05-26T04:23:57.939766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does the world go so crazy so quickly???\n",
      "\n",
      "If you are a person who has experienced any time of loss, pain or sadness you should know just how overwhelming life can be during that time.\n",
      "\n",
      "The best way to get through an\n"
     ]
    }
   ],
   "source": [
    "res = query_gpt_neo('What makes fish so')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
