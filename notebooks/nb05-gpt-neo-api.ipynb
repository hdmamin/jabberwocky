{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "`Try getting GPT Neo predictions using the Huggingface API.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T03:47:11.819457Z",
     "start_time": "2021-05-26T03:47:11.803281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:03:50.878646Z",
     "start_time": "2021-05-26T04:03:50.803352Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key\n",
    "from jabberwocky.utils import load_huggingface_api_key\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T03:47:52.065588Z",
     "start_time": "2021-05-26T03:47:52.035290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:15:31.706275Z",
     "start_time": "2021-05-26T04:15:31.627561Z"
    }
   },
   "outputs": [],
   "source": [
    "HF_API_KEY = load_huggingface_api_key()\n",
    "HEADERS = {'Authorization': f'Bearer api_{HF_API_KEY}'}\n",
    "URL_FMT = 'https://api-inference.huggingface.co/models/{}'\n",
    "# These accept different parameters. For now just start with the basics, but\n",
    "# keep these around in case I want to do something with them later.\n",
    "_task2suff = {'generate': 'EleutherAI/gpt-neo-2.7B',\n",
    "              'summarize': 'facebook/bart-large-cnn',\n",
    "              'chat': 'microsoft/DialoGPT-large',\n",
    "              'q&a': 'deepset/roberta-base-squad2'}\n",
    "TASK2URL = DotDict({k: URL_FMT.format(v) for k, v in _task2suff.items()})\n",
    "NEO_URL = URL_FMT.format(_task2suff['generate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T02:43:36.042772Z",
     "start_time": "2021-05-27T02:43:35.984255Z"
    }
   },
   "outputs": [],
   "source": [
    "def query_gpt_neo(prompt, top_k=None, top_p=None, temperature=1.0, \n",
    "                  repetition_penalty=None, max_tokens=256, api_key=None,\n",
    "                  **kwargs):\n",
    "    headers = {'Authorization': \n",
    "               f'Bearer api_{api_key or load_huggingface_api_key()}'}\n",
    "    # Notice the names don't always align with parameter names - I wanted \n",
    "    # those to be more consistent with query_gpt3() function.\n",
    "    data = {'inputs': prompt, 'top_k': top_k, 'top_p': top_p, \n",
    "            'temperature': temperature, 'max_new_tokens': max_tokens}\n",
    "    r = requests.post(NEO_URL, headers=headers, data=json.dumps(data))\n",
    "    return prompt, r.json()\n",
    "#     return r.json()[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T02:44:30.528377Z",
     "start_time": "2021-05-27T02:44:27.739166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'I love to think I can do things like this myself, but honestly, I know not if it\\'s \"fun\" for me, my family, or my coworkers. I want to take it to the next level, but I\\'m a bit nervous'}]\n"
     ]
    }
   ],
   "source": [
    "text = 'I love to'\n",
    "prompt, res = query_gpt_neo(text, max_tokens=12)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T02:44:34.355399Z",
     "start_time": "2021-05-27T02:44:34.308760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love to think I can do things like this myself, but honestly, I know not if it's \"fun\" for me, my family, or my coworkers. I want to take it to the next level, but I'm a bit nervous\n"
     ]
    }
   ],
   "source": [
    "print(res[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T02:43:40.748768Z",
     "start_time": "2021-05-27T02:43:40.685817Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0dade9c25905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for row in res:\n",
    "    print(row[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:22:58.640691Z",
     "start_time": "2021-05-26T04:22:57.851528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does the world go so crazy so quickly???\n",
      "\n",
      "If you are a person who has experienced any time of loss, pain or sadness you should know just how overwhelming life can be during that time.\n",
      "\n",
      "The best way to get through an\n"
     ]
    }
   ],
   "source": [
    "dates_kwargs = load_prompt('short_dates', verbose=False)\n",
    "res = query_gpt_neo(**dates_kwargs)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T04:23:58.322141Z",
     "start_time": "2021-05-26T04:23:57.939766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does the world go so crazy so quickly???\n",
      "\n",
      "If you are a person who has experienced any time of loss, pain or sadness you should know just how overwhelming life can be during that time.\n",
      "\n",
      "The best way to get through an\n"
     ]
    }
   ],
   "source": [
    "res = query_gpt_neo('What makes fish so')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
