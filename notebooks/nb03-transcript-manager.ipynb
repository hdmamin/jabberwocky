{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Start tying openai and youtube functionality together to manage the punctuation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T20:44:46.290749Z",
     "start_time": "2021-04-24T20:44:46.250880Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T20:58:25.316377Z",
     "start_time": "2021-04-24T20:58:25.257986Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from jabberwocky.openai_utils import query_gpt3\n",
    "from jabberwocky.utils import load_prompt\n",
    "from jabberwocky.youtube import realign_punctuated_text, get_transcripts, \\\n",
    "    text_segment, video_id\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T20:46:32.729227Z",
     "start_time": "2021-04-24T20:46:32.701229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T21:45:40.229005Z",
     "start_time": "2021-04-24T21:45:40.181204Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnpunctuatedTranscript:\n",
    "    \n",
    "    def __init__(self, df_gen, **kwargs):\n",
    "        self.df_gen = df_gen\n",
    "        self.df_punct = self.df_gen.copy()\n",
    "        self.df_punct['text'] = np.nan\n",
    "        # TODO: adjust so prompt template saved separately from prompt_kwargs.\n",
    "        # TODO: adjust load_prompt to have option to skip .format call \n",
    "        # if no text passed in.\n",
    "        self.prompt_fmt = load_prompt('punctuate', **kwargs)\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        # TODO: maybe should return self.df_punct, possibly after punct query? \n",
    "        # Unsure.\n",
    "        return self.df_gen\n",
    "    \n",
    "    # Not sure yet about this interface.\n",
    "#     def _punctuate_chunk(self, ...):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T21:44:15.242699Z",
     "start_time": "2021-04-24T21:44:15.213814Z"
    }
   },
   "outputs": [],
   "source": [
    "class PunctuatedTranscript:\n",
    "    \n",
    "    def __init__(self, df_gen, df_punct, **kwargs):\n",
    "        \"\"\"\n",
    "        kwargs:\n",
    "            Just for compatibility with UnpunctuatedTranscript, which needs\n",
    "            these to specify args like 'rstrip' when loading a prompt.\n",
    "        \"\"\"\n",
    "        self.df_gen = df_gen\n",
    "        self.df_punct = df_punct\n",
    "        \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self.df_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T21:43:34.004742Z",
     "start_time": "2021-04-24T21:43:33.856325Z"
    }
   },
   "outputs": [],
   "source": [
    "@auto_repr\n",
    "class Transcript:\n",
    "    \n",
    "    def __init__(self, url, **kwargs):\n",
    "        self.url = url\n",
    "        self.id = video_id(url)\n",
    "        self._transcript = self._fetch_transcripts(url, **kwargs)\n",
    "        self.is_generated = isinstance(self._transcript,\n",
    "                                       UnpunctuatedTranscript)\n",
    "        self.start_time, self.end_time = self.df.start.ends(1)\n",
    "            \n",
    "    def time_range(self, start, end, full_sentences=True):\n",
    "        assert end > start, 'End time must be later than start time.'\n",
    "        assert start > 0 and end > 0, 'Times must be non-negative.'\n",
    "\n",
    "        df = self.df\n",
    "        if start < self.start_time:\n",
    "            start_idx = 0\n",
    "        else:\n",
    "            start_idx = df.loc[df.start <= start].index[-1]\n",
    "\n",
    "        if end > df.start.iloc[-1]:\n",
    "            end_idx = df.tail(1).index[0]\n",
    "        else:\n",
    "            end_idx = df.loc[df.start >= end].index[0]\n",
    "        return df.iloc[start_idx:end_idx+1]\n",
    "#         return ' '.join(df.iloc[start_idx:end_idx+1].text)\n",
    "    \n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._transcript.df\n",
    "    \n",
    "    def _fetch_transcripts(self, url, **kwargs):\n",
    "        \"\"\"Wrapper to fetch youtube transcripts and create the appropriate\n",
    "        transcript object depending on whether a manually generated (i.e.\n",
    "        punctuated) transcript was retrieved.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        url: str\n",
    "        verbose: bool\n",
    "        \"\"\"\n",
    "        df_gen, df_man, _ = self.get_transcripts(\n",
    "            url, verbose=kwargs.get('verbose', True)\n",
    "        )\n",
    "        if df_man is None:\n",
    "            return UnpunctuatedTranscript(df_gen, **kwargs)\n",
    "        else:\n",
    "            return PunctuatedTranscript(df_gen, df_man, **kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_transcripts(url, verbose=True):\n",
    "        \"\"\"Fetch one or more transcripts for a youtube video given its URL.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        url: str\n",
    "            Don't include any channel-related suffix. E.G. use\n",
    "            https://www.youtube.com/watch?v=OZbCRN3C_Hs, not\n",
    "            https://www.youtube.com/watch?v=OZbCRN3C_Hs&ab_channel=BBC.\n",
    "        verbose: bool\n",
    "            Warn\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DotDict: Contains keys 'id' (maps to video ID str), 'generated',\n",
    "        and 'manual' (the latter two lap to pandas dfs or None if no \n",
    "        transcript was found). Manual transcripts are human-created.\n",
    "        Generated transcripts are a bit lower quality and tend to lack\n",
    "        punctuation.\n",
    "        \"\"\"\n",
    "        langs = ['en', 'en-GB']\n",
    "        id_ = video_id(url)\n",
    "        res = {'generated': None, 'manual': None}\n",
    "        trans_list = YouTubeTranscriptApi.list_transcripts(id_)\n",
    "        res['generated'] = trans_list.find_generated_transcript(langs)\n",
    "        try:\n",
    "            res['manual'] = trans_list.find_manually_created_transcript(langs)\n",
    "        except NoTranscriptFound:\n",
    "            if verbose: warnings.warn('No manual transcript found.')\n",
    "        if verbose:\n",
    "            non_eng = [k for k, v in res.items()\n",
    "                       if v and ('United Kingdom' in v.language)]\n",
    "            if non_eng:\n",
    "                warnings.warn(\n",
    "                    f'{non_eng} {\"has\" if len(non_eng) == 1 else \"have\"} '\n",
    "                    'language en-GB, not en.'\n",
    "                )\n",
    "        return Args(**{k: pd.DataFrame(v.fetch()) if v else v \n",
    "                       for k, v in res.items()},\n",
    "                    id=id_)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{type(self).__name__}(url={self.url}, '\\\n",
    "               f'is_generated={self.is_generated})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T21:43:35.473932Z",
     "start_time": "2021-04-24T21:43:34.387931Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:80: UserWarning: No manual transcript found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should probably adjust max_tokens based on the length of the input. Bumping up to engine 2 or 3 might help a little, but engine 1 is serviceable (probably best to avoid 0 though). You should probably try training a huggingface model to add punctuation instead of using gpt3 credits though.\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transcript(url='https://www.youtube.com/watch?v=AtTsn1Ia4JY&ab_channel=LukeThomas')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.youtube.com/watch?v=AtTsn1Ia4JY&ab_channel=LukeThomas'\n",
    "trans = Transcript(url)\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T21:43:38.056340Z",
     "start_time": "2021-04-24T21:43:38.017781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolutely spectacular fashion knocking</td>\n",
       "      <td>6.879</td>\n",
       "      <td>5.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>out dan hooker in just over a couple of</td>\n",
       "      <td>10.160</td>\n",
       "      <td>2.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>minutes</td>\n",
       "      <td>12.400</td>\n",
       "      <td>3.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>at ufc 257 in the co-main event you want</td>\n",
       "      <td>12.960</td>\n",
       "      <td>5.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to talk about ufc debuts wow but</td>\n",
       "      <td>15.759</td>\n",
       "      <td>4.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how did he do it yes of course a big</td>\n",
       "      <td>18.480</td>\n",
       "      <td>3.360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text   start  duration\n",
       "4   absolutely spectacular fashion knocking   6.879     5.521\n",
       "5   out dan hooker in just over a couple of  10.160     2.800\n",
       "6                                   minutes  12.400     3.359\n",
       "7  at ufc 257 in the co-main event you want  12.960     5.520\n",
       "8          to talk about ufc debuts wow but  15.759     4.561\n",
       "9      how did he do it yes of course a big  18.480     3.360"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.time_range(7, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T21:44:24.471943Z",
     "start_time": "2021-04-24T21:44:24.413251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'engine_i': 1,\n",
       " 'prompt': \"Please add punctuation to these passages so that they are grammatically correct:\\n\\nPassage: thank you I'm honored to be with you today for your commencement from one of the finest universities in the world truth be told I never graduated from college and this is the closest I've ever gotten to a college graduation today I want to tell you three stories from my life that's it no big deal just three stories the first story is about connecting the dots I dropped out of Reed College after the first six months but then stayed around as a drop-in for another 18 months or so before I really quit so why did I drop out it started before I was born my\\n\\nPassage with punctuation: Thank You. I am honored to be with you today at your commencement from one of the finest universities in the world. Truth be told, I never graduated from college and this is the closest I've ever gotten to a college graduation. Today I want to tell you three stories from my life. That's it. No big deal. Just three stories. The first story is about connecting the dots. I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out? It started before I was born. My\\n\\nPassage: them to exonerate the person a literature showing that a disproportionate share of female aggression comes around the time of menses next one there is an area the brain you will know so much about over the next three months called the amygdala that has something to do with aggression and has something to do with fear and you get a brain tumor there and in a number of cases you get someone who is uncontrollably violent and this has also been used successfully in a court of law junk food any of you who are San\\n\\nPassage with punctuation: them to exonerate the person. A literature showing that a disproportionate share of female aggression comes around the time of menses. Next one - there is an area of the brain you will know so much about over the next three months called the amygdala that has something to do with aggression and has something to do with fear. And you get a brain tumor there, and in a number of cases, you get someone who is uncontrollably violent. And this has also been used successfully in a court of law. Junk food-- any of you who are San\\n\\nPassage: two facts that fall within the same category next example remember back at various points of anxiety during exams in such back-when where there was a world of difference between getting a 65 on a test in a 66 on a test not particularly different but because there's this boundary drawn there between passing and failing there is this dramatic differentiating we make when you put a boundaries you have trouble seeing how similar things are on either side of it next example one additional problem that you get when you\\n\\nPassage with punctuation: two facts that fall within the same category. Next example. I remember back at various points of anxiety during exams, and such back when where there was a world of difference between getting a 65 on a test and a 66 on a test. Not particularly different. But because there is this boundary drawn there between passing and failing, there is this dramatic differentiating we make. When you put up boundaries, you have trouble seeing how similar things are on either side of it. Next example, one\\nadditional problem that you get when you\\n\\nPassage: welcome to the final video of this machine learning class we've been through a lot of different videos together in this video I like to just quickly summarize the main topics of this class and then say a few words at the end and that will wrap up the class so what are we done in this class we spent a lot of time talking about supervised learning algorithms like linear regression logistic Russian neural networks SVM's for problems where you have labeled data and labeled examples and we also spent a lot of time talking about unsupervised learning algorithms like team is clustering principal components analysis for dimensionality reduction and anomaly detection algorithms for when you have only unlabeled data although anomaly detection can also use some label data to evaluate the algorithm we also spend some time talking about special applications or special topics like recommender systems\\n\\nPassage with punctuation: Welcome to the final video of this machine learning class. We've been through a lot of different videos together. In this video, I'd like to just quickly summarize the main topics of this class and then say a few words at the end, and that will wrap up the class. So what have we done in this class? We spent a lot of time talking about supervised learning algorithms like linear regression, logistic regression, neural networks, and SVM's for problems where you have labeled data and labeled examples. We also spent a lot of time talking about unsupervised learning algorithms like k-means clustering, principal component analysis for dimensioality reduction, and anomaly detection algorithms for when you have only unlabeled data (although anomaly detection can also use some labeled data to evaluate the algorithm). We also spent some time talking about special applications or special topics like recommender systems.\\n\\nPassage: \\n\\nPassage with punctuation:\",\n",
       " 'stop': ['Passage: ', 'Passage with punctuation: '],\n",
       " 'strip_output': True,\n",
       " 'temperature': 0.1}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans._transcript.prompt_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
