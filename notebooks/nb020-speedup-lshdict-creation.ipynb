{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "See if we can speed up lshdict instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:16:58.487790Z",
     "start_time": "2022-06-19T23:16:58.350459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:17:01.627123Z",
     "start_time": "2022-06-19T23:17:01.518745Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from alexa.utils import get_number\n",
    "from jabberwocky.config import C\n",
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key\n",
    "from jabberwocky.utils import ReturningThread\n",
    "from htools import *\n",
    "from htools.structures import _FuzzyDictBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T02:53:33.198550Z",
     "start_time": "2022-06-18T02:53:33.154094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:42:01.114335Z",
     "start_time": "2022-06-18T17:42:01.039144Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: remove \"New\" prefix when porting.\n",
    "class NewLSHDict(_FuzzyDictBase):\n",
    "    \"\"\"Dictionary that returns the value corresponding to a key's nearest\n",
    "    neighbor if the key isn't present in the dict. This is intended for use\n",
    "    as a word2index dict when using embeddings in deep learning: e.g. if we\n",
    "    have domain embeddings for the top 100k websites, some of our options for\n",
    "    dealing with unknown domains are:\n",
    "\n",
    "    1. Encode all of them as <UNK>. This loses a lot of information.\n",
    "    2. Create a FuzzyKeyDict which will search for similar keys using variants\n",
    "    of Levenshtein distance. Lookup is O(N) and for 100k domains, that comes\n",
    "    out to 0.6 seconds per item. We might have thousands or millions of\n",
    "    lookups over the course of training so this can be a significant cost.\n",
    "    3. Create an LSHDict (lookups are O(1)). Indexing into the dict as usual\n",
    "    (e.g. my_lsh_dict[key]) will provide the key's index if present and the\n",
    "    (approximate) nearest neighbor's index otherwise. Either way, the result\n",
    "    can be used to index into your embedding layer.\n",
    "    4. Create an LSHDict and use the `similar_values` method to return n>1\n",
    "    neighbors. Then pass their indices to an Embedding layer and\n",
    "    compute the sum/average/weighted average of the results. This may be\n",
    "    preferable to #3 cases such as web domain lookup, where similar URLs are\n",
    "    not guaranteed to represent similar sites. (This is basically\n",
    "    equivalent to an EmbeddingBag layer, but in torch that doesn't store\n",
    "    intermediate representations so we wouldn't be able to use our pretrained\n",
    "    embeddings.)\n",
    "\n",
    "    LSHDict does NOT support pickling as of version 6.0.6 (note: setitem seems\n",
    "    to be called before init when unpickling, meaning we try to access\n",
    "    self.forest in self._update_forest before it's been defined. Even if we\n",
    "    change setitem so reindexing does not occur by default, it still tries to\n",
    "    hash the new word and add it to the forest so unpickling will still fail).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, n_candidates=None, n_keys=3, ngram_size=3,\n",
    "                 scorer=fuzz.ratio, chunksize=100):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: dict or list[tuple]\n",
    "            The base dictionary. Unlike FuzzyKeyDict, we require this since\n",
    "            adding items one by one is computationally infeasible for large\n",
    "            datasets. Just build up your dictionary first.\n",
    "        n_candidates: int or None\n",
    "            Number of reasonably similar keys to retrieve when trying to index\n",
    "            in with a key that's missing (or when using the `similar` method).\n",
    "            You can override this in `similar` but not when using\n",
    "            __getitem__'s square bracket syntax. If not specified, this will\n",
    "            be auto initialized to vocab size/1,000, clipped to lie in\n",
    "            [20, 500]. See `similar` docstring for more on this.\n",
    "        n_keys: int\n",
    "            Default number of similar keys to retrieve in `similar`.\n",
    "        scorer: function\n",
    "            Default scoring function to use to narrow `n_candidates` keys down\n",
    "            to `n_keys`. Should be a fuzzywuzzy function where scores lie in\n",
    "            [0, 100] and higher values indicate high similarity.\n",
    "        chunksize: int\n",
    "            Determines how many items to send to each process when hashing\n",
    "            all the keys in the input data using multiprocessing. The default\n",
    "            should be fine in most cases.\n",
    "        \"\"\"\n",
    "        if len(data) < 10_000 and len(next(iter(data))) < 100:\n",
    "            warnings.warn(\n",
    "                'It looks like you\\'re working with a relatively small '\n",
    "                'amount of data. FuzzyKeyDict may be fast enough for your '\n",
    "                'use case and would provide the set of strictly most similar '\n",
    "                'keys rather than an approximation of that set.'\n",
    "            )\n",
    "\n",
    "        super().__init__(data)\n",
    "        self.scorer = scorer\n",
    "        self.hash_word = partial(self.lsh_hash_word, n=ngram_size)\n",
    "        self.forest = MinHashLSHForest(num_perm=128)\n",
    "        self.chunksize = chunksize\n",
    "        self._initialize_forest()\n",
    "\n",
    "        # Datasketch's LSH implementation usually gives pretty decent results\n",
    "        # even with numbers as low as 5-10, but increasing that by a factor of\n",
    "        # 10 comes with minimal time cost: Fuzzywuzzy matching doesn't get\n",
    "        # particularly slow until we get into the thousands. The fact that\n",
    "        # we cap this at 500 makes this lookup asymptotically O(1) while\n",
    "        # FuzzyKeyDict's is O(N).\n",
    "        self.n_candidates = n_candidates or np.clip(len(self) // 1_000,\n",
    "                                                    20, 500)\n",
    "        self.n_keys = n_keys\n",
    "\n",
    "    def __setitem__(self, key, val):\n",
    "        \"\"\"Try to add keys all at once in the constructor because adding new\n",
    "        keys can be extremely slow.\n",
    "        \"\"\"\n",
    "        super().__setitem__(key, val)\n",
    "        self._update_forest(key)\n",
    "\n",
    "    def _update_forest(self, key, index=True):\n",
    "        \"\"\"Used in __setitem__ to update our LSH Forest. Forest's index method\n",
    "        seems to recompute everything so adding items to a large LSHDict will\n",
    "        be incredibly slow. Luckily, our deep learning use case rarely/never\n",
    "        requires us to update object2index dicts after instantiation so that's\n",
    "        not as troubling as it might seem.\n",
    "        \n",
    "        This used to be used by _initialize_forest as well but it didn't lend\n",
    "        itself to parallelization as well since it acts on a shared, existing\n",
    "        data structure.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key: str\n",
    "        index: bool\n",
    "            If True, reindex the forest (essentially making the key\n",
    "            queryable). This should be False when initializing the forest so\n",
    "            we just index once after everything's been added.\n",
    "        \"\"\"\n",
    "        self.forest.add(key, self.hash_word(key))\n",
    "        if index: self.forest.index()\n",
    "\n",
    "    def _initialize_forest(self):\n",
    "        \"\"\"Called once in __init__ to add all items to LSH Forest. This is\n",
    "        necessary because dict specifically calls its own __setitem__, not\n",
    "        its children's.\n",
    "        \"\"\"\n",
    "        hashes = parallelize(self.hash_word, self.keys(), total=len(self),\n",
    "                             chunksize=self.chunksize)\n",
    "        for hash_, key in zip(hashes, self.keys()):\n",
    "            self.forest.add(key, hash_)\n",
    "        self.forest.index()\n",
    "\n",
    "    @add_docstring(_FuzzyDictBase._filter_similarity_pairs)\n",
    "    def similar(self, key, mode='keys_values', n_candidates=None,\n",
    "                n_keys=None, scorer=None):\n",
    "        \"\"\"Find a list of similar keys. This is used in __getitem__ but can\n",
    "        also be useful as a user-facing method if you want to get more than\n",
    "        1 neighbor or you want to get similarity scores as well.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key: str\n",
    "            Word/URL/etc. to find similar keys to.\n",
    "        mode: str\n",
    "            See section below `Returns`.\n",
    "        n_candidates: int or None\n",
    "            Number of similar candidates to retrieve. This uses Jaccard\n",
    "            Similarity which isn't always a great metric for string\n",
    "            similarity. This is also where the LSH comes in so they're not\n",
    "            strictly the n best candidates, but rather a close approximation\n",
    "            of that set. If None, this will fall back to self.n_candidates.\n",
    "            Keep in mind this determines how many keys to\n",
    "        n_keys: int or None\n",
    "            Number of similar keys to return. If None, this will fall back to\n",
    "            self.n_keys.\n",
    "        scorer: function or None\n",
    "            Fuzzywuzzy scoring function, e.g. fuzz.ratio or\n",
    "            fuzz.partial_ratio, which will be used to score each candidate and\n",
    "            select which to return. Higher scores indicate higher levels of\n",
    "            similarity. If None, this will fall back to self.scorer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list: List if `mode` is \"keys\" or \"values\". List of tuples otherwise.\n",
    "        \"\"\"\n",
    "        candidates = self.forest.query(self.hash_word(key),\n",
    "                                       n_candidates or self.n_candidates)\n",
    "        if not candidates: raise KeyError('No similar keys found.')\n",
    "\n",
    "        # List of (key, score) where higher means more similar.\n",
    "        pairs = process.extract(key, candidates,\n",
    "                                limit=n_keys or self.n_keys,\n",
    "                                scorer=scorer or self.scorer)\n",
    "        return self._filter_similarity_pairs(pairs, mode=mode)\n",
    "\n",
    "    @staticmethod\n",
    "    @add_docstring(ngrams)\n",
    "    def lsh_hash_word(word, num_perm=128, **ngram_kwargs):\n",
    "        \"\"\"Hash an input word (str) and return a MinHash object that can be\n",
    "        added to an LSHForest.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        word: str\n",
    "            Word to hash.\n",
    "        num_perm: int\n",
    "        ngram_kwargs: any\n",
    "            Forwarded to `ngrams`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        datasketch MinHash object\n",
    "        \"\"\"\n",
    "        mhash = MinHash(num_perm=num_perm)\n",
    "        for ng in ngrams(word, **ngram_kwargs):\n",
    "            mhash.update(ng.encode('utf8'))\n",
    "        return mhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:41:23.535797Z",
     "start_time": "2022-06-18T17:41:23.465239Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_utterance_map(model_json, fuzzy=True,\n",
    "                        exclude_types=('AMAZON.Person', 'AMAZON.SearchQuery'),\n",
    "                        save_=False, model_path='data/alexa/dialog_model.json',\n",
    "                        meta_path='data/alexa/utterance2meta.pkl',\n",
    "                        min_num=0, max_num=100):\n",
    "    \"\"\"Given a dictionary copied from Alexa's JSON Editor, return a\n",
    "    dict or FuzzyKeyDict mapping each possible sample utterance to its\n",
    "    corresponding intent. This allows our delegate() function to do some\n",
    "    utterance validation before blindly forwarding an utterance to _reply() or\n",
    "    the next queued function.\n",
    "\n",
    "    Warning: because each intent may have several utterances and\n",
    "    each utterance may contain multiple slots and each slot may have multiple\n",
    "    sample values, the dimensionality can blow up quickly here.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_json\n",
    "    exclude_types: Iterable[str]\n",
    "        One or more slot types where we want to exclude intents that contain\n",
    "        any of them from the output map. For example, AMAZON.SearchQuery is\n",
    "        meant to capture whole utterances matching no particular format as a\n",
    "        fallback intent, so it wouldn't make sense to try to fuzzy match\n",
    "        these utterances to an intent. I could see AMAZON.Person being included\n",
    "        in some contexts but in this skill, we only use it for the choosePerson\n",
    "        utterance which consists solely of a name. There really shouldn't be a\n",
    "        reason to fuzzy match that.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict: Maps sample utterance to dict containing 'intent' str and 'slots'\n",
    "    dict.\n",
    "    \"\"\"\n",
    "    exclude_types = set(exclude_types)\n",
    "    model = model_json['interactionModel']['languageModel']\n",
    "    type2vals = {type_['name']: [row['name']['value']\n",
    "                                 for row in type_['values']]\n",
    "                 for type_ in model['types']}\n",
    "    type2vals['AMAZON.NUMBER'] = list(map(str, range(min_num, max_num + 1)))\n",
    "    utt2meta = {}\n",
    "    for intent in model['intents']:\n",
    "        slot2vals = {}\n",
    "        try:\n",
    "            for slot_ in intent.get('slots', []):\n",
    "                assert slot_['type'] not in exclude_types\n",
    "                slot2vals[slot_['name']] = type2vals[slot_['type']]\n",
    "        except AssertionError:\n",
    "            continue\n",
    "\n",
    "        # Replace all slot names with common slot values.\n",
    "        for row in intent['samples']:\n",
    "            for args in product(*slot2vals.values()):\n",
    "                kwargs = dict(zip(slot2vals, args))\n",
    "                utt2meta[row.format(**kwargs)] = {'intent': intent['name'],\n",
    "                                                  'slots': kwargs}\n",
    "    meta = FuzzyKeyDict(utt2meta) if fuzzy else utt2meta\n",
    "    if save_:\n",
    "        save(model_json, model_path)\n",
    "        save(meta, meta_path)\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:07:54.159175Z",
     "start_time": "2022-06-19T23:07:54.055464Z"
    }
   },
   "outputs": [],
   "source": [
    "# More up to date than what was in the lib at the time, but we develop a\n",
    "# more up to date version later in the nb.\n",
    "def infer_intent(\n",
    "    utt,\n",
    "    fuzzy_dict,\n",
    "    n_keys=5,\n",
    "    n_candidates=None,\n",
    "    top_1_thresh=0.9,\n",
    "    weighted_thresh=0.7,\n",
    "):\n",
    "    \"\"\"\n",
    "    Try to infer the user's intent from an utterance. Alexa should detect\n",
    "    this automatically but it sometimes messes up. This also helps if the user\n",
    "    gets the utterance slightly wrong, e.g. \"Lou, set backend to goose ai\"\n",
    "    rather than \"Lou, switch backend to goose ai\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    utt\n",
    "    fuzzy_dict\n",
    "    n_keys\n",
    "    top_1_thresh\n",
    "    weighted_thresh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict: Contains keys \"intent\", \"confidence\", \"reason\", and \"res\".\n",
    "    Intent is the name of the closest matching intent if one was sufficiently\n",
    "    close (empty string otherwise), confidence is a float between 0 and 1\n",
    "    indicating our confidence in this being correct (sort of, not anything\n",
    "    rigorous though; -1 if no matching intent is found), and reason is a string\n",
    "    indicating our method for determining this ('top_1' means we found 1 sample\n",
    "    utterance that was very close to the input, 'weighted' means that most of\n",
    "    the nearest matching utterances tended to belong to the same intent, empty\n",
    "    string means no matching intent was found). Res is always just the raw\n",
    "    results of our fuzzy_dict similar() method call, a list of tuples\n",
    "    containing all n_keys matching utterances, their corresponding intents,\n",
    "    and similarity scores.\n",
    "    \"\"\"\n",
    "    kwargs = dict(n_keys=n_keys, mode='keys_values_similarities')\n",
    "    if isinstance(fuzzy_dict, LSHDict):\n",
    "        kwargs['n_candidates'] = n_candidates\n",
    "    res = fuzzy_dict.similar(utt, **kwargs)\n",
    "    top_1_pct = res[0][-1] / 100\n",
    "    if top_1_pct >= top_1_thresh:\n",
    "        return {'intent': res[0][1]['intent'],\n",
    "                'slots': res[0][1]['slots'],\n",
    "                'confidence': top_1_pct,\n",
    "                'reason': 'top_1',\n",
    "                'res': res}\n",
    "    df = pd.DataFrame(res, columns=['txt', 'intent', 'score'])\\\n",
    "        .assign(slots=lambda df_: df_.intent.apply(lambda x: x['slots']),\n",
    "                intent=lambda df_: df_.intent.apply(lambda x: x['intent']))\n",
    "    weighted = df.groupby('intent').score.sum()\\\n",
    "        .to_frame()\\\n",
    "        .assign(pct=lambda x: x / (n_keys * 100))\n",
    "    if weighted.pct.iloc[0] > weighted_thresh:\n",
    "        intent = weighted.iloc[0].name\n",
    "        slots = df.loc[df.intent == intent, 'slots'].iloc[0]\n",
    "        return {'intent': intent,\n",
    "                'slots': slots,\n",
    "                'confidence': weighted.iloc[0].pct,\n",
    "                'reason': 'weighted',\n",
    "                'res': res}\n",
    "    # In this case, confidence is a bit different but it's loosely intended to\n",
    "    # mean \"confidence that the utterance matched no pre-defined intent\".\n",
    "    # Value simply needs to be higher than 1 - weighted_thresh.\n",
    "    return {'intent': '',\n",
    "            'slots': {},\n",
    "            'confidence': 1 - weighted.iloc[0].pct,\n",
    "            'reason': '',\n",
    "            'res': res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T03:51:24.922922Z",
     "start_time": "2022-06-18T03:51:24.871875Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_intent2utts(fd):\n",
    "    df = pd.DataFrame(fd).T\n",
    "    intent2utts = dict(df.reset_index().groupby('intent')['index'].apply(set).items())\n",
    "    return intent2utts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T02:54:20.900391Z",
     "start_time": "2022-06-18T02:54:20.810524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from data/alexa/dialog_model.json.\n"
     ]
    }
   ],
   "source": [
    "model = load('data/alexa/dialog_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T03:29:35.025172Z",
     "start_time": "2022-06-18T03:29:34.847786Z"
    }
   },
   "outputs": [],
   "source": [
    "fd = build_utterance_map(model, save_=False, max_num=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T03:51:56.117570Z",
     "start_time": "2022-06-18T03:51:54.735357Z"
    }
   },
   "outputs": [],
   "source": [
    "intent2utts = build_intent2utts(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T03:31:32.271039Z",
     "start_time": "2022-06-18T03:30:23.741220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a857429b9904b4ebb45ec23efb1f82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block executed in 68.481 seconds.\n"
     ]
    }
   ],
   "source": [
    "with block_timer():\n",
    "    lsh = LSHDict(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T03:30:17.533091Z",
     "start_time": "2022-06-18T03:29:44.413347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block 'HASHING' executed in 31.848 seconds.\n",
      "[TIMER]: Block 'UPDATE' executed in 1.022 seconds.\n",
      "[TIMER]: Block executed in 33.075 seconds.\n"
     ]
    }
   ],
   "source": [
    "with block_timer():\n",
    "    lsh2 = NewLSHDict(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T03:32:08.332210Z",
     "start_time": "2022-06-18T03:31:33.085565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block 'HASHING' executed in 33.982 seconds.\n",
      "[TIMER]: Block 'UPDATE' executed in 0.967 seconds.\n",
      "[TIMER]: Block executed in 35.201 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Chunksize 100\n",
    "with block_timer():\n",
    "    lsh2 = NewLSHDict(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T03:35:40.366019Z",
     "start_time": "2022-06-18T03:35:02.332588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block 'HASHING' executed in 36.665 seconds.\n",
      "[TIMER]: Block 'UPDATE' executed in 1.029 seconds.\n",
      "[TIMER]: Block executed in 37.956 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Chunksize 100, explicitly set processes=cpu_count()\n",
    "with block_timer():\n",
    "    lsh2 = NewLSHDict(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T03:43:23.237608Z",
     "start_time": "2022-06-18T03:42:13.398189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block executed in 69.805 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Threaded version\n",
    "with block_timer():\n",
    "    lsh2 = NewLSHDict(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:23:11.176364Z",
     "start_time": "2022-06-18T17:23:11.116432Z"
    }
   },
   "outputs": [],
   "source": [
    "utt = 'Lou please change my temp to 36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:23:13.431774Z",
     "start_time": "2022-06-18T17:23:12.938087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'changeTemperature',\n",
       " 'slots': {'Number': '36', 'Scope': 'global'},\n",
       " 'confidence': 0.794,\n",
       " 'reason': 'weighted',\n",
       " 'res': [('Lou change temp to 36',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '36', 'Scope': 'global'}},\n",
       "   81),\n",
       "  ('Lou change temp to 136',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '136', 'Scope': 'global'}},\n",
       "   79),\n",
       "  ('Lou change temp to 236',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '236', 'Scope': 'global'}},\n",
       "   79),\n",
       "  ('Lou change temp to 306',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '306', 'Scope': 'global'}},\n",
       "   79),\n",
       "  ('Lou change temp to 316',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '316', 'Scope': 'global'}},\n",
       "   79)]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_intent(utt, fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 1. First use lsh dict to infer intent, then use fuzzydict to brute force search over all that intent's utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:57:30.087517Z",
     "start_time": "2022-06-18T17:57:29.858357Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block 'lsh block' executed in 0.007 seconds.\n",
      "[TIMER]: Block 'fuzzy block' executed in 0.102 seconds.\n"
     ]
    }
   ],
   "source": [
    "with block_timer('lsh block'):\n",
    "    res = infer_intent(utt, lsh, weighted_thresh=.5)\n",
    "with block_timer('fuzzy block'):\n",
    "    if res['intent']:\n",
    "        utts = intent2utts[res['intent']]\n",
    "        utt_match, score = process.extractOne(utt, utts, scorer=fuzz.ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:57:33.895451Z",
     "start_time": "2022-06-18T17:57:33.826082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lou change temp to 36\n",
      "81\n",
      "{'Number': '36', 'Scope': 'global'}\n"
     ]
    }
   ],
   "source": [
    "print(utt_match)\n",
    "print(score)\n",
    "print(fd[utt_match]['slots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:23:23.739259Z",
     "start_time": "2022-06-18T17:23:23.705480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14416"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intent2utts[res['intent']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 2. Use single lsh dict and have it retrieve a larger group of candidates first before using fuzzywuzzy to re-rank them. Differs from approach 1 in that we brute force search a fixed number of candidates rather than however many sample utts an intent has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:44:01.758252Z",
     "start_time": "2022-06-18T17:44:01.684132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block executed in 0.032 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Use lsh here bc lsh2 used developmental class. Infer_intent checks fuzzy\n",
    "# dict type when determining whether to pass n_candidates to similar() call.\n",
    "with block_timer():\n",
    "    res = infer_intent(utt, lsh, n_candidates=1_000, n_keys=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:48:33.720455Z",
     "start_time": "2022-06-18T17:48:33.675501Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('changeTemperature', {'Number': '36', 'Scope': 'global'})"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['intent'], res['slots']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 3. Current brute force approach. Fuzzy dict search all possible utts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:48:42.362414Z",
     "start_time": "2022-06-18T17:48:41.980446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block executed in 0.339 seconds.\n"
     ]
    }
   ],
   "source": [
    "with block_timer():\n",
    "    res = infer_intent(utt, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T17:48:42.411803Z",
     "start_time": "2022-06-18T17:48:42.366131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('changeTemperature', {'Number': '36', 'Scope': 'global'})"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['intent'], res['slots']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 4. Use LSH dict to infer intent, then if that intent has a Number slot, use separate function to extract number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T18:00:21.179956Z",
     "start_time": "2022-06-18T18:00:21.035179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'changeTemperature',\n",
       " 'slots': {'Number': '358', 'Scope': 'global'},\n",
       " 'confidence': 0.73,\n",
       " 'reason': 'weighted',\n",
       " 'res': [('Lou change temp to 358',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '358', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change temp to 308',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '308', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change temp to 338',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '338', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change global temp to 308',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '308', 'Scope': 'global'}},\n",
       "   70),\n",
       "  ('Lou change global temp to 358',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '358', 'Scope': 'global'}},\n",
       "   70)]}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T18:01:56.351052Z",
     "start_time": "2022-06-18T18:01:56.234686Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block 'lsh block' executed in 0.007 seconds.\n",
      "[TIMER]: Block 'fuzzy block' executed in 0.007 seconds.\n"
     ]
    }
   ],
   "source": [
    "with block_timer('lsh block'):\n",
    "    res = infer_intent(utt, lsh, weighted_thresh=.5)\n",
    "with block_timer('fuzzy block'):\n",
    "    if res['intent']:\n",
    "        if 'Number' in res['slots']:\n",
    "            res['slots']['Number'] = get_number(utt)['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T18:01:56.952221Z",
     "start_time": "2022-06-18T18:01:56.881122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'changeTemperature',\n",
       " 'slots': {'Number': '36', 'Scope': 'global'},\n",
       " 'confidence': 0.73,\n",
       " 'reason': 'weighted',\n",
       " 'res': [('Lou change temp to 358',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '36', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change temp to 308',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '308', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change temp to 338',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '338', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change global temp to 308',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '308', 'Scope': 'global'}},\n",
       "   70),\n",
       "  ('Lou change global temp to 358',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '358', 'Scope': 'global'}},\n",
       "   70)]}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Status**\n",
    "\n",
    "- lshDict method is a little faster but not as much as I hoped (no big O change). Mostly because a single intent can still have a large number of utts so we still end up fuzzy dict searching a big list.\n",
    "- For additional complexity to be worth it, I think I'd need to find some further optimizations. Should be at least an order of magnitude faster to be worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:02:42.916912Z",
     "start_time": "2022-06-19T23:02:41.994629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46983"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:58:22.568233Z",
     "start_time": "2022-06-19T23:58:22.492919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd5 = build_utterance_map(model, save_=False, max_num=5)\n",
    "len(fd5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:06:43.371798Z",
     "start_time": "2022-06-19T23:06:43.266835Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIMER]: Block 'lsh block' executed in 0.007 seconds.\n",
      "[TIMER]: Block 'fuzzy block' executed in 0.009 seconds.\n"
     ]
    }
   ],
   "source": [
    "with block_timer('lsh block'):\n",
    "    res = infer_intent(utt, fd5)\n",
    "with block_timer('fuzzy block'):\n",
    "    if res['intent'] and 'Number' in res['slots']:\n",
    "        res['slots']['Number'] = get_number(utt)['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:06:44.303785Z",
     "start_time": "2022-06-19T23:06:44.233362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'changeTemperature',\n",
       " 'slots': {'Number': '36', 'Scope': 'global'},\n",
       " 'confidence': 0.756,\n",
       " 'reason': 'weighted',\n",
       " 'res': [('Lou change temp to 3',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '36', 'Scope': 'global'}},\n",
       "   78),\n",
       "  ('Lou change temp to 0',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '0', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change temp to 1',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '1', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change temp to 2',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '2', 'Scope': 'global'}},\n",
       "   75),\n",
       "  ('Lou change temp to 4',\n",
       "   {'intent': 'changeTemperature',\n",
       "    'slots': {'Number': '4', 'Scope': 'global'}},\n",
       "   75)]}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:34:51.954919Z",
     "start_time": "2022-06-19T23:34:51.822647Z"
    }
   },
   "outputs": [],
   "source": [
    "def infer_intent(\n",
    "    utt,\n",
    "    fuzzy_dict,\n",
    "    n_keys=5,\n",
    "    n_candidates=None,\n",
    "    top_1_thresh=0.9,\n",
    "    weighted_thresh=0.7,\n",
    "):\n",
    "    \"\"\"\n",
    "    Try to infer the user's intent from an utterance. Alexa should detect\n",
    "    this automatically but it sometimes messes up. This also helps if the user\n",
    "    gets the utterance slightly wrong, e.g. \"Lou, set backend to goose ai\"\n",
    "    rather than \"Lou, switch backend to goose ai\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    utt\n",
    "    fuzzy_dict\n",
    "    n_keys\n",
    "    top_1_thresh\n",
    "    weighted_thresh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict: Contains keys \"intent\", \"confidence\", \"reason\", and \"res\".\n",
    "    Intent is the name of the closest matching intent if one was sufficiently\n",
    "    close (empty string otherwise), confidence is a float between 0 and 1\n",
    "    indicating our confidence in this being correct (sort of, not anything\n",
    "    rigorous though; -1 if no matching intent is found), and reason is a string\n",
    "    indicating our method for determining this ('top_1' means we found 1 sample\n",
    "    utterance that was very close to the input, 'weighted' means that most of\n",
    "    the nearest matching utterances tended to belong to the same intent, empty\n",
    "    string means no matching intent was found). Res is always just the raw\n",
    "    results of our fuzzy_dict similar() method call, a list of tuples\n",
    "    containing all n_keys matching utterances, their corresponding intents,\n",
    "    and similarity scores.\n",
    "    \"\"\"\n",
    "    kwargs = dict(n_keys=n_keys, mode='keys_values_similarities')\n",
    "    if isinstance(fuzzy_dict, LSHDict):\n",
    "        kwargs['n_candidates'] = n_candidates\n",
    "    res = fuzzy_dict.similar(utt, **kwargs)\n",
    "    top_1_pct = res[0][-1] / 100\n",
    "    res_final = {'res': res}\n",
    "    if top_1_pct >= top_1_thresh:\n",
    "        res_final.update(intent=res[0][1]['intent'],\n",
    "                         slots=res[0][1]['slots'],\n",
    "                         confidence=top_1_pct,\n",
    "                         reason='top_1')\n",
    "    else:\n",
    "        df = pd.DataFrame(res, columns=['txt', 'intent', 'score'])\n",
    "        df['slots'] = df.intent.apply(lambda x: x['slots'])\n",
    "        df['intent'] = df.intent.apply(lambda x: x['intent'])\n",
    "        weighted = df.groupby('intent').score.sum()\\\n",
    "            .to_frame()\\\n",
    "            .assign(pct=lambda x: x / (n_keys * 100))\n",
    "\n",
    "    # Only consider weighted method if top 1 check was not satisfied.\n",
    "    if 'intent' not in res_final:\n",
    "        if weighted.pct.iloc[0] > weighted_thresh:\n",
    "            intent = weighted.iloc[0].name\n",
    "            slots = df.loc[df.intent == intent, 'slots'].iloc[0]\n",
    "            res_final.update(intent=intent,\n",
    "                             slots=slots,\n",
    "                             confidence=weighted.iloc[0].pct,\n",
    "                             reason='weighted')\n",
    "        else:\n",
    "            # In this case, confidence is a bit different but it's loosely \n",
    "            # intended to mean \"confidence that the utterance matched no \n",
    "            # pre-defined intent\". Value simply needs to be higher than \n",
    "            # 1 - weighted_thresh.\n",
    "            res_final.update(intent='',\n",
    "                             slots={},\n",
    "                             confidence=1 - weighted.iloc[0].pct,\n",
    "                             reason='')\n",
    "    if res_final['intent'] and 'Number' in res_final['slots']:\n",
    "        res_final['slots']['Number'] = get_number(utt)['value']\n",
    "        # Sometimes no number could be extracted. Unclear what confidence \n",
    "        # score should be here so I just leave it unchanged.\n",
    "        if res_final['slots']['Number'] is None:\n",
    "            res_final['intent'] = ''\n",
    "    return res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:34:52.339362Z",
     "start_time": "2022-06-19T23:34:52.255928Z"
    }
   },
   "outputs": [],
   "source": [
    "positives = [\n",
    "    'lou change temperature to 47',\n",
    "    'lou change my temperature to 100',\n",
    "    'lou set temperature to 95',\n",
    "    'lou use temperature 33',\n",
    "    'lou please change the temperature to 13',\n",
    "    'lou change global temperature to 99',\n",
    "    'lou please set the conversation temperature to 43',\n",
    "    'lou change my person level temperature to 18',\n",
    "    'lou use max length of 14',\n",
    "    'lou change my max length to 52',\n",
    "    'lou set the max length to 9',\n",
    "    'lou please change global max length to 19',\n",
    "    'lou can you change my conversation level max length to 77',\n",
    "    'change max length to 9',\n",
    "    'please set max length to 45',\n",
    "    'could you change my person level temp to 67'\n",
    "]\n",
    "negatives = [\n",
    "    'what is the temperature?',\n",
    "    'can you change that today?',\n",
    "    'change my mind about #23',\n",
    "    'the maximum length that is allowed is 2',\n",
    "    'the global temperature has risen by 3 degrees',\n",
    "    'I am a temp but I want to change that',\n",
    "    'the conversation length is 8',\n",
    "    'lou change temperature to'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T23:34:53.198008Z",
     "start_time": "2022-06-19T23:34:52.884374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE: lou change temperature to 47\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 47, 'Scope': 'global'}, 'confidence': 0.98, 'reason': 'top_1'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou change my temperature to 100\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 100, 'Scope': 'global'}, 'confidence': 0.92, 'reason': 'top_1'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou set temperature to 95\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 95, 'Scope': 'global'}, 'confidence': 0.98, 'reason': 'top_1'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou use temperature 33\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 33, 'Scope': 'global'}, 'confidence': 0.838, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou please change the temperature to 13\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 13, 'Scope': 'global'}, 'confidence': 0.802, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou change global temperature to 99\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 99, 'Scope': 'global'}, 'confidence': 0.96, 'reason': 'top_1'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou please set the conversation temperature to 43\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 43, 'Scope': 'conversation'}, 'confidence': 0.848, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou change my person level temperature to 18\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 18, 'Scope': 'person'}, 'confidence': 0.854, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou use max length of 14\n",
      "{'intent': 'changeMaxLength', 'slots': {'Number': 14, 'Scope': 'global'}, 'confidence': 0.866, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou change my max length to 52\n",
      "{'intent': 'changeMaxLength', 'slots': {'Number': 52, 'Scope': 'global'}, 'confidence': 0.93, 'reason': 'top_1'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou set the max length to 9\n",
      "{'intent': 'changeMaxLength', 'slots': {'Number': 9, 'Scope': 'global'}, 'confidence': 0.88, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou please change global max length to 19\n",
      "{'intent': 'changeMaxLength', 'slots': {'Number': 19, 'Scope': 'global'}, 'confidence': 0.866, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: lou can you change my conversation level max length to 77\n",
      "{'intent': 'changeMaxLength', 'slots': {'Number': 77, 'Scope': 'conversation'}, 'confidence': 0.79, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: change max length to 9\n",
      "{'intent': 'changeMaxLength', 'slots': {'Number': 9, 'Scope': 'global'}, 'confidence': 0.88, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: please set max length to 45\n",
      "{'intent': 'changeMaxLength', 'slots': {'Number': 45, 'Scope': 'global'}, 'confidence': 0.816, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "POSITIVE: could you change my person level temp to 67\n",
      "{'intent': 'changeTemperature', 'slots': {'Number': 67, 'Scope': 'person'}, 'confidence': 0.74, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "NEGATIVE: what is the temperature?\n",
      "{'intent': '', 'slots': {}, 'confidence': 0.36, 'reason': ''}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "NEGATIVE: can you change that today?\n",
      "{'intent': '', 'slots': {}, 'confidence': 0.38, 'reason': ''}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "NEGATIVE: change my mind about #23\n",
      "{'intent': '', 'slots': {}, 'confidence': 0.6639999999999999, 'reason': ''}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "NEGATIVE: the maximum length that is allowed is 2\n",
      "{'intent': '', 'slots': {}, 'confidence': 0.46799999999999997, 'reason': ''}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "NEGATIVE: the global temperature has risen by 3 degrees\n",
      "{'intent': '', 'slots': {}, 'confidence': 0.40800000000000003, 'reason': ''}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "NEGATIVE: I am a temp but I want to change that\n",
      "{'intent': '', 'slots': {}, 'confidence': 0.636, 'reason': ''}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "NEGATIVE: the conversation length is 8\n",
      "{'intent': 'changeMaxLength', 'slots': {'Number': 8, 'Scope': 'conversation'}, 'confidence': 0.72, 'reason': 'weighted'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "NEGATIVE: lou change temperature to\n",
      "{'intent': '', 'slots': {'Number': None, 'Scope': 'global'}, 'confidence': 0.96, 'reason': 'top_1'}\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_pos = len(positives)\n",
    "for i, utt in enumerate(positives + negatives):\n",
    "    inferred = infer_intent(utt, fd5)\n",
    "    print('POSITIVE:' if i < n_pos else 'NEGATIVE:', utt)\n",
    "    print(select(inferred, drop=['res']))\n",
    "    hr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
