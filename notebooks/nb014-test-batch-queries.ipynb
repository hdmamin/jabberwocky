{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Test out new batch query functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:32:45.978870Z",
     "start_time": "2022-04-13T03:32:45.117929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:45:46.933761Z",
     "start_time": "2022-04-13T03:45:46.884062Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key, \\\n",
    "    GPTBackend, query_kwargs_grid, MOCKS, postprocess_gpt_response, \\\n",
    "    containerize, truncate_at_first_stop, query_gpt_mock\n",
    "from jabberwocky.utils import strip\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:32:47.085151Z",
     "start_time": "2022-04-13T03:32:47.047777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:32:47.644277Z",
     "start_time": "2022-04-13T03:32:47.608893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"repeat\".\n"
     ]
    }
   ],
   "source": [
    "gpt = GPTBackend()\n",
    "gpt.switch('repeat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:41:49.862546Z",
     "start_time": "2022-04-13T03:41:49.810037Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess_response(response, n, trunc_full=True, strip_output=True, \n",
    "                         **kwargs):\n",
    "    text, full_response = containerize(*response)\n",
    "    print('TEXT:', text)\n",
    "    print('FULL:', full_response)\n",
    "\n",
    "    # Manually check for stop phrases because most backends either don't\n",
    "    # or truncate AFTER the stop phrase which is rarely what we want.\n",
    "    stop = kwargs.get('stop', [])\n",
    "    clean_text = []\n",
    "    clean_full = []\n",
    "    for i, (text_, resp_) in enumerate(zip(text, full_response)):\n",
    "        text_ = truncate_at_first_stop(\n",
    "            text_,\n",
    "            stop_phrases=stop,\n",
    "            finish_reason=resp_.get('finish_reason', ''),\n",
    "            trunc_full=trunc_full,\n",
    "            trunc_partial=True\n",
    "        )\n",
    "        clean_text.append(strip(text_, strip_output))\n",
    "        clean_full.append({**resp_, 'prompt_index': i // n})\n",
    "\n",
    "    return clean_text, clean_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:36:39.580083Z",
     "start_time": "2022-04-13T03:36:39.523166Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_backend(backend, results=None):\n",
    "    def gen():\n",
    "        yield from results.kwargs\n",
    "        \n",
    "    with gpt(backend):\n",
    "        kwargs_list = []\n",
    "        resp_list = []\n",
    "        gen_kwargs = gen if results else query_kwargs_grid\n",
    "        for i, kwargs in enumerate(gen_kwargs(), start=1):\n",
    "            print(f'\\n\\n{i}.')\n",
    "            if results:\n",
    "                res = results.res[i - 1]\n",
    "            else:\n",
    "                res = gpt.query(**kwargs)\n",
    "            if kwargs['stream']:\n",
    "                cur = []\n",
    "                for tok, tok_full in res:\n",
    "                    cur.append((tok, tok_full))\n",
    "                    print(tok)\n",
    "                    print('\\t' + str(tok_full) + '\\n')\n",
    "                    if tok_full['finish_reason']: print('\\n---\\n')\n",
    "            else:\n",
    "                texts, fulls = res\n",
    "                print('TEXTS:', texts)\n",
    "                print('FULLS:', fulls)\n",
    "                cur = res\n",
    "            print(spacer())\n",
    "\n",
    "            kwargs_list.append(kwargs)\n",
    "            resp_list.append(cur)\n",
    "    return Results(kwargs=kwargs_list, res=resp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues\n",
    "\n",
    "- no prompt_index in stream=True mode for either repeat or banana (pretty sure not for paid backends either)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T04:00:33.121025Z",
     "start_time": "2022-04-13T04:00:32.717286Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/sample_stream_response.pkl.\n",
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n",
      "Switching openai backend to \"repeat\".\n",
      "np>1: False\n",
      "nc>1: False\n",
      "stream: False\n",
      "\n",
      "\n",
      "1.\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "TEXTS: ['YESTERDAY WAS']\n",
      "FULLS: [{'prompt_index': 0}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: False\n",
      "stream: True\n",
      "\n",
      "\n",
      "2.\n",
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "YESTERDAY \n",
      "\t{'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "WAS \n",
      "\t{'index': 0, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: True\n",
      "stream: False\n",
      "\n",
      "\n",
      "3.\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "TEXTS: ['YESTERDAY WAS', 'YESTERDAY WAS']\n",
      "FULLS: [{'prompt_index': 0}, {'prompt_index': 0}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: True\n",
      "stream: True\n",
      "\n",
      "\n",
      "4.\n",
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "YESTERDAY \n",
      "\t{'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "WAS \n",
      "\t{'index': 0, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "YESTERDAY \n",
      "\t{'index': 1, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "WAS \n",
      "\t{'index': 1, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: False\n",
      "stream: False\n",
      "\n",
      "\n",
      "5.\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "fulls: [[{'prompt_index': 0}], [{'prompt_index': 0}]]\n",
      "TEXTS: ['YESTERDAY WAS', 'HOW MANY']\n",
      "FULLS: [{'prompt_index': 0}, {'prompt_index': 1}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: False\n",
      "stream: True\n",
      "\n",
      "\n",
      "6.\n",
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "YESTERDAY \n",
      "\t{'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "WAS \n",
      "\t{'index': 0, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "HOW \n",
      "\t{'index': 1, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "MANY \n",
      "\t{'index': 1, 'prompt_index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: True\n",
      "stream: False\n",
      "\n",
      "\n",
      "7.\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "fulls: [[{'prompt_index': 0}, {'prompt_index': 0}], [{'prompt_index': 0}, {'prompt_index': 0}]]\n",
      "TEXTS: ['YESTERDAY WAS', 'YESTERDAY WAS', 'HOW MANY', 'HOW MANY']\n",
      "FULLS: [{'prompt_index': 0}, {'prompt_index': 0}, {'prompt_index': 1}, {'prompt_index': 1}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: True\n",
      "stream: True\n",
      "\n",
      "\n",
      "8.\n",
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'repeat', 'query_func': 'query_gpt_repeat'}}\n",
      "YESTERDAY \n",
      "\t{'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "WAS \n",
      "\t{'index': 0, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "YESTERDAY \n",
      "\t{'index': 1, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "WAS \n",
      "\t{'index': 1, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "HOW \n",
      "\t{'index': 2, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "MANY \n",
      "\t{'index': 2, 'prompt_index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "HOW \n",
      "\t{'index': 3, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "MANY \n",
      "\t{'index': 3, 'prompt_index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "Switching  backend back to \"repeat\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:372: UserWarning: Unused kwargs {'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3} received by query_gpt_repeat.\n",
      "  warnings.warn(f'Unused kwargs {kwargs} received by query_gpt_repeat.')\n",
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:669: UserWarning: strip_output=True is not supported in stream mode. Automatically setting it to False.\n",
      "  warnings.warn('strip_output=True is not supported in stream '\n",
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:674: UserWarning: Streaming mode does not support manual truncation of stop phrases and your current backend has limited support for truncation.\n",
      "  'Streaming mode does not support manual truncation of '\n",
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:372: UserWarning: Unused kwargs {'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3} received by query_gpt_repeat.\n",
      "  warnings.warn(f'Unused kwargs {kwargs} received by query_gpt_repeat.')\n",
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:372: UserWarning: Unused kwargs {'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3} received by query_gpt_repeat.\n",
      "  warnings.warn(f'Unused kwargs {kwargs} received by query_gpt_repeat.')\n",
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:372: UserWarning: Unused kwargs {'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3} received by query_gpt_repeat.\n",
      "  warnings.warn(f'Unused kwargs {kwargs} received by query_gpt_repeat.')\n"
     ]
    }
   ],
   "source": [
    "repeat_res = test_backend('repeat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T02:57:42.673561Z",
     "start_time": "2022-04-13T02:57:37.351545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"banana\".\n",
      "np>1: True\n",
      "nc>1: True\n",
      "stream: True\n",
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n",
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:421: UserWarning: query_gpt_banana received unused kwargs {'stream': True, 'engine_i': 0, 'logprobs': 3}.\n",
      "  warnings.warn(f'query_gpt_banana received unused kwargs {kwargs}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1.\n",
      " \n",
      "\t{'id': '563b1b8f-eb21-4582-8cf3-715a0e01cb74', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a big day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "a \n",
      "\t{'id': '563b1b8f-eb21-4582-8cf3-715a0e01cb74', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a big day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "big \n",
      "\t{'id': '563b1b8f-eb21-4582-8cf3-715a0e01cb74', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a big day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': '563b1b8f-eb21-4582-8cf3-715a0e01cb74', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a big day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': '05a64c41-244c-4aa8-aa74-cbf8ab602f92', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a big day', 'input': 'Yesterday was'}], 'index': 1, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "a \n",
      "\t{'id': '05a64c41-244c-4aa8-aa74-cbf8ab602f92', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a big day', 'input': 'Yesterday was'}], 'index': 1, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "big \n",
      "\t{'id': '05a64c41-244c-4aa8-aa74-cbf8ab602f92', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a big day', 'input': 'Yesterday was'}], 'index': 1, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': '05a64c41-244c-4aa8-aa74-cbf8ab602f92', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a big day', 'input': 'Yesterday was'}], 'index': 1, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': 'a17a5cdc-7e6e-4dc1-90d0-0661dadc2d17', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you are', 'input': 'How many'}], 'index': 2, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "of \n",
      "\t{'id': 'a17a5cdc-7e6e-4dc1-90d0-0661dadc2d17', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you are', 'input': 'How many'}], 'index': 2, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "you \n",
      "\t{'id': 'a17a5cdc-7e6e-4dc1-90d0-0661dadc2d17', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you are', 'input': 'How many'}], 'index': 2, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "are \n",
      "\t{'id': 'a17a5cdc-7e6e-4dc1-90d0-0661dadc2d17', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you are', 'input': 'How many'}], 'index': 2, 'prompt_index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': '5843f000-0572-4c04-97ba-b1488ca3b9b5', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 3, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "minutes \n",
      "\t{'id': '5843f000-0572-4c04-97ba-b1488ca3b9b5', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 3, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "are \n",
      "\t{'id': '5843f000-0572-4c04-97ba-b1488ca3b9b5', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 3, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "there \n",
      "\t{'id': '5843f000-0572-4c04-97ba-b1488ca3b9b5', 'message': 'success', 'created': 1649818659, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 3, 'prompt_index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: True\n",
      "stream: False\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:421: UserWarning: query_gpt_banana received unused kwargs {'stream': False, 'engine_i': 0, 'logprobs': 3}.\n",
      "  warnings.warn(f'query_gpt_banana received unused kwargs {kwargs}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2.\n",
      "TEXTS: ['a great day', 'my first day', 'of you have', 'more weeks are']\n",
      "FULLS: [{'id': '0626ac30-7312-4102-a60c-f0b43bf91c7c', 'message': 'success', 'created': 1649818660, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a great day', 'input': 'Yesterday was'}], 'prompt_index': 0}, {'id': '83c796e2-157e-40b0-86c6-e12cf922f5a9', 'message': 'success', 'created': 1649818660, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' my first day', 'input': 'Yesterday was'}], 'prompt_index': 0}, {'id': '71ac8cfc-c798-4ca5-838a-97c16588fbd3', 'message': 'success', 'created': 1649818660, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you have', 'input': 'How many'}], 'prompt_index': 1}, {'id': '2c16ad55-1958-43de-a79f-19ef01a0840e', 'message': 'success', 'created': 1649818660, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' more weeks are', 'input': 'How many'}], 'prompt_index': 1}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: False\n",
      "stream: True\n",
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n",
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:421: UserWarning: query_gpt_banana received unused kwargs {'n': 1, 'stream': True, 'engine_i': 0, 'logprobs': 3}.\n",
      "  warnings.warn(f'query_gpt_banana received unused kwargs {kwargs}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3.\n",
      " \n",
      "\t{'id': '87438ad7-c243-4cc1-8660-45c15f1bc1fe', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "the \n",
      "\t{'id': '87438ad7-c243-4cc1-8660-45c15f1bc1fe', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "first \n",
      "\t{'id': '87438ad7-c243-4cc1-8660-45c15f1bc1fe', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': '87438ad7-c243-4cc1-8660-45c15f1bc1fe', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': 'b48854d6-6943-41fb-a109-96c93628724b', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 1, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "minutes \n",
      "\t{'id': 'b48854d6-6943-41fb-a109-96c93628724b', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 1, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "are \n",
      "\t{'id': 'b48854d6-6943-41fb-a109-96c93628724b', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 1, 'prompt_index': 1, 'finish_reason': None}\n",
      "\n",
      "there \n",
      "\t{'id': 'b48854d6-6943-41fb-a109-96c93628724b', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 1, 'prompt_index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: False\n",
      "stream: False\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:421: UserWarning: query_gpt_banana received unused kwargs {'n': 1, 'stream': False, 'engine_i': 0, 'logprobs': 3}.\n",
      "  warnings.warn(f'query_gpt_banana received unused kwargs {kwargs}.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4.\n",
      "TEXTS: ['the first day', 'minutes are there']\n",
      "FULLS: [{'id': '4e38743f-be5d-4ee1-b9b4-bd3478a57826', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'prompt_index': 0}, {'id': 'e67d74e2-3c49-44d0-9103-3f29354049f8', 'message': 'success', 'created': 1649818661, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'prompt_index': 1}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: True\n",
      "stream: True\n",
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n",
      "\n",
      "\n",
      "5.\n",
      " \n",
      "\t{'id': '07a2463a-aa72-43ec-bccd-740afc5c0142', 'message': 'success', 'created': 1649818662, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "the \n",
      "\t{'id': '07a2463a-aa72-43ec-bccd-740afc5c0142', 'message': 'success', 'created': 1649818662, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "first \n",
      "\t{'id': '07a2463a-aa72-43ec-bccd-740afc5c0142', 'message': 'success', 'created': 1649818662, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': '07a2463a-aa72-43ec-bccd-740afc5c0142', 'message': 'success', 'created': 1649818662, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': '782b4c8c-dd69-4bdc-bc46-97bed6b4ab41', 'message': 'success', 'created': 1649818662, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'index': 1, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "a \n",
      "\t{'id': '782b4c8c-dd69-4bdc-bc46-97bed6b4ab41', 'message': 'success', 'created': 1649818662, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'index': 1, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "good \n",
      "\t{'id': '782b4c8c-dd69-4bdc-bc46-97bed6b4ab41', 'message': 'success', 'created': 1649818662, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'index': 1, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': '782b4c8c-dd69-4bdc-bc46-97bed6b4ab41', 'message': 'success', 'created': 1649818662, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'index': 1, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: True\n",
      "stream: False\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n",
      "\n",
      "\n",
      "6.\n",
      "TEXTS: ['the first time', 'my birthday and']\n",
      "FULLS: [{'id': 'e5939eef-a96e-4d7a-8ee9-f4ec9bc38971', 'message': 'success', 'created': 1649818663, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first time', 'input': 'Yesterday was'}], 'prompt_index': 0}, {'id': 'c9c3b0eb-5e9d-4d6e-a83f-c8990e2259be', 'message': 'success', 'created': 1649818663, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' my birthday and', 'input': 'Yesterday was'}], 'prompt_index': 0}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: False\n",
      "stream: True\n",
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n",
      "\n",
      "\n",
      "7.\n",
      " \n",
      "\t{'id': 'd9bbe0d6-dc75-4d52-9da9-a885736ba6e0', 'message': 'success', 'created': 1649818663, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a sad day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "a \n",
      "\t{'id': 'd9bbe0d6-dc75-4d52-9da9-a885736ba6e0', 'message': 'success', 'created': 1649818663, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a sad day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "sad \n",
      "\t{'id': 'd9bbe0d6-dc75-4d52-9da9-a885736ba6e0', 'message': 'success', 'created': 1649818663, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a sad day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': 'd9bbe0d6-dc75-4d52-9da9-a885736ba6e0', 'message': 'success', 'created': 1649818663, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a sad day', 'input': 'Yesterday was'}], 'index': 0, 'prompt_index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: False\n",
      "stream: False\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'banana', 'query_func': 'query_gpt_banana'}}\n",
      "\n",
      "\n",
      "8.\n",
      "TEXTS: ['the day.']\n",
      "FULLS: [{'id': '61764c3b-bc49-46f3-837b-8ce47cc1f878', 'message': 'success', 'created': 1649818664, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the day.', 'input': 'Yesterday was'}], 'prompt_index': 0}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "Switching  backend back to \"repeat\".\n",
      "Writing data to data/tmp/banana_res.pkl.\n",
      "Object loaded from data/tmp/banana_res.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Even though it's free, try to avoid hitting the API too much just in case \n",
    "# they have some rate limit.\n",
    "banana_res = test_backend('banana')\n",
    "save(banana_res, 'data/tmp/banana_res.pkl')\n",
    "banana_res = load('data/tmp/banana_res.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T02:57:14.713250Z",
     "start_time": "2022-04-13T02:57:14.669919Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"banana\".\n",
      "\n",
      "\n",
      "1.\n",
      " \n",
      "\t{'id': 'ab2f3b0a-0011-495d-848a-62bc558484a1', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "a \n",
      "\t{'id': 'ab2f3b0a-0011-495d-848a-62bc558484a1', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "good \n",
      "\t{'id': 'ab2f3b0a-0011-495d-848a-62bc558484a1', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': 'ab2f3b0a-0011-495d-848a-62bc558484a1', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': '896ede81-9576-43da-9d56-e0bc1bc0cafe', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "the \n",
      "\t{'id': '896ede81-9576-43da-9d56-e0bc1bc0cafe', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "last \n",
      "\t{'id': '896ede81-9576-43da-9d56-e0bc1bc0cafe', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': '896ede81-9576-43da-9d56-e0bc1bc0cafe', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': 'd680ada1-f30f-48f5-bcd6-c61ad3c40ad3', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 2, 'finish_reason': None}\n",
      "\n",
      "minutes \n",
      "\t{'id': 'd680ada1-f30f-48f5-bcd6-c61ad3c40ad3', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 2, 'finish_reason': None}\n",
      "\n",
      "are \n",
      "\t{'id': 'd680ada1-f30f-48f5-bcd6-c61ad3c40ad3', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 2, 'finish_reason': None}\n",
      "\n",
      "there \n",
      "\t{'id': 'd680ada1-f30f-48f5-bcd6-c61ad3c40ad3', 'message': 'success', 'created': 1649736961, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'index': 2, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': 'e6494451-c7a4-4ef3-8f0e-e7643434717f', 'message': 'success', 'created': 1649736962, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you have', 'input': 'How many'}], 'index': 3, 'finish_reason': None}\n",
      "\n",
      "of \n",
      "\t{'id': 'e6494451-c7a4-4ef3-8f0e-e7643434717f', 'message': 'success', 'created': 1649736962, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you have', 'input': 'How many'}], 'index': 3, 'finish_reason': None}\n",
      "\n",
      "you \n",
      "\t{'id': 'e6494451-c7a4-4ef3-8f0e-e7643434717f', 'message': 'success', 'created': 1649736962, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you have', 'input': 'How many'}], 'index': 3, 'finish_reason': None}\n",
      "\n",
      "have \n",
      "\t{'id': 'e6494451-c7a4-4ef3-8f0e-e7643434717f', 'message': 'success', 'created': 1649736962, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' of you have', 'input': 'How many'}], 'index': 3, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "2.\n",
      "TEXTS: ['the first day', 'my birthday,', 'times have you', 'minutes are there']\n",
      "FULLS: [{'id': '946576ca-e75b-46da-9f36-316371b783e1', 'message': 'success', 'created': 1649736962, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'prompt_index': 0}, {'id': '26ba94c4-eb9b-4f04-8e41-e429725a4d57', 'message': 'success', 'created': 1649736962, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' my birthday,', 'input': 'Yesterday was'}], 'prompt_index': 0}, {'id': '602c2a18-6609-4df4-9ec2-6694d61af84a', 'message': 'success', 'created': 1649736962, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' times have you', 'input': 'How many'}], 'prompt_index': 1}, {'id': '08cb64a3-06a3-44c8-b35d-55decba5bd3b', 'message': 'success', 'created': 1649736962, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' minutes are there', 'input': 'How many'}], 'prompt_index': 1}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "3.\n",
      " \n",
      "\t{'id': 'a1752878-1967-4cb8-b41c-a0e6e814c818', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "the \n",
      "\t{'id': 'a1752878-1967-4cb8-b41c-a0e6e814c818', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "last \n",
      "\t{'id': 'a1752878-1967-4cb8-b41c-a0e6e814c818', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': 'a1752878-1967-4cb8-b41c-a0e6e814c818', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': '0b9f48af-fee6-4e27-b6f3-a9861919b2c4', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' times have you', 'input': 'How many'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "times \n",
      "\t{'id': '0b9f48af-fee6-4e27-b6f3-a9861919b2c4', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' times have you', 'input': 'How many'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "have \n",
      "\t{'id': '0b9f48af-fee6-4e27-b6f3-a9861919b2c4', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' times have you', 'input': 'How many'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "you \n",
      "\t{'id': '0b9f48af-fee6-4e27-b6f3-a9861919b2c4', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' times have you', 'input': 'How many'}], 'index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "4.\n",
      "TEXTS: ['the first time', 'people in the']\n",
      "FULLS: [{'id': 'b5be0b3b-6a24-42ad-a938-572e745dc3ff', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first time', 'input': 'Yesterday was'}], 'prompt_index': 0}, {'id': '790747fd-7b93-4dab-8527-4bfac174d4d8', 'message': 'success', 'created': 1649736963, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' people in the', 'input': 'How many'}], 'prompt_index': 1}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "5.\n",
      " \n",
      "\t{'id': '77b109b3-02cb-4327-a19a-763a4c601974', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the big day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "the \n",
      "\t{'id': '77b109b3-02cb-4327-a19a-763a4c601974', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the big day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "big \n",
      "\t{'id': '77b109b3-02cb-4327-a19a-763a4c601974', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the big day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': '77b109b3-02cb-4327-a19a-763a4c601974', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the big day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " \n",
      "\t{'id': 'c04648cb-ece4-4e52-9847-023dc49e84a4', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the deadline for', 'input': 'Yesterday was'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "the \n",
      "\t{'id': 'c04648cb-ece4-4e52-9847-023dc49e84a4', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the deadline for', 'input': 'Yesterday was'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "deadline \n",
      "\t{'id': 'c04648cb-ece4-4e52-9847-023dc49e84a4', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the deadline for', 'input': 'Yesterday was'}], 'index': 1, 'finish_reason': None}\n",
      "\n",
      "for \n",
      "\t{'id': 'c04648cb-ece4-4e52-9847-023dc49e84a4', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the deadline for', 'input': 'Yesterday was'}], 'index': 1, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "6.\n",
      "TEXTS: ['the first day', 'a good day']\n",
      "FULLS: [{'id': '2936449d-6585-4b4e-844b-0b9be8dd9047', 'message': 'success', 'created': 1649736964, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the first day', 'input': 'Yesterday was'}], 'prompt_index': 0}, {'id': '981b06e5-2848-4421-8603-68a1708c60b3', 'message': 'success', 'created': 1649736965, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a good day', 'input': 'Yesterday was'}], 'prompt_index': 0}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "7.\n",
      " \n",
      "\t{'id': 'a21dfd6a-c789-4c7d-841c-a70190d16eef', 'message': 'success', 'created': 1649736965, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a weird day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "a \n",
      "\t{'id': 'a21dfd6a-c789-4c7d-841c-a70190d16eef', 'message': 'success', 'created': 1649736965, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a weird day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "weird \n",
      "\t{'id': 'a21dfd6a-c789-4c7d-841c-a70190d16eef', 'message': 'success', 'created': 1649736965, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a weird day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': None}\n",
      "\n",
      "day \n",
      "\t{'id': 'a21dfd6a-c789-4c7d-841c-a70190d16eef', 'message': 'success', 'created': 1649736965, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' a weird day', 'input': 'Yesterday was'}], 'index': 0, 'finish_reason': 'dummy'}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "8.\n",
      "TEXTS: ['the last day']\n",
      "FULLS: [{'id': '61aba164-3173-4248-ad9b-5122add465a2', 'message': 'success', 'created': 1649736965, 'apiVersion': '26 Nov 2021', 'modelOutputs': [{'output': ' the last day', 'input': 'Yesterday was'}], 'prompt_index': 0}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "Switching  backend back to \"repeat\".\n"
     ]
    }
   ],
   "source": [
    "banana_res = test_backend('banana', results=banana_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T04:00:42.749903Z",
     "start_time": "2022-04-13T04:00:42.612671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"mock\".\n",
      "np>1: False\n",
      "nc>1: False\n",
      "stream: False\n",
      "\n",
      "\n",
      "1.\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      "TEXTS: ['a typical rainy']\n",
      "FULLS: [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cce570> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    2,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375,\n",
      "    -6.06640625,\n",
      "    -5.671875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\",\n",
      "    \" typical\",\n",
      "    \" rainy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    },\n",
      "    {\n",
      "      \" Monday\": -2.974609375,\n",
      "      \" day\": -1.095703125,\n",
      "      \" work\": -2.94140625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a typical rainy', 'token_index': 0, 'prompt_index': 0}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: False\n",
      "stream: True\n",
      "\n",
      "\n",
      "2.\n",
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      " a\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cce048> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0}\n",
      "\n",
      " bit\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cce200> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -4.75390625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" bit\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' bit', 'token_index': 1}\n",
      "\n",
      " busy\n",
      "\t{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cce3b8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    6\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -5.09375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" busy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" like\": -4.03515625,\n",
      "      \" more\": -3.875,\n",
      "      \" of\": -0.352294921875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' busy', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: True\n",
      "stream: False\n",
      "\n",
      "\n",
      "3.\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      "TEXTS: ['my mother�', 'the Academy Awards']\n",
      "FULLS: [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cecbf8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    3,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.384765625,\n",
      "    -5.4375,\n",
      "    -0.44677734375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" my\",\n",
      "    \" mother\",\n",
      "    \"\\ufffd\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" birthday\": -2.107421875,\n",
      "      \" first\": -1.3818359375,\n",
      "      \" last\": -2.130859375\n",
      "    },\n",
      "    {\n",
      "      \"'s\": -1.509765625,\n",
      "      \"-\": -2.630859375,\n",
      "      \"\\ufffd\": -0.44677734375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' my mother�', 'token_index': 0, 'prompt_index': 0}, {'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x125cecdb0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    4,\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.8720703125,\n",
      "    -8.796875,\n",
      "    -0.1270751953125\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" the\",\n",
      "    \" Academy\",\n",
      "    \" Awards\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" day\": -2.28125,\n",
      "      \" first\": -1.69921875,\n",
      "      \" last\": -2.41015625\n",
      "    },\n",
      "    {\n",
      "      \" Award\": -2.845703125,\n",
      "      \" Awards\": -0.1270751953125,\n",
      "      \"\\ufffd\": -4.12109375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' the Academy Awards', 'token_index': 0, 'prompt_index': 0}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: False\n",
      "nc>1: True\n",
      "stream: True\n",
      "\n",
      "\n",
      "4.\n",
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      " a\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cec1a8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0}\n",
      "\n",
      " positive\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cec360> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -8.34375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" positive\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' positive', 'token_index': 1}\n",
      "\n",
      " day\n",
      "\t{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cec518> JSON: {\n",
      "  \"text_offset\": [\n",
      "    11\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -0.4296875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" day\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" day\": -0.4296875,\n",
      "      \" experience\": -3.392578125,\n",
      "      \" one\": -3.216796875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' day', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " clearer\n",
      "\t{'finish_reason': None, 'index': 1, 'logprobs': <OpenAIObject at 0x125cec6d0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -12.46875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" clearer\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' clearer', 'token_index': 0}\n",
      "\n",
      " and\n",
      "\t{'finish_reason': None, 'index': 1, 'logprobs': <OpenAIObject at 0x125cec888> JSON: {\n",
      "  \"text_offset\": [\n",
      "    8\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.021484375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" and\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" and\": -2.021484375,\n",
      "      \" than\": -0.619140625,\n",
      "      \",\": -2.5078125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' and', 'token_index': 1}\n",
      "\n",
      " colder\n",
      "\t{'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x125ceca40> JSON: {\n",
      "  \"text_offset\": [\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -3.44140625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" colder\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" brighter\": -1.658203125,\n",
      "      \" more\": -2.109375,\n",
      "      \" warmer\": -2.234375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' colder', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: False\n",
      "stream: False\n",
      "\n",
      "\n",
      "5.\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      "{'n': 1, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      "fulls: [[{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cce570> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    2,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375,\n",
      "    -6.06640625,\n",
      "    -5.671875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\",\n",
      "    \" typical\",\n",
      "    \" rainy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    },\n",
      "    {\n",
      "      \" Monday\": -2.974609375,\n",
      "      \" day\": -1.095703125,\n",
      "      \" work\": -2.94140625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a typical rainy', 'token_index': 0, 'prompt_index': 0}], [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cce570> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    2,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375,\n",
      "    -6.06640625,\n",
      "    -5.671875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\",\n",
      "    \" typical\",\n",
      "    \" rainy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    },\n",
      "    {\n",
      "      \" Monday\": -2.974609375,\n",
      "      \" day\": -1.095703125,\n",
      "      \" work\": -2.94140625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a typical rainy', 'token_index': 0, 'prompt_index': 0}]]\n",
      "TEXTS: ['a typical rainy', 'a typical rainy']\n",
      "FULLS: [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cce570> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    2,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375,\n",
      "    -6.06640625,\n",
      "    -5.671875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\",\n",
      "    \" typical\",\n",
      "    \" rainy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    },\n",
      "    {\n",
      "      \" Monday\": -2.974609375,\n",
      "      \" day\": -1.095703125,\n",
      "      \" work\": -2.94140625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a typical rainy', 'token_index': 0, 'prompt_index': 0}, {'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cce570> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    2,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375,\n",
      "    -6.06640625,\n",
      "    -5.671875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\",\n",
      "    \" typical\",\n",
      "    \" rainy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    },\n",
      "    {\n",
      "      \" Monday\": -2.974609375,\n",
      "      \" day\": -1.095703125,\n",
      "      \" work\": -2.94140625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a typical rainy', 'token_index': 0, 'prompt_index': 1}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: False\n",
      "stream: True\n",
      "\n",
      "\n",
      "6.\n",
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 1, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      " a\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cce048> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0}\n",
      "\n",
      " bit\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cce200> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -4.75390625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" bit\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' bit', 'token_index': 1}\n",
      "\n",
      " busy\n",
      "\t{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cce3b8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    6\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -5.09375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" busy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" like\": -4.03515625,\n",
      "      \" more\": -3.875,\n",
      "      \" of\": -0.352294921875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' busy', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " a\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cce048> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0}\n",
      "\n",
      " bit\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cce200> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -4.75390625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" bit\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' bit', 'token_index': 1}\n",
      "\n",
      " busy\n",
      "\t{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cce3b8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    6\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -5.09375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" busy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" like\": -4.03515625,\n",
      "      \" more\": -3.875,\n",
      "      \" of\": -0.352294921875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' busy', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: True\n",
      "stream: False\n",
      "\n",
      "\n",
      "7.\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      "{'n': 2, 'stream': False, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      "fulls: [[{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cecbf8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    3,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.384765625,\n",
      "    -5.4375,\n",
      "    -0.44677734375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" my\",\n",
      "    \" mother\",\n",
      "    \"\\ufffd\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" birthday\": -2.107421875,\n",
      "      \" first\": -1.3818359375,\n",
      "      \" last\": -2.130859375\n",
      "    },\n",
      "    {\n",
      "      \"'s\": -1.509765625,\n",
      "      \"-\": -2.630859375,\n",
      "      \"\\ufffd\": -0.44677734375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' my mother�', 'token_index': 0, 'prompt_index': 0}, {'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x125cecdb0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    4,\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.8720703125,\n",
      "    -8.796875,\n",
      "    -0.1270751953125\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" the\",\n",
      "    \" Academy\",\n",
      "    \" Awards\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" day\": -2.28125,\n",
      "      \" first\": -1.69921875,\n",
      "      \" last\": -2.41015625\n",
      "    },\n",
      "    {\n",
      "      \" Award\": -2.845703125,\n",
      "      \" Awards\": -0.1270751953125,\n",
      "      \"\\ufffd\": -4.12109375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' the Academy Awards', 'token_index': 0, 'prompt_index': 0}], [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cecbf8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    3,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.384765625,\n",
      "    -5.4375,\n",
      "    -0.44677734375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" my\",\n",
      "    \" mother\",\n",
      "    \"\\ufffd\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" birthday\": -2.107421875,\n",
      "      \" first\": -1.3818359375,\n",
      "      \" last\": -2.130859375\n",
      "    },\n",
      "    {\n",
      "      \"'s\": -1.509765625,\n",
      "      \"-\": -2.630859375,\n",
      "      \"\\ufffd\": -0.44677734375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' my mother�', 'token_index': 0, 'prompt_index': 0}, {'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x125cecdb0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    4,\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.8720703125,\n",
      "    -8.796875,\n",
      "    -0.1270751953125\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" the\",\n",
      "    \" Academy\",\n",
      "    \" Awards\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" day\": -2.28125,\n",
      "      \" first\": -1.69921875,\n",
      "      \" last\": -2.41015625\n",
      "    },\n",
      "    {\n",
      "      \" Award\": -2.845703125,\n",
      "      \" Awards\": -0.1270751953125,\n",
      "      \"\\ufffd\": -4.12109375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' the Academy Awards', 'token_index': 0, 'prompt_index': 0}]]\n",
      "TEXTS: ['my mother�', 'the Academy Awards', 'my mother�', 'the Academy Awards']\n",
      "FULLS: [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cecbf8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    3,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.384765625,\n",
      "    -5.4375,\n",
      "    -0.44677734375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" my\",\n",
      "    \" mother\",\n",
      "    \"\\ufffd\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" birthday\": -2.107421875,\n",
      "      \" first\": -1.3818359375,\n",
      "      \" last\": -2.130859375\n",
      "    },\n",
      "    {\n",
      "      \"'s\": -1.509765625,\n",
      "      \"-\": -2.630859375,\n",
      "      \"\\ufffd\": -0.44677734375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' my mother�', 'token_index': 0, 'prompt_index': 0}, {'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x125cecdb0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    4,\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.8720703125,\n",
      "    -8.796875,\n",
      "    -0.1270751953125\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" the\",\n",
      "    \" Academy\",\n",
      "    \" Awards\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" day\": -2.28125,\n",
      "      \" first\": -1.69921875,\n",
      "      \" last\": -2.41015625\n",
      "    },\n",
      "    {\n",
      "      \" Award\": -2.845703125,\n",
      "      \" Awards\": -0.1270751953125,\n",
      "      \"\\ufffd\": -4.12109375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' the Academy Awards', 'token_index': 0, 'prompt_index': 0}, {'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cecbf8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    3,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.384765625,\n",
      "    -5.4375,\n",
      "    -0.44677734375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" my\",\n",
      "    \" mother\",\n",
      "    \"\\ufffd\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" birthday\": -2.107421875,\n",
      "      \" first\": -1.3818359375,\n",
      "      \" last\": -2.130859375\n",
      "    },\n",
      "    {\n",
      "      \"'s\": -1.509765625,\n",
      "      \"-\": -2.630859375,\n",
      "      \"\\ufffd\": -0.44677734375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' my mother�', 'token_index': 0, 'prompt_index': 1}, {'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x125cecdb0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    4,\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.8720703125,\n",
      "    -8.796875,\n",
      "    -0.1270751953125\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" the\",\n",
      "    \" Academy\",\n",
      "    \" Awards\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" day\": -2.28125,\n",
      "      \" first\": -1.69921875,\n",
      "      \" last\": -2.41015625\n",
      "    },\n",
      "    {\n",
      "      \" Award\": -2.845703125,\n",
      "      \" Awards\": -0.1270751953125,\n",
      "      \"\\ufffd\": -4.12109375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' the Academy Awards', 'token_index': 0, 'prompt_index': 1}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "np>1: True\n",
      "nc>1: True\n",
      "stream: True\n",
      "\n",
      "\n",
      "8.\n",
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'Yesterday was', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 2, 'stream': True, 'engine_i': 0, 'max_tokens': 3, 'logprobs': 3, 'prompt': 'How many', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      " a\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cec1a8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0}\n",
      "\n",
      " positive\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cec360> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -8.34375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" positive\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' positive', 'token_index': 1}\n",
      "\n",
      " day\n",
      "\t{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cec518> JSON: {\n",
      "  \"text_offset\": [\n",
      "    11\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -0.4296875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" day\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" day\": -0.4296875,\n",
      "      \" experience\": -3.392578125,\n",
      "      \" one\": -3.216796875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' day', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " clearer\n",
      "\t{'finish_reason': None, 'index': 1, 'logprobs': <OpenAIObject at 0x125cec6d0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -12.46875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" clearer\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' clearer', 'token_index': 0}\n",
      "\n",
      " and\n",
      "\t{'finish_reason': None, 'index': 1, 'logprobs': <OpenAIObject at 0x125cec888> JSON: {\n",
      "  \"text_offset\": [\n",
      "    8\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.021484375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" and\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" and\": -2.021484375,\n",
      "      \" than\": -0.619140625,\n",
      "      \",\": -2.5078125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' and', 'token_index': 1}\n",
      "\n",
      " colder\n",
      "\t{'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x125ceca40> JSON: {\n",
      "  \"text_offset\": [\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -3.44140625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" colder\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" brighter\": -1.658203125,\n",
      "      \" more\": -2.109375,\n",
      "      \" warmer\": -2.234375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' colder', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " a\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cec1a8> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a', 'token_index': 0}\n",
      "\n",
      " positive\n",
      "\t{'finish_reason': None, 'index': 0, 'logprobs': <OpenAIObject at 0x125cec360> JSON: {\n",
      "  \"text_offset\": [\n",
      "    2\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -8.34375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" positive\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' positive', 'token_index': 1}\n",
      "\n",
      " day\n",
      "\t{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125cec518> JSON: {\n",
      "  \"text_offset\": [\n",
      "    11\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -0.4296875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" day\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" day\": -0.4296875,\n",
      "      \" experience\": -3.392578125,\n",
      "      \" one\": -3.216796875\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' day', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      " clearer\n",
      "\t{'finish_reason': None, 'index': 1, 'logprobs': <OpenAIObject at 0x125cec6d0> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -12.46875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" clearer\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' clearer', 'token_index': 0}\n",
      "\n",
      " and\n",
      "\t{'finish_reason': None, 'index': 1, 'logprobs': <OpenAIObject at 0x125cec888> JSON: {\n",
      "  \"text_offset\": [\n",
      "    8\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.021484375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" and\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" and\": -2.021484375,\n",
      "      \" than\": -0.619140625,\n",
      "      \",\": -2.5078125\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' and', 'token_index': 1}\n",
      "\n",
      " colder\n",
      "\t{'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x125ceca40> JSON: {\n",
      "  \"text_offset\": [\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -3.44140625\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" colder\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" brighter\": -1.658203125,\n",
      "      \" more\": -2.109375,\n",
      "      \" warmer\": -2.234375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' colder', 'token_index': 2}\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "Switching  backend back to \"repeat\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:400: UserWarning: query_gpt_mock received unused kwargs: {'engine_i': 0, 'max_tokens': 3, 'logprobs': 3}\n",
      "  warnings.warn(f'query_gpt_mock received unused kwargs: {kwargs}')\n"
     ]
    }
   ],
   "source": [
    "mock_res = test_backend('mock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:56:23.948259Z",
     "start_time": "2022-04-13T03:56:23.881636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True, False)\n",
      "[\" Mozilla's ann\", ' reminded of this', ' lessons would it', ' teenagers are allowed']\n",
      "(True, False, False)\n",
      "[' 24 years ago', ' months did it']\n",
      "(False, True, False)\n",
      "[' my mother�', ' the Academy Awards']\n",
      "(False, False, False)\n",
      "[' a typical rainy']\n"
     ]
    }
   ],
   "source": [
    "for k, v in MOCKS.items():\n",
    "    if k[-1]: continue\n",
    "    print(k)\n",
    "    print([row['text'] for row in v['choices']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:25:47.312235Z",
     "start_time": "2022-04-13T03:25:47.269492Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2 prompts, 1 completion per prompt, stream=False\n",
    "p2c1s0 = MOCKS[True, False, False]\n",
    "p1c2s0 = MOCKS[False, True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:25:53.635408Z",
     "start_time": "2022-04-13T03:25:53.587866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['24 years ago', 'months did it'],\n",
       " [{'finish_reason': 'length',\n",
       "   'index': 0,\n",
       "   'logprobs': <OpenAIObject at 0x125bacaf0> JSON: {\n",
       "     \"text_offset\": [\n",
       "       0,\n",
       "       3,\n",
       "       9\n",
       "     ],\n",
       "     \"token_logprobs\": [\n",
       "       -8.1484375,\n",
       "       -1.931640625,\n",
       "       -0.8271484375\n",
       "     ],\n",
       "     \"tokens\": [\n",
       "       \" 24\",\n",
       "       \" years\",\n",
       "       \" ago\"\n",
       "     ],\n",
       "     \"top_logprobs\": [\n",
       "       {\n",
       "         \" a\": -1.3818359375,\n",
       "         \" my\": -2.384765625,\n",
       "         \" the\": -1.8720703125\n",
       "       },\n",
       "       {\n",
       "         \" hours\": -1.21484375,\n",
       "         \" years\": -1.931640625,\n",
       "         \"th\": -1.8212890625\n",
       "       },\n",
       "       {\n",
       "         \" ago\": -0.8271484375,\n",
       "         \" since\": -1.0576171875,\n",
       "         \" to\": -2.794921875\n",
       "       }\n",
       "     ]\n",
       "   },\n",
       "   'text': ' 24 years ago',\n",
       "   'token_index': 0,\n",
       "   'prompt_index': 0},\n",
       "  {'finish_reason': 'length',\n",
       "   'index': 1,\n",
       "   'logprobs': <OpenAIObject at 0x125bacca8> JSON: {\n",
       "     \"text_offset\": [\n",
       "       0,\n",
       "       7,\n",
       "       11\n",
       "     ],\n",
       "     \"token_logprobs\": [\n",
       "       -5.46484375,\n",
       "       -5,\n",
       "       -1.4169921875\n",
       "     ],\n",
       "     \"tokens\": [\n",
       "       \" months\",\n",
       "       \" did\",\n",
       "       \" it\"\n",
       "     ],\n",
       "     \"top_logprobs\": [\n",
       "       {\n",
       "         \" of\": -2.251953125,\n",
       "         \" people\": -2.943359375,\n",
       "         \" times\": -1.8173828125\n",
       "       },\n",
       "       {\n",
       "         \" are\": -0.167724609375,\n",
       "         \" is\": -3.70703125,\n",
       "         \" will\": -3.78515625\n",
       "       },\n",
       "       {\n",
       "         \" it\": -1.4169921875,\n",
       "         \" the\": -3.44140625,\n",
       "         \" you\": -0.48876953125\n",
       "       }\n",
       "     ]\n",
       "   },\n",
       "   'text': ' months did it',\n",
       "   'token_index': 0,\n",
       "   'prompt_index': 1}])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts, fulls = containerize(*postprocess_gpt_response(p2c1s0))\n",
    "postprocess_response((texts, fulls), n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:41:52.515976Z",
     "start_time": "2022-04-13T03:41:52.450132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: [' my mother�', ' the Academy Awards']\n",
      "FULL: [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x1245f1990> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    3,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -2.384765625,\n",
      "    -5.4375,\n",
      "    -0.44677734375\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" my\",\n",
      "    \" mother\",\n",
      "    \"\\ufffd\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" birthday\": -2.107421875,\n",
      "      \" first\": -1.3818359375,\n",
      "      \" last\": -2.130859375\n",
      "    },\n",
      "    {\n",
      "      \"'s\": -1.509765625,\n",
      "      \"-\": -2.630859375,\n",
      "      \"\\ufffd\": -0.44677734375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' my mother�', 'token_index': 0}, {'finish_reason': 'length', 'index': 1, 'logprobs': <OpenAIObject at 0x1245f1b48> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    4,\n",
      "    12\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.8720703125,\n",
      "    -8.796875,\n",
      "    -0.1270751953125\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" the\",\n",
      "    \" Academy\",\n",
      "    \" Awards\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" day\": -2.28125,\n",
      "      \" first\": -1.69921875,\n",
      "      \" last\": -2.41015625\n",
      "    },\n",
      "    {\n",
      "      \" Award\": -2.845703125,\n",
      "      \" Awards\": -0.1270751953125,\n",
      "      \"\\ufffd\": -4.12109375\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' the Academy Awards', 'token_index': 0}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['my mother�', 'the Academy Awards'],\n",
       " [{'finish_reason': 'length',\n",
       "   'index': 0,\n",
       "   'logprobs': <OpenAIObject at 0x1245f1990> JSON: {\n",
       "     \"text_offset\": [\n",
       "       0,\n",
       "       3,\n",
       "       10\n",
       "     ],\n",
       "     \"token_logprobs\": [\n",
       "       -2.384765625,\n",
       "       -5.4375,\n",
       "       -0.44677734375\n",
       "     ],\n",
       "     \"tokens\": [\n",
       "       \" my\",\n",
       "       \" mother\",\n",
       "       \"\\ufffd\"\n",
       "     ],\n",
       "     \"top_logprobs\": [\n",
       "       {\n",
       "         \" a\": -1.3818359375,\n",
       "         \" my\": -2.384765625,\n",
       "         \" the\": -1.8720703125\n",
       "       },\n",
       "       {\n",
       "         \" birthday\": -2.107421875,\n",
       "         \" first\": -1.3818359375,\n",
       "         \" last\": -2.130859375\n",
       "       },\n",
       "       {\n",
       "         \"'s\": -1.509765625,\n",
       "         \"-\": -2.630859375,\n",
       "         \"\\ufffd\": -0.44677734375\n",
       "       }\n",
       "     ]\n",
       "   },\n",
       "   'text': ' my mother�',\n",
       "   'token_index': 0,\n",
       "   'prompt_index': 0},\n",
       "  {'finish_reason': 'length',\n",
       "   'index': 1,\n",
       "   'logprobs': <OpenAIObject at 0x1245f1b48> JSON: {\n",
       "     \"text_offset\": [\n",
       "       0,\n",
       "       4,\n",
       "       12\n",
       "     ],\n",
       "     \"token_logprobs\": [\n",
       "       -1.8720703125,\n",
       "       -8.796875,\n",
       "       -0.1270751953125\n",
       "     ],\n",
       "     \"tokens\": [\n",
       "       \" the\",\n",
       "       \" Academy\",\n",
       "       \" Awards\"\n",
       "     ],\n",
       "     \"top_logprobs\": [\n",
       "       {\n",
       "         \" a\": -1.3818359375,\n",
       "         \" my\": -2.384765625,\n",
       "         \" the\": -1.8720703125\n",
       "       },\n",
       "       {\n",
       "         \" day\": -2.28125,\n",
       "         \" first\": -1.69921875,\n",
       "         \" last\": -2.41015625\n",
       "       },\n",
       "       {\n",
       "         \" Award\": -2.845703125,\n",
       "         \" Awards\": -0.1270751953125,\n",
       "         \"\\ufffd\": -4.12109375\n",
       "       }\n",
       "     ]\n",
       "   },\n",
       "   'text': ' the Academy Awards',\n",
       "   'token_index': 0,\n",
       "   'prompt_index': 0}])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts, fulls = postprocess_gpt_response(p1c2s0)\n",
    "postprocess_response((texts, fulls), n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:42:57.404628Z",
     "start_time": "2022-04-13T03:42:57.368447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' my mother�', ' the Academy Awards']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:58:46.231595Z",
     "start_time": "2022-04-13T03:58:46.199365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"mock\".\n",
      "{'n': 1, 'stream': False, 'prompt': 'ac', 'meta': {'backend_name': 'mock', 'query_func': 'query_gpt_mock'}}\n",
      ">>> response: ([' a typical rainy'], [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125a06e08> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    2,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375,\n",
      "    -6.06640625,\n",
      "    -5.671875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\",\n",
      "    \" typical\",\n",
      "    \" rainy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    },\n",
      "    {\n",
      "      \" Monday\": -2.974609375,\n",
      "      \" day\": -1.095703125,\n",
      "      \" work\": -2.94140625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a typical rainy', 'token_index': 0}])\n",
      "TEXT: [' a typical rainy']\n",
      "FULL: [{'finish_reason': 'length', 'index': 0, 'logprobs': <OpenAIObject at 0x125a06e08> JSON: {\n",
      "  \"text_offset\": [\n",
      "    0,\n",
      "    2,\n",
      "    10\n",
      "  ],\n",
      "  \"token_logprobs\": [\n",
      "    -1.3818359375,\n",
      "    -6.06640625,\n",
      "    -5.671875\n",
      "  ],\n",
      "  \"tokens\": [\n",
      "    \" a\",\n",
      "    \" typical\",\n",
      "    \" rainy\"\n",
      "  ],\n",
      "  \"top_logprobs\": [\n",
      "    {\n",
      "      \" a\": -1.3818359375,\n",
      "      \" my\": -2.384765625,\n",
      "      \" the\": -1.8720703125\n",
      "    },\n",
      "    {\n",
      "      \" big\": -1.83984375,\n",
      "      \" day\": -2.53125,\n",
      "      \" very\": -2.916015625\n",
      "    },\n",
      "    {\n",
      "      \" Monday\": -2.974609375,\n",
      "      \" day\": -1.095703125,\n",
      "      \" work\": -2.94140625\n",
      "    }\n",
      "  ]\n",
      "}, 'text': ' a typical rainy', 'token_index': 0}]\n",
      "Switching  backend back to \"repeat\".\n"
     ]
    }
   ],
   "source": [
    "with gpt('mock'):\n",
    "    res = gpt.query('ac', n=1, stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T03:58:50.103218Z",
     "start_time": "2022-04-13T03:58:50.052234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a typical rainy'],\n",
       " [{'finish_reason': 'length',\n",
       "   'index': 0,\n",
       "   'logprobs': <OpenAIObject at 0x125a06e08> JSON: {\n",
       "     \"text_offset\": [\n",
       "       0,\n",
       "       2,\n",
       "       10\n",
       "     ],\n",
       "     \"token_logprobs\": [\n",
       "       -1.3818359375,\n",
       "       -6.06640625,\n",
       "       -5.671875\n",
       "     ],\n",
       "     \"tokens\": [\n",
       "       \" a\",\n",
       "       \" typical\",\n",
       "       \" rainy\"\n",
       "     ],\n",
       "     \"top_logprobs\": [\n",
       "       {\n",
       "         \" a\": -1.3818359375,\n",
       "         \" my\": -2.384765625,\n",
       "         \" the\": -1.8720703125\n",
       "       },\n",
       "       {\n",
       "         \" big\": -1.83984375,\n",
       "         \" day\": -2.53125,\n",
       "         \" very\": -2.916015625\n",
       "       },\n",
       "       {\n",
       "         \" Monday\": -2.974609375,\n",
       "         \" day\": -1.095703125,\n",
       "         \" work\": -2.94140625\n",
       "       }\n",
       "     ]\n",
       "   },\n",
       "   'text': ' a typical rainy',\n",
       "   'token_index': 0,\n",
       "   'prompt_index': 0}])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
