{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "ConversationManager refactor attempt. Trying to change its interface so it can more effectively:\n",
    "1. Support longer conversations via prompting with a subset of past responseses,\n",
    "2. Support longer conversations via summarizing past conv, and\n",
    "3. Still work with my GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T03:10:53.432081Z",
     "start_time": "2021-07-13T03:10:53.413544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T03:53:51.989984Z",
     "start_time": "2021-07-13T03:53:51.922547Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T03:11:09.060903Z",
     "start_time": "2021-07-13T03:11:09.005977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T03:59:49.227909Z",
     "start_time": "2021-07-13T03:59:49.083994Z"
    }
   },
   "outputs": [],
   "source": [
    "class ProtoConversationManager:\n",
    "    \"\"\"Similar to PromptManager but designed for ongoing conversations. This\n",
    "    currently references just a single prompt: conversation.\n",
    "    \"\"\"\n",
    "\n",
    "    img_exts = {'.jpg', '.jpeg', '.png'}\n",
    "\n",
    "    def __init__(self, *names, verbose=True, data_dir='./data',\n",
    "                 backup_image='data/misc/unknown_person.png', \n",
    "                 turn_window=4):\n",
    "        assert 1 <= turn_window <= 20, 'turn_window should be in [1, 20].'\n",
    "        \n",
    "        # User window is adjusted because we'll be adding in the user's new\n",
    "        # turn separately from accessing their historical turns.\n",
    "        self.user_turn_window = int(np.ceil(turn_window / 2)) - 1\n",
    "        self.gpt3_turn_window = turn_window - self.user_turn_window\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Set directories for data storage, logging, etc.\n",
    "        self.backup_image = Path(backup_image)\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.persona_dir = self.data_dir/'conversation_personas'\n",
    "        self.conversation_dir = self.data_dir/'conversations'\n",
    "        self.log_dir = self.data_dir/'logs'\n",
    "        self.log_path = Path(self.log_dir)/'conversation_query_kwargs.json'\n",
    "        for dir_ in (self.persona_dir, self.conversation_dir, self.log_dir):\n",
    "            os.makedirs(dir_, exist_ok=True)\n",
    "\n",
    "        # These attributes will be updated when we load a persona and cleared\n",
    "        # when we end a conversation. current_persona is the processed name\n",
    "        # (i.e. lowercase w/ underscores).\n",
    "        self.current_persona = ''\n",
    "        self.current_summary = ''\n",
    "        self.current_img_path = ''\n",
    "        self.current_gender = ''\n",
    "        self.full_conv = ''\n",
    "        self.cached_query = ''\n",
    "        self.user_turns = []\n",
    "        self.gpt3_turns = []\n",
    "\n",
    "        # Load prompt, default query kwargs, and existing personas.\n",
    "        self._kwargs = load_prompt('conversation')\n",
    "        self._base_prompt = self._kwargs.pop('prompt')\n",
    "\n",
    "        # Populated by _load_personas().\n",
    "        self.name2img_path = {}\n",
    "        self.name2base = {}\n",
    "        self.name2gender = {}\n",
    "        self._load_personas(names)\n",
    "\n",
    "    def _load_personas(self, names):\n",
    "        names = names or [path.stem for path in self.persona_dir.iterdir()]\n",
    "        for name in names:\n",
    "            print(name)\n",
    "            try:\n",
    "                self.update_persona_dicts(self.process_name(name))\n",
    "            except:\n",
    "                print('exc')\n",
    "                warnings.warn(f'Could not load files for {name}.')\n",
    "\n",
    "    def start_conversation(self, name, download_if_necessary=False):\n",
    "        if name not in self:\n",
    "            if not download_if_necessary:\n",
    "                raise KeyError(f'{name} persona not available. You can set '\n",
    "                               'download_if_necessary=True if you wish to '\n",
    "                               'construct a new persona.')\n",
    "            _ = self.add_persona(name, return_data=True)\n",
    "        self.end_conversation()\n",
    "\n",
    "        processed_name = self.process_name(name)\n",
    "        self.current_persona = processed_name\n",
    "        self.full_conv = self.name2base[processed_name]\n",
    "        self.current_img_path = self.name2img_path[processed_name]\n",
    "        self.current_gender = self.name2gender[processed_name]\n",
    "        # This one is not returned. Info would be a bit repetitive.\n",
    "        self.current_summary = self._name2summary(processed_name)\n",
    "        return (self.current_persona,\n",
    "                self.full_conv,\n",
    "                self.current_img_path,\n",
    "                self.current_gender)\n",
    "\n",
    "    def _name2summary(self, name):\n",
    "        if '_' not in name: name = self.process_name(name)\n",
    "        base = self.name2base[name]\n",
    "        intro = sent_tokenize(base)[0]\n",
    "        return base.replace(intro, '').strip()\n",
    "\n",
    "    def end_conversation(self, fname=None):\n",
    "        if fname: self.save_conversation(fname)\n",
    "        self.full_conv = ''\n",
    "        self.current_summary = ''\n",
    "        self.current_persona = ''\n",
    "        self.current_img_path = ''\n",
    "        self.current_gender = ''\n",
    "        self.cached_query = ''\n",
    "        self.user_turns.clear()\n",
    "        self.gpt3_turns.clear()\n",
    "\n",
    "    def save_conversation(self, fname):\n",
    "        if not self.full_conv:\n",
    "            raise RuntimeError('No conversation to save.')\n",
    "        save(self.full_conv, self.conversation_dir/fname)\n",
    "\n",
    "    def add_persona(self, name, return_data=False):\n",
    "        processed_name = self.process_name(name)\n",
    "        dir_ = self.persona_dir/processed_name\n",
    "        if dir_.exists():\n",
    "            summary, img_path, gender = self.update_persona_dicts(\n",
    "                processed_name, return_values=True\n",
    "            )\n",
    "        else:\n",
    "            summary, _, img_path, gender = wiki_data(\n",
    "                name, img_dir=self.persona_dir/processed_name, fname='profile'\n",
    "            )\n",
    "            save(summary, dir_/'summary.txt')\n",
    "            save(gender, dir_/'gender.json')\n",
    "\n",
    "            # Otherwise it's an empty string if we fail to download an image.\n",
    "            if not img_path:\n",
    "                img_path = dir_/f'profile{self.backup_image.suffix}'\n",
    "                shutil.copy2(self.backup_image, img_path)\n",
    "            self.update_persona_dicts(processed_name)\n",
    "        if return_data: return summary, img_path, gender\n",
    "\n",
    "    def update_persona_dicts(self, processed_name, return_values=False):\n",
    "        dir_ = self.persona_dir/processed_name\n",
    "        summary = load(dir_/'summary.txt')\n",
    "        self.name2gender[processed_name] = load(dir_/'gender.json')\n",
    "        self.name2img_path[processed_name] = [p for p in dir_.iterdir()\n",
    "                                              if p.stem == 'profile'][0]\n",
    "        self.name2base[processed_name] = self._base_prompt.format(\n",
    "            name=self.process_name(processed_name, inverse=True),\n",
    "            summary=summary\n",
    "        )\n",
    "        if return_values:\n",
    "            return Results(summary=summary,\n",
    "                           img_path=self.name2img_path[processed_name],\n",
    "                           gender=self.name2gender[processed_name])\n",
    "\n",
    "    def process_name(self, name, inverse=False):\n",
    "        if inverse:\n",
    "            return name.replace('_', ' ').title()\n",
    "        return name.lower().replace(' ', '_').replace('.', '')\n",
    "\n",
    "    def personas(self, pretty=True, sort=True):\n",
    "        names = list(self.name2base)\n",
    "        if pretty: names = [self.process_name(name, True) for name in names]\n",
    "        if sort: names = sorted(names)\n",
    "        return names\n",
    "\n",
    "    def kwargs(self, name='', fully_resolved=True, return_prompt=False,\n",
    "               extra_kwargs=None, **kwargs):\n",
    "        # Name param should be pretty version, i.e. no underscores. Only\n",
    "        # needed when return_prompt is True.\n",
    "        if 'prompt' in kwargs:\n",
    "            raise RuntimeError(\n",
    "                'Arg \"prompt\" should not be in query kwargs. It will be '\n",
    "                'constructed within this method and passing it in will '\n",
    "                'override the new version.'\n",
    "            )\n",
    "        kwargs = {**self._kwargs, **kwargs}\n",
    "        for k, v in (extra_kwargs or {}).items():\n",
    "            v_cls = type(v)\n",
    "            # Make a new object instead of just using get() or setdefault\n",
    "            # since the latter two methods both mutate our default kwargs.\n",
    "            curr_val = v_cls(kwargs.get(k, v_cls()))\n",
    "            if isinstance(v, Iterable):\n",
    "                curr_val.extend(v)\n",
    "            elif isinstance(v, Mapping):\n",
    "                curr_val.update(v)\n",
    "            else:\n",
    "                raise TypeError(f'Key {k} has unrecognized type {v_cls} in '\n",
    "                                '`extra_kwargs`.')\n",
    "            kwargs[k] = curr_val\n",
    "\n",
    "        if fully_resolved: kwargs = dict(bound_args(query_gpt3, [], kwargs))\n",
    "        if name and return_prompt:\n",
    "            kwargs['prompt'] = self.name2base[self.process_name(name)]\n",
    "        return kwargs\n",
    "\n",
    "    def query_later(self, text):\n",
    "        self.cached_query = text.strip()\n",
    "        \n",
    "    def query(self, text=None, debug=False, extra_kwargs=None, **kwargs):\n",
    "        if not self.current_persona:\n",
    "            raise RuntimeError('You must call the `start_conversation` '\n",
    "                               'method before making a query.')\n",
    "        \n",
    "        # In the same spirit as our handling of kwargs here, passing in a text\n",
    "        # arg will override a cached query if one exists.\n",
    "        text = text or self.cached_query\n",
    "        self.cached_query = ''\n",
    "        kwargs = self.kwargs(fully_resolved=False, return_prompt=False,\n",
    "                             extra_kwargs=extra_kwargs, **kwargs)\n",
    "        prompt = self.format_prompt(user_text=text)\n",
    "        if debug:\n",
    "            print('prompt:\\n' + prompt)\n",
    "            print(spacer())\n",
    "            print('kwargs:\\n', kwargs)\n",
    "            print(spacer())\n",
    "            print('fully resolved kwargs:\\n',\n",
    "                  dict(bound_args(query_gpt3, [], kwargs)))\n",
    "            return\n",
    "        \n",
    "        # Update this after format_prompt() call and debug check.\n",
    "        self.user_turns.append(text.strip())\n",
    "        save({'prompt': prompt, **kwargs}, self.log_path, verbose=False)\n",
    "        prompt, resp = query_gpt3(prompt, **kwargs)\n",
    "        self.gpt3_turns.append(text.strip())\n",
    "        # GPT3 prefers prompts that don't end with spaces and query_gpt3()\n",
    "        # strips output, but we want a space after the colon.\n",
    "        self.full_conv = prompt + ' ' + resp\n",
    "        return prompt, resp\n",
    "\n",
    "    def format_prompt(self, user_text, exclude_trailing_name=False):\n",
    "        if not self.full_conv:\n",
    "            raise RuntimeError('Conversation history is empty. Have you '\n",
    "                               'started a conversation?')\n",
    "        user_turns = (self.user_turns[-self.user_turn_window:]\n",
    "                      + [user_text.strip()])\n",
    "        gpt3_turns = self.gpt3_turns[-self.gpt3_turn_window]\n",
    "        user_turns = [f'Me: {turn}' for turn in user_turns]\n",
    "        gpt3_turns = [f'{self.current_persona}: {turn}'\n",
    "                      for turn in gpt3_turns]\n",
    "        prompt = self.current_summary + \\\n",
    "            '\\n\\n'.join(flatten(zip_longest(user_turns, gpt3_turns)))\n",
    "        # TODO: still need to check if this works as expected.\n",
    "        if exclude_trailing_name: return prompt\n",
    "        return f'{prompt}\\n\\n{self.process_name(self.current_persona, True)}:'\n",
    "\n",
    "    @contextmanager\n",
    "    def converse(self, name, fname='', download_if_necessary=False):\n",
    "        try:\n",
    "            _ = self.start_conversation(name, download_if_necessary)\n",
    "            yield\n",
    "        finally:\n",
    "            self.end_conversation(fname=fname)\n",
    "\n",
    "    @staticmethod\n",
    "    def format_conversation(text, gpt_color='black'):\n",
    "        def _format(line, color='black'):\n",
    "            if not line: return line\n",
    "            name, _, line = line.partition(':')\n",
    "            # Bold's stop character also resets color so we need to color the\n",
    "            # chunks separately.\n",
    "            return colored(bold(name + ':'), color) + colored(line, color)\n",
    "\n",
    "        if listlike(text): text = ' '.join(text)\n",
    "        summary, *lines = text.splitlines()\n",
    "        name = [name for name, n in\n",
    "                Counter(line.split(':')[0]\n",
    "                        for line in lines if ':' in line).most_common(2)\n",
    "                if name != 'Me'][0]\n",
    "        formatted_lines = [bold(summary)]\n",
    "        prev_is_me = True\n",
    "        for line in lines:\n",
    "            if line.startswith(name + ':'):\n",
    "                line = _format(line, gpt_color)\n",
    "                prev_is_me = False\n",
    "            elif line.startswith('Me: ') or prev_is_me:\n",
    "                line = _format(line)\n",
    "                prev_is_me = True\n",
    "            formatted_lines.append(line)\n",
    "        return '\\n'.join(formatted_lines)\n",
    "\n",
    "    def __contains__(self, name):\n",
    "        return self.process_name(name) in self.name2base\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name2base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T03:55:42.622885Z",
     "start_time": "2021-07-13T03:55:42.562016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "a\n",
      "two\n",
      "b\n",
      "three\n"
     ]
    }
   ],
   "source": [
    "a = ['one', 'two', 'three']\n",
    "b = ['a', 'b']\n",
    "tmp = '\\n'.join(filter(None, flatten(zip_longest(a, b))))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T03:55:45.781715Z",
     "start_time": "2021-07-13T03:55:45.721898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "a\n",
      "two\n",
      "b\n",
      "three\n"
     ]
    }
   ],
   "source": [
    "'\\n'.join(filter(None, flatten(zip_longest(a, b + ['c']))))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
