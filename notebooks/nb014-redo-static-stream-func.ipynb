{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Try rewriting generator that streams from static backends. Want to do stopword truncation upfront. Might also be able to make this MUCH simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:17:02.326216Z",
     "start_time": "2022-05-10T03:17:02.304066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:32:04.420226Z",
     "start_time": "2022-05-10T03:32:04.374851Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from jabberwocky.config import C\n",
    "from jabberwocky.openai_utils import load_prompt, load_openai_api_key, GPT, \\\n",
    "    query_gpt_huggingface, truncate_at_first_stop, stream_response\n",
    "from jabberwocky.streaming import _stream_fake_generator, _stream_response\n",
    "from jabberwocky.utils import containerize\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:17:48.952742Z",
     "start_time": "2022-05-10T03:17:48.919324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/jabberwocky\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:17:58.738285Z",
     "start_time": "2022-05-10T03:17:58.704216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching openai backend to \"huggingface\".\n"
     ]
    }
   ],
   "source": [
    "GPT.switch('huggingface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:36:11.301205Z",
     "start_time": "2022-05-10T03:36:11.251024Z"
    }
   },
   "outputs": [],
   "source": [
    "def stream_fake_generator_v2(response, stop, start_i=0, prompt_i=0,\n",
    "                             subwords=True, **kwargs):\n",
    "    texts, fulls = containerize(*response)\n",
    "    for i, (text, full) in enumerate(zip(texts, fulls)):\n",
    "        trunc_text = truncate_at_first_stop(text, stop, **kwargs)\n",
    "        # Converting to list lets us edit the last finish_reason more easily.\n",
    "        pairs = [\n",
    "            list(pair) for pair in\n",
    "            _stream_response(\n",
    "                trunc_text,\n",
    "                {**full,\n",
    "                 'index': i + start_i,\n",
    "                 'prompt_index': prompt_i,\n",
    "                 'finish_reason': None},\n",
    "                subwords=subwords)\n",
    "        ]\n",
    "        reason = 'dummy' if trunc_text == text else 'stop'\n",
    "        pairs[-1][-1]['finish_reason'] = reason\n",
    "        yield from pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:32:06.564906Z",
     "start_time": "2022-05-10T03:32:06.531098Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the math question.\n",
    "\n",
    "Question: What is 3+4?\n",
    "Answer: 7\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't use GPT.query as usual because the whole point here is to get the result without all my builtin postprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:25:56.718958Z",
     "start_time": "2022-05-10T03:25:54.673876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:267: UserWarning: query_gpt_huggingface received unused kwargs {'stream': False}.\n",
      "  warnings.warn('query_gpt_huggingface received unused kwargs '\n"
     ]
    }
   ],
   "source": [
    "stop = ['\\n\\nQuestion: ', '\\nAnswer:']\n",
    "res = query_gpt_huggingface(prompt.format('What is 5-2?'), max_tokens=15,\n",
    "                            engine=0, \n",
    "                            stop=stop, \n",
    "                            n=2,\n",
    "                            stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:37:41.889345Z",
     "start_time": "2022-05-10T03:37:41.810061Z"
    }
   },
   "outputs": [],
   "source": [
    "res[0].append('Fake completion with no stopwords.')\n",
    "res[1].append({'generated_text': 'Fake completion with no stopwords.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:25:57.771223Z",
     "start_time": "2022-05-10T03:25:57.733152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       " ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:21:13.284843Z",
     "start_time": "2022-05-10T03:21:13.240351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncate_at_first_stop(res[0][0], stop_phrases=stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:26:06.931864Z",
     "start_time": "2022-05-10T03:26:06.868756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' 3',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('.',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('\\n',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('\\n',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('Question',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (':',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (' 2',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('+',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('4',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('-',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('3',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('?',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (' 6',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('\\n',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('Answer',\n",
       "  {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer',\n",
       "   'index': 0,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': 'dummy'}),\n",
       " (' 8',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('\\n',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('\\n',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('Question',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (':',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (' What',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (' is',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (' 1',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('+',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('2',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('?',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('\\n',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " ('Answer',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (':',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': None}),\n",
       " (' 3',\n",
       "  {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3',\n",
       "   'index': 1,\n",
       "   'prompt_index': 0,\n",
       "   'finish_reason': 'dummy'})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(_stream_fake_generator(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:37:51.859640Z",
     "start_time": "2022-05-10T03:37:51.821849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3 {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer', 'index': 0, 'prompt_index': 0, 'finish_reason': None}\n",
      ". {'generated_text': ' 3.\\n\\nQuestion: 2+4-3? 6\\nAnswer', 'index': 0, 'prompt_index': 0, 'finish_reason': 'stop'}\n",
      " 8 {'generated_text': ' 8\\n\\nQuestion: What is 1+2?\\nAnswer: 3', 'index': 1, 'prompt_index': 0, 'finish_reason': 'stop'}\n",
      "Fake {'generated_text': 'Fake completion with no stopwords.', 'index': 2, 'prompt_index': 0, 'finish_reason': None}\n",
      " completion {'generated_text': 'Fake completion with no stopwords.', 'index': 2, 'prompt_index': 0, 'finish_reason': None}\n",
      " with {'generated_text': 'Fake completion with no stopwords.', 'index': 2, 'prompt_index': 0, 'finish_reason': None}\n",
      " no {'generated_text': 'Fake completion with no stopwords.', 'index': 2, 'prompt_index': 0, 'finish_reason': None}\n",
      " stopwords {'generated_text': 'Fake completion with no stopwords.', 'index': 2, 'prompt_index': 0, 'finish_reason': None}\n",
      ". {'generated_text': 'Fake completion with no stopwords.', 'index': 2, 'prompt_index': 0, 'finish_reason': 'dummy'}\n"
     ]
    }
   ],
   "source": [
    "for tok, full in stream_fake_generator_v2(res, stop):\n",
    "    print(tok, full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
